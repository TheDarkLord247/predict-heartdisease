{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aman Oberoi: Predicting the risk of stroke in patients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The dataset\n",
    "The dataset provided contains information about 5110 patients on features such as their age, gender, average glucose level, smoking habits, etc. along with whether they have had stroke or not. This dataset can thus be used to train some machine learning models to predict whether given certain medical information about a person, are they likely to get a stroke or not - and thus help the patients take adequate precautions to prevent a stroke from happening or their general cardiovasucalar health from worsening."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attribute Information\n",
    "1) id: unique identifier\n",
    "2) gender: \"Male\", \"Female\" or \"Other\"\n",
    "3) age: age of the patient\n",
    "4) hypertension: 0 if the patient doesn't have hypertension, 1 if the patient has hypertension 5) heart_disease: 0 if the patient doesn't have any heart diseases, 1 if the patient has a heart disease\n",
    "6) ever_married: \"No\" or \"Yes\"\n",
    "7) work_type: \"children\", \"Govt_jov\", \"Never_worked\", \"Private\" or \"Self-employed\"\n",
    "8) Residence_type: \"Rural\" or \"Urban\"\n",
    "9) avg_glucose_level: average glucose level in blood\n",
    "10) bmi: body mass index\n",
    "11) smoking_status: \"formerly smoked\", \"never smoked\", \"smokes\" or \"Unknown\"*\n",
    "12) stroke: 1 if the patient had a stroke or 0 if not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries and inspecting dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt # this is used for the plot the graph \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "health_df = pd.read_csv(\"stroke_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head of df:\n",
      "      id  gender   age  hypertension  heart_disease ever_married  \\\n",
      "0   9046    Male  67.0             0              1          Yes   \n",
      "1  51676  Female  61.0             0              0          Yes   \n",
      "2  31112    Male  80.0             0              1          Yes   \n",
      "3  60182  Female  49.0             0              0          Yes   \n",
      "4   1665  Female  79.0             1              0          Yes   \n",
      "\n",
      "       work_type Residence_type  avg_glucose_level   bmi   smoking_status  \\\n",
      "0        Private          Urban             228.69  36.6  formerly smoked   \n",
      "1  Self-employed          Rural             202.21   NaN     never smoked   \n",
      "2        Private          Rural             105.92  32.5     never smoked   \n",
      "3        Private          Urban             171.23  34.4           smokes   \n",
      "4  Self-employed          Rural             174.12  24.0     never smoked   \n",
      "\n",
      "   stroke  \n",
      "0       1  \n",
      "1       1  \n",
      "2       1  \n",
      "3       1  \n",
      "4       1  \n",
      "DF info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5110 entries, 0 to 5109\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   id                 5110 non-null   int64  \n",
      " 1   gender             5110 non-null   object \n",
      " 2   age                5110 non-null   float64\n",
      " 3   hypertension       5110 non-null   int64  \n",
      " 4   heart_disease      5110 non-null   int64  \n",
      " 5   ever_married       5110 non-null   object \n",
      " 6   work_type          5110 non-null   object \n",
      " 7   Residence_type     5110 non-null   object \n",
      " 8   avg_glucose_level  5110 non-null   float64\n",
      " 9   bmi                4909 non-null   float64\n",
      " 10  smoking_status     5110 non-null   object \n",
      " 11  stroke             5110 non-null   int64  \n",
      "dtypes: float64(3), int64(4), object(5)\n",
      "memory usage: 479.2+ KB\n",
      "None\n",
      "DF stats:\n",
      "                 id          age  hypertension  heart_disease  \\\n",
      "count   5110.000000  5110.000000   5110.000000    5110.000000   \n",
      "mean   36517.829354    43.226614      0.097456       0.054012   \n",
      "std    21161.721625    22.612647      0.296607       0.226063   \n",
      "min       67.000000     0.080000      0.000000       0.000000   \n",
      "25%    17741.250000    25.000000      0.000000       0.000000   \n",
      "50%    36932.000000    45.000000      0.000000       0.000000   \n",
      "75%    54682.000000    61.000000      0.000000       0.000000   \n",
      "max    72940.000000    82.000000      1.000000       1.000000   \n",
      "\n",
      "       avg_glucose_level          bmi       stroke  \n",
      "count        5110.000000  4909.000000  5110.000000  \n",
      "mean          106.147677    28.893237     0.048728  \n",
      "std            45.283560     7.854067     0.215320  \n",
      "min            55.120000    10.300000     0.000000  \n",
      "25%            77.245000    23.500000     0.000000  \n",
      "50%            91.885000    28.100000     0.000000  \n",
      "75%           114.090000    33.100000     0.000000  \n",
      "max           271.740000    97.600000     1.000000  \n"
     ]
    }
   ],
   "source": [
    "print(\"Head of df:\")\n",
    "print(health_df.head())\n",
    "print(\"DF info:\")\n",
    "print(health_df.info())\n",
    "print(\"DF stats:\")\n",
    "print(health_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examining data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting non-numeric data to numeric data purely for doing some intial data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting gender data to numeric\n",
      "Classes:  ['Female' 'Male' 'Other']\n",
      "Encoded list:  [1 0 1 ... 0 1 0]\n",
      "Converting marriage data to numeric\n",
      "Classes:  ['No' 'Yes']\n",
      "Encoded list:  [1 1 1 ... 1 1 1]\n",
      "Converting smoking data to numeric\n",
      "Classes:  ['Unknown' 'formerly smoked' 'never smoked' 'smokes']\n",
      "Encoded list:  [1 2 2 ... 2 1 0]\n",
      "Converting work data to numeric\n",
      "Classes:  ['Govt_job' 'Never_worked' 'Private' 'Self-employed' 'children']\n",
      "Encoded list:  [2 3 2 ... 3 2 0]\n",
      "Converting residence data to numeric\n",
      "Classes:  ['Rural' 'Urban']\n",
      "Encoded list:  [1 0 0 ... 0 0 1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>stroke</th>\n",
       "      <th>gender</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>work_type</th>\n",
       "      <th>Residence_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9046</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>228.69</td>\n",
       "      <td>36.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51676</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>202.21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31112</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>105.92</td>\n",
       "      <td>32.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60182</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>171.23</td>\n",
       "      <td>34.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1665</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>174.12</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id   age  hypertension  heart_disease  avg_glucose_level   bmi  stroke  \\\n",
       "0   9046  67.0             0              1             228.69  36.6       1   \n",
       "1  51676  61.0             0              0             202.21   NaN       1   \n",
       "2  31112  80.0             0              1             105.92  32.5       1   \n",
       "3  60182  49.0             0              0             171.23  34.4       1   \n",
       "4   1665  79.0             1              0             174.12  24.0       1   \n",
       "\n",
       "   gender  ever_married  smoking_status  work_type  Residence_type  \n",
       "0       1             1               1          2               1  \n",
       "1       0             1               2          3               0  \n",
       "2       1             1               2          2               0  \n",
       "3       0             1               3          2               1  \n",
       "4       0             1               2          3               0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "#mapping males to 1, females to 0 and other genders to 2 \n",
    "print(\"Converting gender data to numeric\")\n",
    "gender_list = health_df['gender'].tolist()\n",
    "label_encoder.fit(gender_list)\n",
    "print(\"Classes: \", label_encoder.classes_)\n",
    "\n",
    "encoded_list = label_encoder.transform(gender_list)\n",
    "print(\"Encoded list: \", encoded_list)\n",
    "\n",
    "health_df = health_df.drop('gender', axis=1) # dropping sick column with t/f values\n",
    "health_df['gender'] = encoded_list \n",
    "\n",
    "#mapping married people to 1, unmarried people to 0\n",
    "print(\"Converting marriage data to numeric\")\n",
    "e_list = health_df['ever_married'].tolist()\n",
    "label_encoder.fit(e_list)\n",
    "print(\"Classes: \", label_encoder.classes_)\n",
    "\n",
    "encoded_list = label_encoder.transform(e_list) \n",
    "print(\"Encoded list: \", encoded_list)\n",
    "\n",
    "health_df = health_df.drop('ever_married', axis=1) # dropping sick column with t/f values\n",
    "health_df['ever_married'] = encoded_list\n",
    "\n",
    "# for smoking_status, mapping 'Unknown' to 0, 'formerly smoked' to 1, 'never smoked' to 2, 'smokes' to 3\n",
    "print(\"Converting smoking data to numeric\")\n",
    "s_list = health_df['smoking_status'].tolist()\n",
    "label_encoder.fit(s_list)\n",
    "print(\"Classes: \", label_encoder.classes_)\n",
    "\n",
    "encoded_list = label_encoder.transform(s_list) \n",
    "print(\"Encoded list: \", encoded_list)\n",
    "\n",
    "health_df = health_df.drop('smoking_status', axis=1) # dropping sick column with t/f values\n",
    "health_df['smoking_status'] = encoded_list\n",
    "\n",
    "#for work_type, mapping 'Govt_job' to 0, 'Never_worked' to 1, 'Private' to 2, 'Self-employed' to 3, 'children' to 4\n",
    "print(\"Converting work data to numeric\")\n",
    "w_list = health_df['work_type'].tolist()\n",
    "label_encoder.fit(w_list)\n",
    "print(\"Classes: \", label_encoder.classes_)\n",
    "\n",
    "encoded_list = label_encoder.transform(w_list) \n",
    "print(\"Encoded list: \", encoded_list)\n",
    "\n",
    "health_df = health_df.drop('work_type', axis=1) # dropping sick column with t/f values\n",
    "health_df['work_type'] = encoded_list\n",
    "\n",
    "#for residence_type, mapping urban to 1 and rural to 0\n",
    "print(\"Converting residence data to numeric\")\n",
    "r_list = health_df['Residence_type'].tolist()\n",
    "label_encoder.fit(r_list)\n",
    "print(\"Classes: \", label_encoder.classes_)\n",
    "\n",
    "encoded_list = label_encoder.transform(r_list) \n",
    "print(\"Encoded list: \", encoded_list)\n",
    "\n",
    "health_df = health_df.drop('Residence_type', axis=1) # dropping sick column with t/f values\n",
    "health_df['Residence_type'] = encoded_list\n",
    "\n",
    "health_df.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we have a completely numerical data and can do some initial analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1080 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "health_df.hist(bins=50, figsize=(20,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    4861\n",
      "1     249\n",
      "Name: stroke, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "health_df['stroke'].hist(bins=3, figsize=(5,5))\n",
    "plt.show()\n",
    "print(health_df['stroke'].value_counts())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation of other variables with the stroke variable:\n",
      "stroke               1.000000\n",
      "age                  0.245257\n",
      "heart_disease        0.134914\n",
      "avg_glucose_level    0.131945\n",
      "hypertension         0.127904\n",
      "ever_married         0.108340\n",
      "bmi                  0.042374\n",
      "smoking_status       0.028123\n",
      "Residence_type       0.015458\n",
      "gender               0.008929\n",
      "id                   0.006388\n",
      "work_type           -0.032316\n",
      "Name: stroke, dtype: float64\n",
      "Heatmap:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr_matrix = health_df.corr()\n",
    "#plotting varibales correlated to the 'sick' variable in descending order\n",
    "#the correlation matrix contains the correlations between all the variables but only the correlation with ...\n",
    "# ... the sick variable is important\n",
    "print(\"Correlation of other variables with the stroke variable:\")\n",
    "print(corr_matrix['stroke'].sort_values(ascending=False))\n",
    "\n",
    "import seaborn as sns\n",
    "print('Heatmap:')\n",
    "sns.heatmap(corr_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data feature extraction\n",
    "The id field is not going to be useful for our models as it does not carry any correlation with the stroke variable. We will drop it.\n",
    "\n",
    "The age, avg_glucose_level, bmi numeric variables can remain the same. I will carry out normalization on all three variables to improve our models performances/\n",
    "\n",
    "The ever_married and Residence_type categorical variables have no ordinal properties but are binary and dont need One-Hot encoding so I will transform them into a binary numeric type.\n",
    "\n",
    "The gender, work_type and smoking_status categorical variables have no ordinal properties either but are not binary so I will one-hot encode these predictor variables. Note that smoking_status could be considered as an ordinal variable but it also has an unknown value which will contribute to noise if we choose to treat the variable as ordinal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "health_df = pd.read_csv(\"stroke_data.csv\") # reimporting dataset\n",
    "health_df = health_df.drop('id', axis=1) # dropping id as it is not a useful variable for our study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying variables with null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bmi']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "health_df.columns[health_df.isna().any()].tolist() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incomp_rows = health_df[health_df.isnull().any(axis=1)].head()\n",
    "len(incomp_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'bmi' is the only variable with missing values and only 5 datapoints are missing the BMI information. The best strategy here would be to replace the bmi with the median of the entire column or drop the datapoints but I prefer replacing with median to keep the 5 datapoints for training the model later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting categorical variables ever_married and Residence_type to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting marriage data to numeric\n",
      "Classes:  ['No' 'Yes']\n",
      "Encoded list:  [1 1 1 ... 1 1 1]\n",
      "Converting residence data to numeric\n",
      "Classes:  ['Rural' 'Urban']\n",
      "Encoded list:  [1 0 0 ... 0 0 1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>work_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>stroke</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>Residence_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Private</td>\n",
       "      <td>228.69</td>\n",
       "      <td>36.6</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Female</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>202.21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Private</td>\n",
       "      <td>105.92</td>\n",
       "      <td>32.5</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Female</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Private</td>\n",
       "      <td>171.23</td>\n",
       "      <td>34.4</td>\n",
       "      <td>smokes</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Female</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>174.12</td>\n",
       "      <td>24.0</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender   age  hypertension  heart_disease      work_type  \\\n",
       "0    Male  67.0             0              1        Private   \n",
       "1  Female  61.0             0              0  Self-employed   \n",
       "2    Male  80.0             0              1        Private   \n",
       "3  Female  49.0             0              0        Private   \n",
       "4  Female  79.0             1              0  Self-employed   \n",
       "\n",
       "   avg_glucose_level   bmi   smoking_status  stroke  ever_married  \\\n",
       "0             228.69  36.6  formerly smoked       1             1   \n",
       "1             202.21   NaN     never smoked       1             1   \n",
       "2             105.92  32.5     never smoked       1             1   \n",
       "3             171.23  34.4           smokes       1             1   \n",
       "4             174.12  24.0     never smoked       1             1   \n",
       "\n",
       "   Residence_type  \n",
       "0               1  \n",
       "1               0  \n",
       "2               0  \n",
       "3               1  \n",
       "4               0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mapping married people to 1, unmarried people to 0\n",
    "print(\"Converting marriage data to numeric\")\n",
    "e_list = health_df['ever_married'].tolist()\n",
    "label_encoder.fit(e_list)\n",
    "print(\"Classes: \", label_encoder.classes_)\n",
    "\n",
    "encoded_list = label_encoder.transform(e_list) \n",
    "print(\"Encoded list: \", encoded_list)\n",
    "\n",
    "health_df = health_df.drop('ever_married', axis=1) # dropping sick column with t/f values\n",
    "health_df['ever_married'] = encoded_list\n",
    "\n",
    "#for residence_type, mapping urban to 1 and rural to 0\n",
    "print(\"Converting residence data to numeric\")\n",
    "r_list = health_df['Residence_type'].tolist()\n",
    "label_encoder.fit(r_list)\n",
    "print(\"Classes: \", label_encoder.classes_)\n",
    "\n",
    "encoded_list = label_encoder.transform(r_list) \n",
    "print(\"Encoded list: \", encoded_list)\n",
    "\n",
    "health_df = health_df.drop('Residence_type', axis=1) # dropping sick column with t/f values\n",
    "health_df['Residence_type'] = encoded_list\n",
    "\n",
    "health_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline to transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   gender   age  hypertension  heart_disease      work_type  \\\n",
      "0    Male  67.0             0              1        Private   \n",
      "1  Female  61.0             0              0  Self-employed   \n",
      "2    Male  80.0             0              1        Private   \n",
      "3  Female  49.0             0              0        Private   \n",
      "4  Female  79.0             1              0  Self-employed   \n",
      "\n",
      "   avg_glucose_level   bmi   smoking_status  ever_married  Residence_type  \n",
      "0             228.69  36.6  formerly smoked             1               1  \n",
      "1             202.21   NaN     never smoked             1               0  \n",
      "2             105.92  32.5     never smoked             1               0  \n",
      "3             171.23  34.4           smokes             1               1  \n",
      "4             174.12  24.0     never smoked             1               0  \n",
      "\n",
      "\n",
      "Prepared health data shape:\n",
      "(5110, 20)\n",
      "Prepared health data examples:\n",
      "[[ 1.05143428 -0.32860186  4.18503199 ...  1.          0.\n",
      "   0.        ]\n",
      " [ 0.78607007 -0.32860186 -0.2389468  ...  0.          1.\n",
      "   0.        ]\n",
      " [ 1.62639008 -0.32860186  4.18503199 ...  0.          1.\n",
      "   0.        ]\n",
      " ...\n",
      " [-0.36384151 -0.32860186 -0.2389468  ...  0.          1.\n",
      "   0.        ]\n",
      " [ 0.34379639 -0.32860186 -0.2389468  ...  1.          0.\n",
      "   0.        ]\n",
      " [ 0.03420481 -0.32860186 -0.2389468  ...  0.          0.\n",
      "   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "stroke_labels = health_df[\"stroke\"].copy()\n",
    "health_df = health_df.drop(\"stroke\", axis=1)\n",
    "\n",
    "OHE_var = ['gender', 'work_type', 'smoking_status'] # variables I intend to OHE\n",
    "\n",
    "health_num = health_df.drop(OHE_var, axis=1)\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"median\") # use median imputation for missing values (for BMI)\n",
    "\n",
    "print(health_df.head())\n",
    "bmi_idx, gluc_idx = 5, 6\n",
    "\n",
    "# \n",
    "class AugmentFeatures(BaseEstimator, TransformerMixin):\n",
    "    '''\n",
    "    implements the cross feature bmi_gluc = bmi * glucose level\n",
    "    '''\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # nothing else to do\n",
    "    \n",
    "    def transform(self, X):\n",
    "        bmi_gluc = X[:, bmi_idx] * X[:, gluc_idx]\n",
    "        return np.c_[X, bmi_gluc]\n",
    "\n",
    "attr_adder = AugmentFeatures()\n",
    "health_extra_attribs = attr_adder.transform(health_df.values) # generate new features\n",
    "\n",
    "# this will be are numerical pipeline\n",
    "# 1. impute, 2. augment the feature set 3. normalize using StandardScaler()\n",
    "num_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "        ('attribs_adder', AugmentFeatures()),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "    ])\n",
    "\n",
    "health_num_tr = num_pipeline.fit_transform(health_num)\n",
    "\n",
    "numerical_features = list(health_num)\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "        (\"num\", num_pipeline, numerical_features),\n",
    "        (\"cat\", OneHotEncoder(), OHE_var),\n",
    "    ])\n",
    "\n",
    "health_prepared = full_pipeline.fit_transform(health_df)\n",
    "print(\"\\n\")\n",
    "print(\"Prepared health data shape:\")\n",
    "print(health_prepared.shape)\n",
    "print(\"Prepared health data examples:\")\n",
    "print(health_prepared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20 features does not seem like a lot, however, we can still do some Principal Component Analysis to reduce the dimensionality of our data (to reduce noise, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality Reduction: Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5110, 8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import decomposition\n",
    "pca = decomposition.PCA(n_components=8) # reducing the number of features\n",
    "\n",
    "health_pca = pca.fit_transform(health_prepared)\n",
    "# we will train and test models on both the reduced dimension data and the normal prepared data\n",
    "health_pca.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OLS (Feature Selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "health_stats = sm.OLS(stroke_labels, health_prepared)\n",
    "result_stats = health_stats.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in the table below the following are the variables:\n",
    "1 - age\n",
    "2 - hypertension\n",
    "3 - heart rate\n",
    "4 - average glucose level\n",
    "5 - BMI\n",
    "6 - ever married\n",
    "7 - residence type\n",
    "8 - BMI x glucose (cross term)\n",
    "9 - female\n",
    "10 - male\n",
    "11 - other\n",
    "12 - govt job\n",
    "13 - never worked\n",
    "14 - private work\n",
    "15 - self employed\n",
    "16 - child\n",
    "17 - unknown smoking status\n",
    "18 - formerly smoking\n",
    "19 - never smoked\n",
    "20 - smokes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 stroke   R-squared:                       0.085\n",
      "Model:                            OLS   Adj. R-squared:                  0.082\n",
      "Method:                 Least Squares   F-statistic:                     27.72\n",
      "Date:                Wed, 18 Aug 2021   Prob (F-statistic):           3.11e-85\n",
      "Time:                        16:41:48   Log-Likelihood:                 822.98\n",
      "No. Observations:                5110   AIC:                            -1610.\n",
      "Df Residuals:                    5092   BIC:                            -1492.\n",
      "Df Model:                          17                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             0.0699      0.005     14.287      0.000       0.060       0.079\n",
      "x2             0.0114      0.003      3.732      0.000       0.005       0.017\n",
      "x3             0.0113      0.003      3.709      0.000       0.005       0.017\n",
      "x4             0.0138      0.003      4.524      0.000       0.008       0.020\n",
      "x5            -0.0055      0.003     -1.678      0.093      -0.012       0.001\n",
      "x6            -0.0140      0.005     -2.800      0.005      -0.024      -0.004\n",
      "x7             0.0058      0.005      1.173      0.241      -0.004       0.015\n",
      "x8            -0.0046      0.006     -0.793      0.428      -0.016       0.007\n",
      "x9             0.0288      0.040      0.722      0.470      -0.049       0.107\n",
      "x10            0.0272      0.040      0.681      0.496      -0.051       0.105\n",
      "x11            0.0038      0.167      0.023      0.982      -0.324       0.331\n",
      "x12           -0.0095      0.020     -0.471      0.637      -0.049       0.030\n",
      "x13            0.0260      0.042      0.624      0.533      -0.056       0.108\n",
      "x14            0.0051      0.019      0.266      0.790      -0.032       0.043\n",
      "x15           -0.0144      0.020     -0.711      0.477      -0.054       0.025\n",
      "x16            0.0525      0.021      2.448      0.014       0.010       0.095\n",
      "x17            0.0166      0.023      0.724      0.469      -0.028       0.061\n",
      "x18            0.0181      0.023      0.792      0.428      -0.027       0.063\n",
      "x19            0.0094      0.023      0.415      0.678      -0.035       0.054\n",
      "x20            0.0157      0.023      0.676      0.499      -0.030       0.061\n",
      "==============================================================================\n",
      "Omnibus:                     3802.599   Durbin-Watson:                   0.173\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            47464.568\n",
      "Skew:                           3.646   Prob(JB):                         0.00\n",
      "Kurtosis:                      16.029   Cond. No.                     1.21e+16\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 9.17e-29. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "print(result_stats.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the data it looks like the 'other' gender type, private work and the 'never smoked' smoking type are variables with high p values which means that the stroke labels (whether someone has had a stroke or not) doesnt depend much on these variables. This makes intuitive sense for never smoked - as although a person doesnt smoke, they are still susceptible to strokes due to other factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "health_pca_stats = sm.OLS(stroke_labels, health_pca)\n",
    "\n",
    "result_pca_stats = health_pca_stats.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                 stroke   R-squared (uncentered):                   0.070\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.069\n",
      "Method:                 Least Squares   F-statistic:                              48.03\n",
      "Date:                Wed, 18 Aug 2021   Prob (F-statistic):                    3.48e-75\n",
      "Time:                        16:41:48   Log-Likelihood:                          654.68\n",
      "No. Observations:                5110   AIC:                                     -1293.\n",
      "Df Residuals:                    5102   BIC:                                     -1241.\n",
      "Df Model:                           8                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             0.0253      0.002     13.793      0.000       0.022       0.029\n",
      "x2             0.0157      0.002      6.553      0.000       0.011       0.020\n",
      "x3             0.0236      0.003      8.150      0.000       0.018       0.029\n",
      "x4            -0.0038      0.003     -1.216      0.224      -0.010       0.002\n",
      "x5             0.0078      0.003      2.383      0.017       0.001       0.014\n",
      "x6            -0.0124      0.004     -3.540      0.000      -0.019      -0.006\n",
      "x7             0.0060      0.004      1.398      0.162      -0.002       0.014\n",
      "x8             0.0404      0.005      7.936      0.000       0.030       0.050\n",
      "==============================================================================\n",
      "Omnibus:                     3867.444   Durbin-Watson:                   0.142\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            49965.579\n",
      "Skew:                           3.722   Prob(JB):                         0.00\n",
      "Kurtosis:                      16.389   Cond. No.                         2.77\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "print(result_pca_stats.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe how the values in the P > |t| column have gone down significantly. This is good as we want our p-values to be as low as possible as it implies that the model is confident that our strple labels are dependent on our predictor features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting dataset into training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this code block creates test train split of data that hasnt had its dimensionality reduced through pca - this data\n",
    "# ... has a lot of noise so I will train my models on the PCA treated data\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#train, test, target, target_test = train_test_split(health_prepared, stroke_labels, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4088, 8)\n",
      "(1022, 8)\n",
      "(4088,)\n",
      "(1022,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "p_train, p_test, p_target, p_target_test = train_test_split(health_pca, stroke_labels, test_size=0.2, random_state=0)\n",
    "print(p_train.shape)\n",
    "print(p_test.shape)\n",
    "print(p_target.shape)\n",
    "print(p_target_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balancing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imblearn\n",
      "  Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
      "Collecting imbalanced-learn\n",
      "  Downloading imbalanced_learn-0.8.0-py3-none-any.whl (206 kB)\n",
      "\u001b[K     |████████████████████████████████| 206 kB 6.5 MB/s eta 0:00:01     |█████████▌                      | 61 kB 9.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /Users/amanoberoi/opt/anaconda3/lib/python3.8/site-packages (from imbalanced-learn->imblearn) (1.20.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /Users/amanoberoi/opt/anaconda3/lib/python3.8/site-packages (from imbalanced-learn->imblearn) (1.6.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/amanoberoi/opt/anaconda3/lib/python3.8/site-packages (from imbalanced-learn->imblearn) (1.0.1)\n",
      "Requirement already satisfied: scikit-learn>=0.24 in /Users/amanoberoi/opt/anaconda3/lib/python3.8/site-packages (from imbalanced-learn->imblearn) (0.24.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/amanoberoi/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn>=0.24->imbalanced-learn->imblearn) (2.1.0)\n",
      "Installing collected packages: imbalanced-learn, imblearn\n",
      "Successfully installed imbalanced-learn-0.8.0 imblearn-0.0\n",
      "Collecting delayed\n",
      "  Downloading delayed-0.11.0b1-py2.py3-none-any.whl (19 kB)\n",
      "Collecting hiredis\n",
      "  Downloading hiredis-2.0.0-cp38-cp38-macosx_10_9_x86_64.whl (24 kB)\n",
      "Collecting redis\n",
      "  Downloading redis-3.5.3-py2.py3-none-any.whl (72 kB)\n",
      "\u001b[K     |████████████████████████████████| 72 kB 1.2 MB/s eta 0:00:011\n",
      "\u001b[?25hInstalling collected packages: redis, hiredis, delayed\n",
      "Successfully installed delayed-0.11.0b1 hiredis-2.0.0 redis-3.5.3\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install imblearn\n",
    "!{sys.executable} -m pip install delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5839, 8)\n",
      "(5839,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state = 33, sampling_strategy=0.5)\n",
    "\n",
    "X_train_new, y_train_new = sm.fit_resample(p_train, p_target.ravel())\n",
    "print(X_train_new.shape)\n",
    "print(y_train_new.shape)\n",
    "pd.Series(y_train_new).value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Classifier with KFold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True) \n",
    "\n",
    "model_1 = LogisticRegression(penalty='l2', max_iter=200, solver='sag')\n",
    "model_2 = LogisticRegression(penalty='l1', solver='liblinear')\n",
    "model_3 = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training models on non dimensionality reduced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy for model 1:  82.62230919765166\n",
      "Average accuracy for model 2:  82.91585127201566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amanoberoi/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/amanoberoi/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/amanoberoi/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy for model 3:  82.73972602739727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amanoberoi/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "labels_arr = stroke_labels\n",
    "\n",
    "sum1 = 0\n",
    "for train_index, test_index in kf.split(health_prepared):\n",
    "    X_train, X_test = health_prepared[train_index], health_prepared[test_index] \n",
    "    y_train, y_test = labels_arr[train_index], labels_arr[test_index]\n",
    "    X_train_new, y_train_new = sm.fit_resample(X_train, y_train.ravel())\n",
    "    model_1.fit(X_train_new, y_train_new)\n",
    "    preds = model_1.predict(X_test)\n",
    "    sum1 += accuracy_score(y_test, preds) * 100\n",
    "\n",
    "print(\"Average accuracy for model 1: \", (sum1/10))\n",
    "\n",
    "sum2 = 0\n",
    "for train_index, test_index in kf.split(health_prepared):\n",
    "    X_train, X_test = health_prepared[train_index], health_prepared[test_index] \n",
    "    y_train, y_test = labels_arr[train_index], labels_arr[test_index]\n",
    "    X_train_new, y_train_new = sm.fit_resample(X_train, y_train.ravel())\n",
    "    model_2.fit(X_train_new, y_train_new)\n",
    "    preds = model_2.predict(X_test)\n",
    "    sum2 += accuracy_score(y_test, preds) * 100\n",
    "\n",
    "print(\"Average accuracy for model 2: \", (sum2/10))\n",
    "\n",
    "sum3 = 0\n",
    "for train_index, test_index in kf.split(health_prepared):\n",
    "    X_train, X_test = health_prepared[train_index], health_prepared[test_index] \n",
    "    y_train, y_test = labels_arr[train_index], labels_arr[test_index]\n",
    "    X_train_new, y_train_new = sm.fit_resample(X_train, y_train.ravel())\n",
    "    model_3.fit(X_train_new, y_train_new)\n",
    "    preds = model_3.predict(X_test)\n",
    "    sum3 += accuracy_score(y_test, preds) * 100\n",
    "\n",
    "print(\"Average accuracy for model 3: \", (sum3/10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like both model 1 has the best accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training model on dimenstionality reduced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy for model 1:  83.17025440313111\n",
      "Average accuracy for model 2:  83.26810176125244\n",
      "Average accuracy for model 3:  83.18982387475538\n"
     ]
    }
   ],
   "source": [
    "labels_arr = stroke_labels\n",
    "\n",
    "sum1 = 0\n",
    "for train_index, test_index in kf.split(health_pca):\n",
    "    X_train, X_test = health_pca[train_index], health_pca[test_index] \n",
    "    y_train, y_test = labels_arr[train_index], labels_arr[test_index]\n",
    "    X_train_new, y_train_new = sm.fit_resample(X_train, y_train.ravel())\n",
    "    model_1.fit(X_train_new, y_train_new)\n",
    "    preds = model_1.predict(X_test)\n",
    "    sum1 += accuracy_score(y_test, preds) * 100\n",
    "\n",
    "print(\"Average accuracy for model 1: \", (sum1/10))\n",
    "\n",
    "sum2 = 0\n",
    "for train_index, test_index in kf.split(health_pca):\n",
    "    X_train, X_test = health_pca[train_index], health_pca[test_index] \n",
    "    y_train, y_test = labels_arr[train_index], labels_arr[test_index]\n",
    "    X_train_new, y_train_new = sm.fit_resample(X_train, y_train.ravel())\n",
    "    model_2.fit(X_train_new, y_train_new)\n",
    "    preds = model_2.predict(X_test)\n",
    "    sum2 += accuracy_score(y_test, preds) * 100\n",
    "\n",
    "print(\"Average accuracy for model 2: \", (sum2/10))\n",
    "\n",
    "sum3 = 0\n",
    "for train_index, test_index in kf.split(health_pca):\n",
    "    X_train, X_test = health_pca[train_index], health_pca[test_index] \n",
    "    y_train, y_test = labels_arr[train_index], labels_arr[test_index]\n",
    "    X_train_new, y_train_new = sm.fit_resample(X_train, y_train.ravel())\n",
    "    model_3.fit(X_train_new, y_train_new)\n",
    "    preds = model_3.predict(X_test)\n",
    "    sum3 += accuracy_score(y_test, preds) * 100\n",
    "\n",
    "print(\"Average accuracy for model 3: \", (sum3/10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treating on dimensionality reduced data produces slightly better accuracy for logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(penalty='l2', max_iter=200, solver='sag')\n",
    "#the model we pick after cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg.fit(X_train_new, y_train_new)\n",
    "predictions_lr = log_reg.predict(p_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression model (in %): 83.95303326810176\n",
      "Precision score: 0.17261904761904762\n",
      "Recall score: 0.5370370370370371\n",
      "F1 score: 0.26126126126126126\n",
      "Confusion matrix:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "import pylab as pl\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "acc = (accuracy_score(p_target_test, predictions_lr) * 100)\n",
    "print(\"Accuracy of logistic regression model (in %):\", acc)\n",
    "\n",
    "prec = precision_score(p_target_test, predictions_lr)\n",
    "print(\"Precision score:\", prec)\n",
    "\n",
    "recall = recall_score(p_target_test, predictions_lr)\n",
    "print(\"Recall score:\", recall)\n",
    "\n",
    "f1 = f1_score(p_target_test, predictions_lr)\n",
    "print(\"F1 score:\", f1)\n",
    "\n",
    "print(\"Confusion matrix:\")\n",
    "#cm = confusion_matrix(target_test, predictions_lr, labels=[0, 1])\n",
    "\n",
    "plot_confusion_matrix(log_reg, p_test, p_target_test)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression model with a lower threshold for predicting 1 to increase recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression model with lower threshold (in %): 80.43052837573386\n",
      "Precision score: 0.17410714285714285\n",
      "Recall score: 0.7222222222222222\n",
      "F1 score: 0.2805755395683453\n",
      "confusion matrix:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions_thres = log_reg.predict_proba(p_test)\n",
    "\n",
    "threshold = 0.4 \n",
    "preds = []\n",
    "for l in predictions_thres: #creating a predictions array based on the threshold\n",
    "    if(l[:1] > (1 -threshold)):\n",
    "        preds.append(0)\n",
    "    else:\n",
    "        preds.append(1)\n",
    "\n",
    "preds = np.asarray(preds)\n",
    "\n",
    "\n",
    "acc = (accuracy_score(p_target_test, preds) * 100)\n",
    "print(\"Accuracy of logistic regression model with lower threshold (in %):\", acc)\n",
    "\n",
    "prec = precision_score(p_target_test, preds)\n",
    "print(\"Precision score:\", prec)\n",
    "\n",
    "recall = recall_score(p_target_test, preds)\n",
    "print(\"Recall score:\", recall)\n",
    "\n",
    "f1 = f1_score(p_target_test, preds)\n",
    "print(\"F1 score:\", f1)\n",
    "\n",
    "\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "cm = confusion_matrix(p_target_test, preds, labels = [0, 1])\n",
    "print(\"confusion matrix:\")\n",
    "\n",
    "plot = sns.heatmap(cm, annot=True) # along the y axis are the true values, along the x axis are the predicted values\n",
    "plot.set(xlabel='Predicted Label', ylabel='Actual label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Classification Method with KFold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy for model 1:  89.72602739726028\n",
      "Average accuracy for model 2:  89.96086105675147\n",
      "Average accuracy for model 3:  89.33463796477494\n",
      "Average accuracy for model 4:  89.74559686888455\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model_1 = RandomForestClassifier(n_estimators=100, \n",
    "                               bootstrap = True,\n",
    "                               max_features = 'sqrt')\n",
    "model_2 = RandomForestClassifier(n_estimators=50, \n",
    "                               bootstrap = True,\n",
    "                               max_features = 'sqrt')\n",
    "model_3 = RandomForestClassifier(n_estimators=25, \n",
    "                               bootstrap = True,\n",
    "                               max_features = 'sqrt')\n",
    "model_4 = RandomForestClassifier(n_estimators=200, \n",
    "                               bootstrap = True,\n",
    "                               max_features = 'sqrt')\n",
    "\n",
    "sum1 = 0\n",
    "for train_index, test_index in kf.split(health_pca):\n",
    "    X_train, X_test = health_pca[train_index], health_pca[test_index] \n",
    "    y_train, y_test = labels_arr[train_index], labels_arr[test_index]\n",
    "    X_train_new, y_train_new = sm.fit_resample(X_train, y_train.ravel())\n",
    "    model_1.fit(X_train_new, y_train_new)\n",
    "    preds = model_1.predict(X_test)\n",
    "    sum1 += accuracy_score(y_test, preds) * 100\n",
    "\n",
    "print(\"Average accuracy for model 1: \", (sum1/10))\n",
    "\n",
    "sum2 = 0\n",
    "for train_index, test_index in kf.split(health_pca):\n",
    "    X_train, X_test = health_pca[train_index], health_pca[test_index] \n",
    "    y_train, y_test = labels_arr[train_index], labels_arr[test_index]\n",
    "    X_train_new, y_train_new = sm.fit_resample(X_train, y_train.ravel())\n",
    "    model_2.fit(X_train_new, y_train_new)\n",
    "    preds = model_2.predict(X_test)\n",
    "    sum2 += accuracy_score(y_test, preds) * 100\n",
    "\n",
    "print(\"Average accuracy for model 2: \", (sum2/10))\n",
    "\n",
    "sum3 = 0\n",
    "for train_index, test_index in kf.split(health_pca):\n",
    "    X_train, X_test = health_pca[train_index], health_pca[test_index] \n",
    "    y_train, y_test = labels_arr[train_index], labels_arr[test_index]\n",
    "    X_train_new, y_train_new = sm.fit_resample(X_train, y_train.ravel())\n",
    "    model_3.fit(X_train_new, y_train_new)\n",
    "    preds = model_3.predict(X_test)\n",
    "    sum3 += accuracy_score(y_test, preds) * 100\n",
    "\n",
    "print(\"Average accuracy for model 3: \", (sum3/10))\n",
    "\n",
    "sum4 = 0\n",
    "for train_index, test_index in kf.split(health_pca):\n",
    "    X_train, X_test = health_pca[train_index], health_pca[test_index] \n",
    "    y_train, y_test = labels_arr[train_index], labels_arr[test_index]\n",
    "    X_train_new, y_train_new = sm.fit_resample(X_train, y_train.ravel())\n",
    "    model_4.fit(X_train_new, y_train_new)\n",
    "    preds = model_4.predict(X_test)\n",
    "    sum4 += accuracy_score(y_test, preds) * 100\n",
    "\n",
    "print(\"Average accuracy for model 4: \", (sum4/10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = model_4\n",
    "X_train_new, y_train_new = sm.fit_resample(p_train, p_target.ravel())\n",
    "rf.fit(X_train_new, y_train_new)\n",
    "predictions_rf = rf.predict(p_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random forrest classifier model (in %): 89.92172211350294\n",
      "Precision score: 0.1111111111111111\n",
      "Recall score: 0.12962962962962962\n",
      "F1 score: 0.11965811965811965\n",
      "Confusion matrix:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = (accuracy_score(p_target_test, predictions_rf) * 100)\n",
    "print(\"Accuracy of random forrest classifier model (in %):\", acc)\n",
    "\n",
    "prec = precision_score(p_target_test, predictions_rf)\n",
    "print(\"Precision score:\", prec)\n",
    "\n",
    "recall = recall_score(p_target_test, predictions_rf)\n",
    "print(\"Recall score:\", recall)\n",
    "\n",
    "f1 = f1_score(p_target_test, predictions_rf)\n",
    "print(\"F1 score:\", f1)\n",
    "\n",
    "print(\"Confusion matrix:\")\n",
    "#cm = confusion_matrix(target_test, predictions_lr, labels=[0, 1])\n",
    "\n",
    "plot_confusion_matrix(rf, p_test, p_target_test)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Net Classifier with KFold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Downloading keras-2.6.0-py2.py3-none-any.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 7.4 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: keras\n",
      "Successfully installed keras-2.6.0\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.6.0-cp38-cp38-macosx_10_11_x86_64.whl (199.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 199.0 MB 10.3 MB/s eta 0:00:01    |██▊                             | 16.7 MB 12.3 MB/s eta 0:00:15     |██▊                             | 17.3 MB 12.3 MB/s eta 0:00:15     |████▍                           | 27.4 MB 9.5 MB/s eta 0:00:19     |██████▉                         | 42.7 MB 9.2 MB/s eta 0:00:17     |███████▍                        | 46.3 MB 9.4 MB/s eta 0:00:17  | 69.3 MB 480 kB/s eta 0:04:31     |██████████████████████▌         | 140.0 MB 11.1 MB/s eta 0:00:06     |███████████████████████████▏    | 169.2 MB 10.9 MB/s eta 0:00:03     |██████████████████████████████  | 187.2 MB 11.3 MB/s eta 0:00:02\n",
      "\u001b[?25hCollecting keras-preprocessing~=1.1.2\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 3.1 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wheel~=0.35 in /Users/amanoberoi/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.36.2)\n",
      "Collecting numpy~=1.19.2\n",
      "  Downloading numpy-1.19.5-cp38-cp38-macosx_10_9_x86_64.whl (15.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 15.6 MB 10.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting clang~=5.0\n",
      "  Downloading clang-5.0.tar.gz (30 kB)\n",
      "Collecting grpcio<2.0,>=1.37.0\n",
      "  Downloading grpcio-1.39.0-cp38-cp38-macosx_10_10_x86_64.whl (3.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.9 MB 12.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting h5py~=3.1.0\n",
      "  Downloading h5py-3.1.0-cp38-cp38-macosx_10_9_x86_64.whl (2.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.9 MB 14.1 MB/s eta 0:00:01     |█▋                              | 143 kB 14.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions~=3.7.4 in /Users/amanoberoi/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (3.7.4.3)\n",
      "Collecting gast==0.4.0\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: six~=1.15.0 in /Users/amanoberoi/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.15.0)\n",
      "Collecting google-pasta~=0.2\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 7.9 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: keras~=2.6 in /Users/amanoberoi/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.6.0)\n",
      "Collecting astunparse~=1.6.3\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting tensorflow-estimator~=2.6\n",
      "  Downloading tensorflow_estimator-2.6.0-py2.py3-none-any.whl (462 kB)\n",
      "\u001b[K     |████████████████████████████████| 462 kB 11.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard~=2.6\n",
      "  Downloading tensorboard-2.6.0-py3-none-any.whl (5.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.6 MB 10.9 MB/s eta 0:00:01     |███████████████████████████▍    | 4.7 MB 10.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting opt-einsum~=3.3.0\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 3.9 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting absl-py~=0.10\n",
      "  Downloading absl_py-0.13.0-py3-none-any.whl (132 kB)\n",
      "\u001b[K     |████████████████████████████████| 132 kB 12.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wrapt~=1.12.1 in /Users/amanoberoi/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.12.1)\n",
      "Collecting protobuf>=3.9.2\n",
      "  Downloading protobuf-3.17.3-cp38-cp38-macosx_10_9_x86_64.whl (1.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0 MB 10.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting termcolor~=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting flatbuffers~=1.12.0\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/amanoberoi/opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (52.0.0.post20210125)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.5-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/amanoberoi/opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (2.25.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Users/amanoberoi/opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (1.0.1)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n",
      "\u001b[K     |████████████████████████████████| 781 kB 9.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-macosx_10_9_x86_64.whl (3.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.5 MB 7.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.4-py3-none-any.whl (97 kB)\n",
      "\u001b[K     |████████████████████████████████| 97 kB 8.5 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting google-auth<2,>=1.6.3\n",
      "  Downloading google_auth-1.35.0-py2.py3-none-any.whl (152 kB)\n",
      "\u001b[K     |████████████████████████████████| 152 kB 12.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "\u001b[K     |████████████████████████████████| 155 kB 11.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.2-py3-none-any.whl (11 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.7.2-py3-none-any.whl (34 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "\u001b[K     |████████████████████████████████| 77 kB 7.5 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /Users/amanoberoi/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/amanoberoi/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/amanoberoi/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/amanoberoi/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.26.4)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.1-py2.py3-none-any.whl (146 kB)\n",
      "\u001b[K     |████████████████████████████████| 146 kB 10.5 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: clang, termcolor\n",
      "  Building wheel for clang (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for clang: filename=clang-5.0-py3-none-any.whl size=30702 sha256=0d7daa74694723730423183f8772851d64963ae2e7be283b399eccc094be2b27\n",
      "  Stored in directory: /Users/amanoberoi/Library/Caches/pip/wheels/f1/60/77/22b9b5887bd47801796a856f47650d9789c74dc3161a26d608\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4829 sha256=5e4b5ceb591eecab6d1f3e58565e1e65008408a1ee078bb091c5e859025b50e8\n",
      "  Stored in directory: /Users/amanoberoi/Library/Caches/pip/wheels/a0/16/9c/5473df82468f958445479c59e784896fa24f4a5fc024b0f501\n",
      "Successfully built clang termcolor\n",
      "Installing collected packages: pyasn1, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, tensorboard-plugin-wit, tensorboard-data-server, protobuf, numpy, markdown, grpcio, google-auth-oauthlib, absl-py, termcolor, tensorflow-estimator, tensorboard, opt-einsum, keras-preprocessing, h5py, google-pasta, gast, flatbuffers, clang, astunparse, tensorflow\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.20.1\n",
      "    Uninstalling numpy-1.20.1:\n",
      "      Successfully uninstalled numpy-1.20.1\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 2.10.0\n",
      "    Uninstalling h5py-2.10.0:\n",
      "      Successfully uninstalled h5py-2.10.0\n",
      "Successfully installed absl-py-0.13.0 astunparse-1.6.3 cachetools-4.2.2 clang-5.0 flatbuffers-1.12 gast-0.4.0 google-auth-1.35.0 google-auth-oauthlib-0.4.5 google-pasta-0.2.0 grpcio-1.39.0 h5py-3.1.0 keras-preprocessing-1.1.2 markdown-3.3.4 numpy-1.19.5 oauthlib-3.1.1 opt-einsum-3.3.0 protobuf-3.17.3 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 rsa-4.7.2 tensorboard-2.6.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.0 tensorflow-2.6.0 tensorflow-estimator-2.6.0 termcolor-1.1.0\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install keras\n",
    "!{sys.executable} -m pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.5222 - accuracy: 0.6943\n",
      "Epoch 2/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.4418 - accuracy: 0.7732\n",
      "Epoch 3/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.4268 - accuracy: 0.7849\n",
      "Epoch 4/150\n",
      "584/584 [==============================] - 1s 996us/step - loss: 0.4170 - accuracy: 0.7875\n",
      "Epoch 5/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.4088 - accuracy: 0.7907\n",
      "Epoch 6/150\n",
      "584/584 [==============================] - 1s 997us/step - loss: 0.4026 - accuracy: 0.7962\n",
      "Epoch 7/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3961 - accuracy: 0.7996\n",
      "Epoch 8/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3928 - accuracy: 0.8029\n",
      "Epoch 9/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3894 - accuracy: 0.8054\n",
      "Epoch 10/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3866 - accuracy: 0.8073\n",
      "Epoch 11/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3840 - accuracy: 0.8090\n",
      "Epoch 12/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3812 - accuracy: 0.8104\n",
      "Epoch 13/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3797 - accuracy: 0.8085\n",
      "Epoch 14/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3769 - accuracy: 0.8101\n",
      "Epoch 15/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3756 - accuracy: 0.8126\n",
      "Epoch 16/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3726 - accuracy: 0.8164\n",
      "Epoch 17/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3720 - accuracy: 0.8166\n",
      "Epoch 18/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3701 - accuracy: 0.8156\n",
      "Epoch 19/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3681 - accuracy: 0.8173: 0s - loss: 0.3646 - accura\n",
      "Epoch 20/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3663 - accuracy: 0.8203\n",
      "Epoch 21/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3651 - accuracy: 0.8209\n",
      "Epoch 22/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3635 - accuracy: 0.8226\n",
      "Epoch 23/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3618 - accuracy: 0.8207\n",
      "Epoch 24/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3599 - accuracy: 0.8243\n",
      "Epoch 25/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3591 - accuracy: 0.8214\n",
      "Epoch 26/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3578 - accuracy: 0.8239\n",
      "Epoch 27/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3564 - accuracy: 0.8277\n",
      "Epoch 28/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3554 - accuracy: 0.8277\n",
      "Epoch 29/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3539 - accuracy: 0.8251\n",
      "Epoch 30/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3529 - accuracy: 0.8289\n",
      "Epoch 31/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3519 - accuracy: 0.8296\n",
      "Epoch 32/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3504 - accuracy: 0.8303\n",
      "Epoch 33/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3498 - accuracy: 0.8296\n",
      "Epoch 34/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3483 - accuracy: 0.8305\n",
      "Epoch 35/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3471 - accuracy: 0.8347\n",
      "Epoch 36/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3456 - accuracy: 0.8366\n",
      "Epoch 37/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3450 - accuracy: 0.8366\n",
      "Epoch 38/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3436 - accuracy: 0.8366\n",
      "Epoch 39/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3425 - accuracy: 0.8392\n",
      "Epoch 40/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3424 - accuracy: 0.8352\n",
      "Epoch 41/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3408 - accuracy: 0.8380\n",
      "Epoch 42/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3406 - accuracy: 0.8399\n",
      "Epoch 43/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3404 - accuracy: 0.8390\n",
      "Epoch 44/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3391 - accuracy: 0.8399\n",
      "Epoch 45/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3397 - accuracy: 0.8378\n",
      "Epoch 46/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3377 - accuracy: 0.8430\n",
      "Epoch 47/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3371 - accuracy: 0.8424\n",
      "Epoch 48/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3365 - accuracy: 0.8407\n",
      "Epoch 49/150\n",
      "584/584 [==============================] - 1s 997us/step - loss: 0.3359 - accuracy: 0.8419\n",
      "Epoch 50/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3342 - accuracy: 0.8428\n",
      "Epoch 51/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3345 - accuracy: 0.8460\n",
      "Epoch 52/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3338 - accuracy: 0.8443: 0s - loss: 0.3374 \n",
      "Epoch 53/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3334 - accuracy: 0.8450\n",
      "Epoch 54/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3330 - accuracy: 0.8464\n",
      "Epoch 55/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3319 - accuracy: 0.8477: 0s - loss: 0.3268 - accura\n",
      "Epoch 56/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3312 - accuracy: 0.8498\n",
      "Epoch 57/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3308 - accuracy: 0.8454\n",
      "Epoch 58/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3299 - accuracy: 0.8469\n",
      "Epoch 59/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3303 - accuracy: 0.8479\n",
      "Epoch 60/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3282 - accuracy: 0.8498\n",
      "Epoch 61/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3288 - accuracy: 0.8467\n",
      "Epoch 62/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3273 - accuracy: 0.8481\n",
      "Epoch 63/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3275 - accuracy: 0.8476\n",
      "Epoch 64/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3267 - accuracy: 0.8484\n",
      "Epoch 65/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3259 - accuracy: 0.8522\n",
      "Epoch 66/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3244 - accuracy: 0.8519\n",
      "Epoch 67/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3255 - accuracy: 0.8460\n",
      "Epoch 68/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3242 - accuracy: 0.8507\n",
      "Epoch 69/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3230 - accuracy: 0.8527\n",
      "Epoch 70/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3230 - accuracy: 0.8543\n",
      "Epoch 71/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3223 - accuracy: 0.8508\n",
      "Epoch 72/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3225 - accuracy: 0.8522\n",
      "Epoch 73/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3221 - accuracy: 0.8515\n",
      "Epoch 74/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3210 - accuracy: 0.8534\n",
      "Epoch 75/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3205 - accuracy: 0.8524\n",
      "Epoch 76/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3195 - accuracy: 0.8510\n",
      "Epoch 77/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3197 - accuracy: 0.8558\n",
      "Epoch 78/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3185 - accuracy: 0.8561\n",
      "Epoch 79/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3180 - accuracy: 0.8549\n",
      "Epoch 80/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3189 - accuracy: 0.8548\n",
      "Epoch 81/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3177 - accuracy: 0.8541: 0s - loss: 0.3092 - accu\n",
      "Epoch 82/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3171 - accuracy: 0.8548\n",
      "Epoch 83/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3165 - accuracy: 0.8549\n",
      "Epoch 84/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3155 - accuracy: 0.8546\n",
      "Epoch 85/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3147 - accuracy: 0.8587\n",
      "Epoch 86/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3148 - accuracy: 0.8553\n",
      "Epoch 87/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3137 - accuracy: 0.8546\n",
      "Epoch 88/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3138 - accuracy: 0.8548\n",
      "Epoch 89/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3127 - accuracy: 0.8584\n",
      "Epoch 90/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3124 - accuracy: 0.8575\n",
      "Epoch 91/150\n",
      "584/584 [==============================] - 1s 996us/step - loss: 0.3119 - accuracy: 0.8594\n",
      "Epoch 92/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3115 - accuracy: 0.8561\n",
      "Epoch 93/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3104 - accuracy: 0.8582\n",
      "Epoch 94/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3110 - accuracy: 0.8563\n",
      "Epoch 95/150\n",
      "584/584 [==============================] - 1s 993us/step - loss: 0.3111 - accuracy: 0.8608\n",
      "Epoch 96/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3106 - accuracy: 0.8585\n",
      "Epoch 97/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3105 - accuracy: 0.8563\n",
      "Epoch 98/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3106 - accuracy: 0.8561\n",
      "Epoch 99/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3087 - accuracy: 0.8591\n",
      "Epoch 100/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3087 - accuracy: 0.8609\n",
      "Epoch 101/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3095 - accuracy: 0.8589\n",
      "Epoch 102/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3071 - accuracy: 0.8577\n",
      "Epoch 103/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3080 - accuracy: 0.8596\n",
      "Epoch 104/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3082 - accuracy: 0.8613\n",
      "Epoch 105/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3075 - accuracy: 0.8606\n",
      "Epoch 106/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3073 - accuracy: 0.8585\n",
      "Epoch 107/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3073 - accuracy: 0.8584\n",
      "Epoch 108/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3069 - accuracy: 0.8591\n",
      "Epoch 109/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3063 - accuracy: 0.8587\n",
      "Epoch 110/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3057 - accuracy: 0.8570\n",
      "Epoch 111/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3064 - accuracy: 0.8620\n",
      "Epoch 112/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3053 - accuracy: 0.8609\n",
      "Epoch 113/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3054 - accuracy: 0.8604\n",
      "Epoch 114/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3053 - accuracy: 0.8565\n",
      "Epoch 115/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3051 - accuracy: 0.8599\n",
      "Epoch 116/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3046 - accuracy: 0.8568\n",
      "Epoch 117/150\n",
      "584/584 [==============================] - 1s 989us/step - loss: 0.3038 - accuracy: 0.8565\n",
      "Epoch 118/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3033 - accuracy: 0.8616\n",
      "Epoch 119/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3025 - accuracy: 0.8613\n",
      "Epoch 120/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3041 - accuracy: 0.8575\n",
      "Epoch 121/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3019 - accuracy: 0.8616\n",
      "Epoch 122/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3033 - accuracy: 0.8594\n",
      "Epoch 123/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3011 - accuracy: 0.8594\n",
      "Epoch 124/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3016 - accuracy: 0.8618\n",
      "Epoch 125/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3013 - accuracy: 0.8620\n",
      "Epoch 126/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3011 - accuracy: 0.8585\n",
      "Epoch 127/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3006 - accuracy: 0.8614\n",
      "Epoch 128/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3009 - accuracy: 0.8606\n",
      "Epoch 129/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3007 - accuracy: 0.8616\n",
      "Epoch 130/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3010 - accuracy: 0.8613\n",
      "Epoch 131/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3006 - accuracy: 0.8614\n",
      "Epoch 132/150\n",
      "584/584 [==============================] - 1s 996us/step - loss: 0.3000 - accuracy: 0.8608\n",
      "Epoch 133/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.2995 - accuracy: 0.8630\n",
      "Epoch 134/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3000 - accuracy: 0.8604\n",
      "Epoch 135/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.2990 - accuracy: 0.8603\n",
      "Epoch 136/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.2995 - accuracy: 0.8609\n",
      "Epoch 137/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.2992 - accuracy: 0.8611\n",
      "Epoch 138/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.2998 - accuracy: 0.8611\n",
      "Epoch 139/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.2987 - accuracy: 0.8640\n",
      "Epoch 140/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.2986 - accuracy: 0.8603\n",
      "Epoch 141/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.2984 - accuracy: 0.8608: 0s - loss: 0.2976 - accuracy: 0.86\n",
      "Epoch 142/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.2990 - accuracy: 0.8604\n",
      "Epoch 143/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.2981 - accuracy: 0.8611\n",
      "Epoch 144/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.2981 - accuracy: 0.8591\n",
      "Epoch 145/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.2975 - accuracy: 0.8616\n",
      "Epoch 146/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.2974 - accuracy: 0.8609\n",
      "Epoch 147/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.2981 - accuracy: 0.8596\n",
      "Epoch 148/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.2965 - accuracy: 0.8633\n",
      "Epoch 149/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.2966 - accuracy: 0.8640\n",
      "Epoch 150/150\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.2961 - accuracy: 0.8626\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train_new, y_train_new, epochs=150, batch_size=10)\n",
    "\n",
    "predictions_nn = model.predict(p_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like our models accuracy plateaud after epoch 55 and any further training will lead to a waste of computer resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of neural network model (in %): 82.28962818003914\n",
      "Precision score: 0.11976047904191617\n",
      "Recall score: 0.37037037037037035\n",
      "F1 score: 0.18099547511312217\n",
      "Confusion matrix:\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.5\n",
    "predictions_nn = np.where(predictions_nn > threshold, 1, 0)\n",
    "\n",
    "acc = (accuracy_score(p_target_test, predictions_nn) * 100)\n",
    "print(\"Accuracy of neural network model (in %):\", acc)\n",
    "\n",
    "prec = precision_score(p_target_test, predictions_nn)\n",
    "print(\"Precision score:\", prec)\n",
    "\n",
    "recall = recall_score(p_target_test, predictions_nn)\n",
    "print(\"Recall score:\", recall)\n",
    "\n",
    "f1 = f1_score(p_target_test, predictions_nn)\n",
    "print(\"F1 score:\", f1)\n",
    "\n",
    "print(\"Confusion matrix:\")\n",
    "#cm = confusion_matrix(target_test, predictions_lr, labels=[0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation with different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = Sequential()\n",
    "model_1.add(Dense(8, input_dim=8, activation='relu'))\n",
    "model_1.add(Dense(8, activation='relu'))\n",
    "model_1.add(Dense(1, activation='sigmoid'))\n",
    "model_1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model_2 = Sequential()\n",
    "model_2.add(Dense(8, input_dim=8, activation='relu'))\n",
    "model_2.add(Dense(10, activation='sigmoid'))\n",
    "model_2.add(Dense(1, activation='sigmoid'))\n",
    "model_2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model_3 = Sequential()\n",
    "model_3.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model_3.add(Dense(20, activation='relu'))\n",
    "model_3.add(Dense(1, activation='sigmoid'))\n",
    "model_3.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "132/132 [==============================] - 1s 1ms/step - loss: 0.6462 - accuracy: 0.6191\n",
      "Epoch 2/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.5329 - accuracy: 0.6947\n",
      "Epoch 3/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4919 - accuracy: 0.7377\n",
      "Epoch 4/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4697 - accuracy: 0.7524\n",
      "Epoch 5/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4569 - accuracy: 0.7651\n",
      "Epoch 6/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4496 - accuracy: 0.7763\n",
      "Epoch 7/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4455 - accuracy: 0.7788\n",
      "Epoch 8/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4425 - accuracy: 0.7805\n",
      "Epoch 9/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4404 - accuracy: 0.7826\n",
      "Epoch 10/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4386 - accuracy: 0.7818\n",
      "Epoch 11/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4371 - accuracy: 0.7832\n",
      "Epoch 12/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4356 - accuracy: 0.7852\n",
      "Epoch 13/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4342 - accuracy: 0.7864\n",
      "Epoch 14/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4326 - accuracy: 0.7873\n",
      "Epoch 15/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4314 - accuracy: 0.7891\n",
      "Epoch 16/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4306 - accuracy: 0.7922\n",
      "Epoch 17/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4295 - accuracy: 0.7873\n",
      "Epoch 18/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4287 - accuracy: 0.7926\n",
      "Epoch 19/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.7932\n",
      "Epoch 20/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4270 - accuracy: 0.7919\n",
      "Epoch 21/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4261 - accuracy: 0.7938\n",
      "Epoch 22/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4258 - accuracy: 0.7928\n",
      "Epoch 23/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4249 - accuracy: 0.7958\n",
      "Epoch 24/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4242 - accuracy: 0.7969\n",
      "Epoch 25/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4232 - accuracy: 0.7938\n",
      "Epoch 26/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4225 - accuracy: 0.7958\n",
      "Epoch 27/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4215 - accuracy: 0.7981\n",
      "Epoch 28/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4204 - accuracy: 0.7955\n",
      "Epoch 29/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4194 - accuracy: 0.7986\n",
      "Epoch 30/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4192 - accuracy: 0.7949\n",
      "Epoch 31/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4185 - accuracy: 0.7978\n",
      "Epoch 32/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.4177 - accuracy: 0.7975\n",
      "Epoch 33/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4171 - accuracy: 0.7952\n",
      "Epoch 34/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4161 - accuracy: 0.7978\n",
      "Epoch 35/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.4154 - accuracy: 0.7987\n",
      "Epoch 36/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4149 - accuracy: 0.7960\n",
      "Epoch 37/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4137 - accuracy: 0.8001\n",
      "Epoch 38/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4132 - accuracy: 0.7961\n",
      "Epoch 39/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.4119 - accuracy: 0.7993\n",
      "Epoch 40/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.4113 - accuracy: 0.7986\n",
      "Epoch 41/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4104 - accuracy: 0.7974\n",
      "Epoch 42/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4100 - accuracy: 0.7974\n",
      "Epoch 43/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4090 - accuracy: 0.7990\n",
      "Epoch 44/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4080 - accuracy: 0.7974\n",
      "Epoch 45/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4083 - accuracy: 0.8005\n",
      "Epoch 46/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4067 - accuracy: 0.7999\n",
      "Epoch 47/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4065 - accuracy: 0.8004\n",
      "Epoch 48/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.4054 - accuracy: 0.8013\n",
      "Epoch 49/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4048 - accuracy: 0.8012\n",
      "Epoch 50/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4040 - accuracy: 0.8013\n",
      "Epoch 1/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4209 - accuracy: 0.7917\n",
      "Epoch 2/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4187 - accuracy: 0.7904\n",
      "Epoch 3/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4175 - accuracy: 0.7927\n",
      "Epoch 4/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4161 - accuracy: 0.7939\n",
      "Epoch 5/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4149 - accuracy: 0.7939\n",
      "Epoch 6/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4146 - accuracy: 0.7960\n",
      "Epoch 7/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4136 - accuracy: 0.7943\n",
      "Epoch 8/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4129 - accuracy: 0.7960\n",
      "Epoch 9/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4126 - accuracy: 0.7968\n",
      "Epoch 10/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4122 - accuracy: 0.7974\n",
      "Epoch 11/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4117 - accuracy: 0.7962\n",
      "Epoch 12/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4110 - accuracy: 0.7959\n",
      "Epoch 13/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4105 - accuracy: 0.7988\n",
      "Epoch 14/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4098 - accuracy: 0.7983\n",
      "Epoch 15/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4093 - accuracy: 0.7966\n",
      "Epoch 16/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4088 - accuracy: 0.8001\n",
      "Epoch 17/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4082 - accuracy: 0.7994\n",
      "Epoch 18/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.4076 - accuracy: 0.7969\n",
      "Epoch 19/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4070 - accuracy: 0.7983\n",
      "Epoch 20/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4064 - accuracy: 0.8016\n",
      "Epoch 21/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4059 - accuracy: 0.8009\n",
      "Epoch 22/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4059 - accuracy: 0.8009\n",
      "Epoch 23/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4057 - accuracy: 0.8007\n",
      "Epoch 24/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4051 - accuracy: 0.8026\n",
      "Epoch 25/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4046 - accuracy: 0.8027\n",
      "Epoch 26/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4043 - accuracy: 0.8013\n",
      "Epoch 27/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4039 - accuracy: 0.8029\n",
      "Epoch 28/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4035 - accuracy: 0.8029\n",
      "Epoch 29/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4032 - accuracy: 0.8027\n",
      "Epoch 30/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4025 - accuracy: 0.8064\n",
      "Epoch 31/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4020 - accuracy: 0.8061\n",
      "Epoch 32/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4018 - accuracy: 0.8053\n",
      "Epoch 33/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4025 - accuracy: 0.8048\n",
      "Epoch 34/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4015 - accuracy: 0.8042\n",
      "Epoch 35/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4015 - accuracy: 0.8010\n",
      "Epoch 36/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4007 - accuracy: 0.8036\n",
      "Epoch 37/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4008 - accuracy: 0.8032\n",
      "Epoch 38/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4003 - accuracy: 0.8051\n",
      "Epoch 39/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4002 - accuracy: 0.8036\n",
      "Epoch 40/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3998 - accuracy: 0.8047\n",
      "Epoch 41/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3996 - accuracy: 0.8041\n",
      "Epoch 42/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.3995 - accuracy: 0.8055\n",
      "Epoch 43/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3994 - accuracy: 0.8042\n",
      "Epoch 44/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3993 - accuracy: 0.8042\n",
      "Epoch 45/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3992 - accuracy: 0.8041\n",
      "Epoch 46/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3994 - accuracy: 0.8053\n",
      "Epoch 47/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3987 - accuracy: 0.8039\n",
      "Epoch 48/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3979 - accuracy: 0.8062\n",
      "Epoch 49/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3981 - accuracy: 0.8015\n",
      "Epoch 50/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3977 - accuracy: 0.8062\n",
      "Epoch 1/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 0.3981 - accuracy: 0.7991\n",
      "Epoch 2/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 0.3967 - accuracy: 0.8013\n",
      "Epoch 3/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 0.3956 - accuracy: 0.8013\n",
      "Epoch 4/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 0.3955 - accuracy: 0.8038\n",
      "Epoch 5/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 0.3950 - accuracy: 0.8021\n",
      "Epoch 6/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 0.3954 - accuracy: 0.8044\n",
      "Epoch 7/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 0.3938 - accuracy: 0.8035\n",
      "Epoch 8/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 0.3943 - accuracy: 0.8032\n",
      "Epoch 9/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 0.3932 - accuracy: 0.8035\n",
      "Epoch 10/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 0.3929 - accuracy: 0.8056\n",
      "Epoch 11/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 0.3924 - accuracy: 0.8052\n",
      "Epoch 12/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 0.3921 - accuracy: 0.8053\n",
      "Epoch 13/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 0.3918 - accuracy: 0.8055\n",
      "Epoch 14/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 0.3912 - accuracy: 0.8036\n",
      "Epoch 15/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 0.3907 - accuracy: 0.8059\n",
      "Epoch 16/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 0.3904 - accuracy: 0.8055\n",
      "Epoch 17/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 0.3895 - accuracy: 0.8015\n",
      "Epoch 18/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 0.3899 - accuracy: 0.8050\n",
      "Epoch 19/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 0.3894 - accuracy: 0.8073\n",
      "Epoch 20/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 0.3898 - accuracy: 0.8056\n",
      "Epoch 21/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 0.3885 - accuracy: 0.8053\n",
      "Epoch 22/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 0.3887 - accuracy: 0.8070\n",
      "Epoch 23/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 0.3885 - accuracy: 0.8049\n",
      "Epoch 24/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 0.3887 - accuracy: 0.8052\n",
      "Epoch 25/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 0.3878 - accuracy: 0.8026\n",
      "Epoch 26/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 0.3879 - accuracy: 0.8013\n",
      "Epoch 27/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 0.3875 - accuracy: 0.8062\n",
      "Epoch 28/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 0.3875 - accuracy: 0.8059\n",
      "Epoch 29/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 0.3869 - accuracy: 0.8090\n",
      "Epoch 30/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 0.3869 - accuracy: 0.8055\n",
      "Epoch 31/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 0.3859 - accuracy: 0.8041\n",
      "Epoch 32/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 0.3871 - accuracy: 0.8055\n",
      "Epoch 33/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 0.3867 - accuracy: 0.8041\n",
      "Epoch 34/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 0.3860 - accuracy: 0.8050\n",
      "Epoch 35/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 0.3860 - accuracy: 0.8061\n",
      "Epoch 36/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 0.3859 - accuracy: 0.8075\n",
      "Epoch 37/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 0.3863 - accuracy: 0.8055\n",
      "Epoch 38/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 0.3856 - accuracy: 0.8059\n",
      "Epoch 39/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 0.3857 - accuracy: 0.8058\n",
      "Epoch 40/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 0.3849 - accuracy: 0.8059\n",
      "Epoch 41/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 0.3846 - accuracy: 0.8091\n",
      "Epoch 42/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 0.3848 - accuracy: 0.8055\n",
      "Epoch 43/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 0.3841 - accuracy: 0.8061\n",
      "Epoch 44/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 0.3845 - accuracy: 0.8076\n",
      "Epoch 45/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 0.3847 - accuracy: 0.8056\n",
      "Epoch 46/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 0.3837 - accuracy: 0.8072\n",
      "Epoch 47/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 0.3843 - accuracy: 0.8030\n",
      "Epoch 48/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 0.3836 - accuracy: 0.8055\n",
      "Epoch 49/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 0.3834 - accuracy: 0.8064\n",
      "Epoch 50/50\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 0.3838 - accuracy: 0.8027\n",
      "Epoch 1/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3821 - accuracy: 0.8103\n",
      "Epoch 2/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3796 - accuracy: 0.8133\n",
      "Epoch 3/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3782 - accuracy: 0.8155\n",
      "Epoch 4/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3775 - accuracy: 0.8150\n",
      "Epoch 5/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3768 - accuracy: 0.8180\n",
      "Epoch 6/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3758 - accuracy: 0.8205\n",
      "Epoch 7/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3754 - accuracy: 0.8167\n",
      "Epoch 8/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3753 - accuracy: 0.8180\n",
      "Epoch 9/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3744 - accuracy: 0.8190\n",
      "Epoch 10/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3739 - accuracy: 0.8194\n",
      "Epoch 11/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3741 - accuracy: 0.8191\n",
      "Epoch 12/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3738 - accuracy: 0.8191\n",
      "Epoch 13/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3725 - accuracy: 0.8188\n",
      "Epoch 14/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3727 - accuracy: 0.8209\n",
      "Epoch 15/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3727 - accuracy: 0.8217\n",
      "Epoch 16/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3717 - accuracy: 0.8208\n",
      "Epoch 17/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3719 - accuracy: 0.8197\n",
      "Epoch 18/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3718 - accuracy: 0.8206\n",
      "Epoch 19/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3709 - accuracy: 0.8217\n",
      "Epoch 20/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3707 - accuracy: 0.8194\n",
      "Epoch 21/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3705 - accuracy: 0.8190\n",
      "Epoch 22/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3698 - accuracy: 0.8205\n",
      "Epoch 23/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3703 - accuracy: 0.8238\n",
      "Epoch 24/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3691 - accuracy: 0.8197\n",
      "Epoch 25/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3697 - accuracy: 0.8214\n",
      "Epoch 26/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3690 - accuracy: 0.8225\n",
      "Epoch 27/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3690 - accuracy: 0.8237\n",
      "Epoch 28/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3684 - accuracy: 0.8246\n",
      "Epoch 29/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3679 - accuracy: 0.8211\n",
      "Epoch 30/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3674 - accuracy: 0.8240\n",
      "Epoch 31/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3677 - accuracy: 0.8234\n",
      "Epoch 32/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3672 - accuracy: 0.8241\n",
      "Epoch 33/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3671 - accuracy: 0.8260\n",
      "Epoch 34/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3665 - accuracy: 0.8237\n",
      "Epoch 35/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3662 - accuracy: 0.8266\n",
      "Epoch 36/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3657 - accuracy: 0.8264\n",
      "Epoch 37/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3654 - accuracy: 0.8260\n",
      "Epoch 38/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3660 - accuracy: 0.8240\n",
      "Epoch 39/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3652 - accuracy: 0.8286\n",
      "Epoch 40/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3652 - accuracy: 0.8264: 0s - loss: 0.3671 - accuracy: \n",
      "Epoch 41/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3649 - accuracy: 0.8287\n",
      "Epoch 42/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3654 - accuracy: 0.8272\n",
      "Epoch 43/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3646 - accuracy: 0.8290\n",
      "Epoch 44/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3645 - accuracy: 0.8272\n",
      "Epoch 45/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3640 - accuracy: 0.8290\n",
      "Epoch 46/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3637 - accuracy: 0.8283\n",
      "Epoch 47/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3632 - accuracy: 0.8289\n",
      "Epoch 48/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3637 - accuracy: 0.8284\n",
      "Epoch 49/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3624 - accuracy: 0.8289\n",
      "Epoch 50/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3623 - accuracy: 0.8327\n",
      "Epoch 1/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3836 - accuracy: 0.8182\n",
      "Epoch 2/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3801 - accuracy: 0.8184\n",
      "Epoch 3/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3797 - accuracy: 0.8184\n",
      "Epoch 4/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3789 - accuracy: 0.8193\n",
      "Epoch 5/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3782 - accuracy: 0.8196\n",
      "Epoch 6/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3779 - accuracy: 0.8176\n",
      "Epoch 7/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3765 - accuracy: 0.8199\n",
      "Epoch 8/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3769 - accuracy: 0.8202\n",
      "Epoch 9/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3761 - accuracy: 0.8193\n",
      "Epoch 10/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3757 - accuracy: 0.8181\n",
      "Epoch 11/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3748 - accuracy: 0.8192\n",
      "Epoch 12/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3745 - accuracy: 0.8201\n",
      "Epoch 13/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3741 - accuracy: 0.8192\n",
      "Epoch 14/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3742 - accuracy: 0.8184\n",
      "Epoch 15/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3741 - accuracy: 0.8173\n",
      "Epoch 16/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3735 - accuracy: 0.8185\n",
      "Epoch 17/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3734 - accuracy: 0.8178\n",
      "Epoch 18/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3735 - accuracy: 0.8208\n",
      "Epoch 19/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3735 - accuracy: 0.8182\n",
      "Epoch 20/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3732 - accuracy: 0.8181\n",
      "Epoch 21/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3736 - accuracy: 0.8185\n",
      "Epoch 22/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3731 - accuracy: 0.8201\n",
      "Epoch 23/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3722 - accuracy: 0.8192\n",
      "Epoch 24/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3721 - accuracy: 0.8202\n",
      "Epoch 25/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3715 - accuracy: 0.8164\n",
      "Epoch 26/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3718 - accuracy: 0.8163\n",
      "Epoch 27/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3711 - accuracy: 0.8202\n",
      "Epoch 28/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3721 - accuracy: 0.8188\n",
      "Epoch 29/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3713 - accuracy: 0.8181\n",
      "Epoch 30/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3708 - accuracy: 0.8198\n",
      "Epoch 31/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3707 - accuracy: 0.8187\n",
      "Epoch 32/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3713 - accuracy: 0.8195\n",
      "Epoch 33/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3711 - accuracy: 0.8176\n",
      "Epoch 34/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3715 - accuracy: 0.8190\n",
      "Epoch 35/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3713 - accuracy: 0.8199\n",
      "Epoch 36/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3704 - accuracy: 0.8198\n",
      "Epoch 37/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3702 - accuracy: 0.8187\n",
      "Epoch 38/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3705 - accuracy: 0.8187\n",
      "Epoch 39/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3709 - accuracy: 0.8207\n",
      "Epoch 40/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3694 - accuracy: 0.8187\n",
      "Epoch 41/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3698 - accuracy: 0.8210\n",
      "Epoch 42/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3697 - accuracy: 0.8169\n",
      "Epoch 43/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3696 - accuracy: 0.8175\n",
      "Epoch 44/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3695 - accuracy: 0.8198\n",
      "Epoch 45/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3694 - accuracy: 0.8187\n",
      "Epoch 46/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3689 - accuracy: 0.8193\n",
      "Epoch 47/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3690 - accuracy: 0.8193\n",
      "Epoch 48/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3681 - accuracy: 0.8220\n",
      "Epoch 49/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3681 - accuracy: 0.8184\n",
      "Epoch 50/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3685 - accuracy: 0.8190\n",
      "Epoch 1/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3786 - accuracy: 0.8186\n",
      "Epoch 2/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3761 - accuracy: 0.8183\n",
      "Epoch 3/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3756 - accuracy: 0.8156\n",
      "Epoch 4/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3736 - accuracy: 0.8200\n",
      "Epoch 5/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3734 - accuracy: 0.8178\n",
      "Epoch 6/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3727 - accuracy: 0.8194\n",
      "Epoch 7/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3722 - accuracy: 0.8201\n",
      "Epoch 8/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3727 - accuracy: 0.8184\n",
      "Epoch 9/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3705 - accuracy: 0.8187\n",
      "Epoch 10/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3703 - accuracy: 0.8194\n",
      "Epoch 11/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3700 - accuracy: 0.8178\n",
      "Epoch 12/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3694 - accuracy: 0.8184\n",
      "Epoch 13/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3691 - accuracy: 0.8197\n",
      "Epoch 14/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3687 - accuracy: 0.8209\n",
      "Epoch 15/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3685 - accuracy: 0.8191\n",
      "Epoch 16/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3681 - accuracy: 0.8200\n",
      "Epoch 17/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3680 - accuracy: 0.8186\n",
      "Epoch 18/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3683 - accuracy: 0.8222\n",
      "Epoch 19/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3676 - accuracy: 0.8180\n",
      "Epoch 20/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3681 - accuracy: 0.8195\n",
      "Epoch 21/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3667 - accuracy: 0.8201\n",
      "Epoch 22/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3672 - accuracy: 0.8204\n",
      "Epoch 23/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3666 - accuracy: 0.8207\n",
      "Epoch 24/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3671 - accuracy: 0.8194\n",
      "Epoch 25/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3666 - accuracy: 0.8203\n",
      "Epoch 26/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3663 - accuracy: 0.8187\n",
      "Epoch 27/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3667 - accuracy: 0.8200\n",
      "Epoch 28/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3663 - accuracy: 0.8213\n",
      "Epoch 29/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3657 - accuracy: 0.8210\n",
      "Epoch 30/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3659 - accuracy: 0.8180\n",
      "Epoch 31/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3658 - accuracy: 0.8187\n",
      "Epoch 32/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3661 - accuracy: 0.8183\n",
      "Epoch 33/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3653 - accuracy: 0.8216\n",
      "Epoch 34/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3654 - accuracy: 0.8177\n",
      "Epoch 35/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3649 - accuracy: 0.8178\n",
      "Epoch 36/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3646 - accuracy: 0.8203\n",
      "Epoch 37/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3648 - accuracy: 0.8192\n",
      "Epoch 38/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3643 - accuracy: 0.8200\n",
      "Epoch 39/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3643 - accuracy: 0.8219\n",
      "Epoch 40/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3637 - accuracy: 0.8204\n",
      "Epoch 41/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3639 - accuracy: 0.8216\n",
      "Epoch 42/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3645 - accuracy: 0.8201\n",
      "Epoch 43/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3640 - accuracy: 0.8215\n",
      "Epoch 44/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3637 - accuracy: 0.8215\n",
      "Epoch 45/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3632 - accuracy: 0.8183\n",
      "Epoch 46/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3631 - accuracy: 0.8218\n",
      "Epoch 47/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3633 - accuracy: 0.8191\n",
      "Epoch 48/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3623 - accuracy: 0.8192\n",
      "Epoch 49/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3624 - accuracy: 0.8219\n",
      "Epoch 50/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3628 - accuracy: 0.8216\n",
      "Epoch 1/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3727 - accuracy: 0.8195\n",
      "Epoch 2/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3672 - accuracy: 0.8232\n",
      "Epoch 3/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3652 - accuracy: 0.8228\n",
      "Epoch 4/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3640 - accuracy: 0.8264\n",
      "Epoch 5/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3629 - accuracy: 0.8251\n",
      "Epoch 6/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3623 - accuracy: 0.8257\n",
      "Epoch 7/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3616 - accuracy: 0.8250\n",
      "Epoch 8/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3611 - accuracy: 0.8242\n",
      "Epoch 9/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3613 - accuracy: 0.8277\n",
      "Epoch 10/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3603 - accuracy: 0.8256\n",
      "Epoch 11/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3602 - accuracy: 0.8260\n",
      "Epoch 12/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3603 - accuracy: 0.8247\n",
      "Epoch 13/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3603 - accuracy: 0.8268\n",
      "Epoch 14/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3595 - accuracy: 0.8238\n",
      "Epoch 15/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3593 - accuracy: 0.8264\n",
      "Epoch 16/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3583 - accuracy: 0.8265\n",
      "Epoch 17/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3598 - accuracy: 0.8267\n",
      "Epoch 18/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3587 - accuracy: 0.8264\n",
      "Epoch 19/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3586 - accuracy: 0.8262\n",
      "Epoch 20/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3585 - accuracy: 0.8241\n",
      "Epoch 21/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3581 - accuracy: 0.8279\n",
      "Epoch 22/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3583 - accuracy: 0.8251\n",
      "Epoch 23/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3578 - accuracy: 0.8247\n",
      "Epoch 24/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3578 - accuracy: 0.8271\n",
      "Epoch 25/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3575 - accuracy: 0.8259\n",
      "Epoch 26/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3574 - accuracy: 0.8271\n",
      "Epoch 27/50\n",
      "132/132 [==============================] - 0s 992us/step - loss: 0.3572 - accuracy: 0.8251\n",
      "Epoch 28/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3574 - accuracy: 0.8247\n",
      "Epoch 29/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3567 - accuracy: 0.8271\n",
      "Epoch 30/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3573 - accuracy: 0.8264\n",
      "Epoch 31/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3566 - accuracy: 0.8248\n",
      "Epoch 32/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3568 - accuracy: 0.8262\n",
      "Epoch 33/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3569 - accuracy: 0.8253\n",
      "Epoch 34/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3556 - accuracy: 0.8267\n",
      "Epoch 35/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3556 - accuracy: 0.8274\n",
      "Epoch 36/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3563 - accuracy: 0.8253\n",
      "Epoch 37/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3551 - accuracy: 0.8260\n",
      "Epoch 38/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3555 - accuracy: 0.8280\n",
      "Epoch 39/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3559 - accuracy: 0.8262\n",
      "Epoch 40/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3546 - accuracy: 0.8268\n",
      "Epoch 41/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3552 - accuracy: 0.8264\n",
      "Epoch 42/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3554 - accuracy: 0.8257\n",
      "Epoch 43/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3541 - accuracy: 0.8257\n",
      "Epoch 44/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3546 - accuracy: 0.8283\n",
      "Epoch 45/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3549 - accuracy: 0.8265\n",
      "Epoch 46/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3542 - accuracy: 0.8273\n",
      "Epoch 47/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3537 - accuracy: 0.8273\n",
      "Epoch 48/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3554 - accuracy: 0.8232\n",
      "Epoch 49/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3539 - accuracy: 0.8274\n",
      "Epoch 50/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3541 - accuracy: 0.8276\n",
      "Epoch 1/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3728 - accuracy: 0.8151\n",
      "Epoch 2/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3683 - accuracy: 0.8180\n",
      "Epoch 3/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3665 - accuracy: 0.8180\n",
      "Epoch 4/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3652 - accuracy: 0.8166\n",
      "Epoch 5/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.3645 - accuracy: 0.8187\n",
      "Epoch 6/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3633 - accuracy: 0.8169\n",
      "Epoch 7/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3636 - accuracy: 0.8202\n",
      "Epoch 8/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3636 - accuracy: 0.8178\n",
      "Epoch 9/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3614 - accuracy: 0.8206\n",
      "Epoch 10/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3624 - accuracy: 0.8209\n",
      "Epoch 11/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3614 - accuracy: 0.8218\n",
      "Epoch 12/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3610 - accuracy: 0.8216\n",
      "Epoch 13/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3606 - accuracy: 0.8207\n",
      "Epoch 14/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3606 - accuracy: 0.8209\n",
      "Epoch 15/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3603 - accuracy: 0.8225\n",
      "Epoch 16/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3590 - accuracy: 0.8199\n",
      "Epoch 17/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3591 - accuracy: 0.8228\n",
      "Epoch 18/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3583 - accuracy: 0.8224\n",
      "Epoch 19/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3586 - accuracy: 0.8221\n",
      "Epoch 20/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3585 - accuracy: 0.8227\n",
      "Epoch 21/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3586 - accuracy: 0.8239\n",
      "Epoch 22/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3580 - accuracy: 0.8224\n",
      "Epoch 23/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3575 - accuracy: 0.8239\n",
      "Epoch 24/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3569 - accuracy: 0.8247\n",
      "Epoch 25/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3576 - accuracy: 0.8224\n",
      "Epoch 26/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3571 - accuracy: 0.8239\n",
      "Epoch 27/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3572 - accuracy: 0.8260\n",
      "Epoch 28/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3569 - accuracy: 0.8257\n",
      "Epoch 29/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.3562 - accuracy: 0.8227\n",
      "Epoch 30/50\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.3562 - accuracy: 0.8270\n",
      "Epoch 31/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.3563 - accuracy: 0.8250\n",
      "Epoch 32/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.3555 - accuracy: 0.8259\n",
      "Epoch 33/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.3558 - accuracy: 0.8241\n",
      "Epoch 34/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3560 - accuracy: 0.8257\n",
      "Epoch 35/50\n",
      "132/132 [==============================] - 0s 963us/step - loss: 0.3554 - accuracy: 0.8260\n",
      "Epoch 36/50\n",
      "132/132 [==============================] - 0s 952us/step - loss: 0.3555 - accuracy: 0.8247\n",
      "Epoch 37/50\n",
      "132/132 [==============================] - 0s 967us/step - loss: 0.3551 - accuracy: 0.8251\n",
      "Epoch 38/50\n",
      "132/132 [==============================] - 0s 948us/step - loss: 0.3547 - accuracy: 0.8265\n",
      "Epoch 39/50\n",
      "132/132 [==============================] - 0s 946us/step - loss: 0.3548 - accuracy: 0.8250\n",
      "Epoch 40/50\n",
      "132/132 [==============================] - 0s 880us/step - loss: 0.3545 - accuracy: 0.8273\n",
      "Epoch 41/50\n",
      "132/132 [==============================] - 0s 956us/step - loss: 0.3543 - accuracy: 0.8248\n",
      "Epoch 42/50\n",
      "132/132 [==============================] - 0s 893us/step - loss: 0.3543 - accuracy: 0.8267\n",
      "Epoch 43/50\n",
      "132/132 [==============================] - 0s 915us/step - loss: 0.3543 - accuracy: 0.8270\n",
      "Epoch 44/50\n",
      "132/132 [==============================] - 0s 889us/step - loss: 0.3532 - accuracy: 0.8277\n",
      "Epoch 45/50\n",
      "132/132 [==============================] - 0s 897us/step - loss: 0.3533 - accuracy: 0.8292\n",
      "Epoch 46/50\n",
      "132/132 [==============================] - 0s 973us/step - loss: 0.3533 - accuracy: 0.8285\n",
      "Epoch 47/50\n",
      "132/132 [==============================] - 0s 968us/step - loss: 0.3550 - accuracy: 0.8295\n",
      "Epoch 48/50\n",
      "132/132 [==============================] - 0s 954us/step - loss: 0.3537 - accuracy: 0.8274\n",
      "Epoch 49/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3532 - accuracy: 0.8271\n",
      "Epoch 50/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3533 - accuracy: 0.8263\n",
      "Epoch 1/50\n",
      "132/132 [==============================] - 0s 908us/step - loss: 0.3592 - accuracy: 0.8285\n",
      "Epoch 2/50\n",
      "132/132 [==============================] - 0s 975us/step - loss: 0.3561 - accuracy: 0.8283\n",
      "Epoch 3/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3545 - accuracy: 0.8276\n",
      "Epoch 4/50\n",
      "132/132 [==============================] - 0s 985us/step - loss: 0.3538 - accuracy: 0.8271\n",
      "Epoch 5/50\n",
      "132/132 [==============================] - 0s 937us/step - loss: 0.3530 - accuracy: 0.8296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50\n",
      "132/132 [==============================] - 0s 930us/step - loss: 0.3527 - accuracy: 0.8300\n",
      "Epoch 7/50\n",
      "132/132 [==============================] - 0s 977us/step - loss: 0.3533 - accuracy: 0.8253\n",
      "Epoch 8/50\n",
      "132/132 [==============================] - 0s 925us/step - loss: 0.3523 - accuracy: 0.8271\n",
      "Epoch 9/50\n",
      "132/132 [==============================] - 0s 979us/step - loss: 0.3512 - accuracy: 0.8308\n",
      "Epoch 10/50\n",
      "132/132 [==============================] - 0s 916us/step - loss: 0.3508 - accuracy: 0.8279\n",
      "Epoch 11/50\n",
      "132/132 [==============================] - 0s 992us/step - loss: 0.3509 - accuracy: 0.8302\n",
      "Epoch 12/50\n",
      "132/132 [==============================] - 0s 934us/step - loss: 0.3508 - accuracy: 0.8283\n",
      "Epoch 13/50\n",
      "132/132 [==============================] - 0s 972us/step - loss: 0.3508 - accuracy: 0.8280\n",
      "Epoch 14/50\n",
      "132/132 [==============================] - 0s 935us/step - loss: 0.3503 - accuracy: 0.8302\n",
      "Epoch 15/50\n",
      "132/132 [==============================] - 0s 906us/step - loss: 0.3499 - accuracy: 0.8305\n",
      "Epoch 16/50\n",
      "132/132 [==============================] - 0s 982us/step - loss: 0.3496 - accuracy: 0.8300\n",
      "Epoch 17/50\n",
      "132/132 [==============================] - 0s 911us/step - loss: 0.3493 - accuracy: 0.8288\n",
      "Epoch 18/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3488 - accuracy: 0.8302\n",
      "Epoch 19/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3489 - accuracy: 0.8321\n",
      "Epoch 20/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3494 - accuracy: 0.8283\n",
      "Epoch 21/50\n",
      "132/132 [==============================] - 0s 963us/step - loss: 0.3481 - accuracy: 0.8311\n",
      "Epoch 22/50\n",
      "132/132 [==============================] - 0s 965us/step - loss: 0.3481 - accuracy: 0.8323\n",
      "Epoch 23/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3480 - accuracy: 0.8306\n",
      "Epoch 24/50\n",
      "132/132 [==============================] - 0s 921us/step - loss: 0.3483 - accuracy: 0.8311\n",
      "Epoch 25/50\n",
      "132/132 [==============================] - 0s 921us/step - loss: 0.3480 - accuracy: 0.8309\n",
      "Epoch 26/50\n",
      "132/132 [==============================] - 0s 984us/step - loss: 0.3480 - accuracy: 0.8286\n",
      "Epoch 27/50\n",
      "132/132 [==============================] - 0s 920us/step - loss: 0.3476 - accuracy: 0.8288\n",
      "Epoch 28/50\n",
      "132/132 [==============================] - 0s 968us/step - loss: 0.3480 - accuracy: 0.8296\n",
      "Epoch 29/50\n",
      "132/132 [==============================] - 0s 963us/step - loss: 0.3475 - accuracy: 0.8329\n",
      "Epoch 30/50\n",
      "132/132 [==============================] - 0s 881us/step - loss: 0.3484 - accuracy: 0.8292\n",
      "Epoch 31/50\n",
      "132/132 [==============================] - 0s 939us/step - loss: 0.3467 - accuracy: 0.8327\n",
      "Epoch 32/50\n",
      "132/132 [==============================] - 0s 905us/step - loss: 0.3471 - accuracy: 0.8299\n",
      "Epoch 33/50\n",
      "132/132 [==============================] - 0s 910us/step - loss: 0.3464 - accuracy: 0.8315\n",
      "Epoch 34/50\n",
      "132/132 [==============================] - 0s 928us/step - loss: 0.3466 - accuracy: 0.8324\n",
      "Epoch 35/50\n",
      "132/132 [==============================] - 0s 918us/step - loss: 0.3466 - accuracy: 0.8332\n",
      "Epoch 36/50\n",
      "132/132 [==============================] - 0s 893us/step - loss: 0.3457 - accuracy: 0.8315\n",
      "Epoch 37/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3468 - accuracy: 0.8337\n",
      "Epoch 38/50\n",
      "132/132 [==============================] - 0s 910us/step - loss: 0.3462 - accuracy: 0.8332\n",
      "Epoch 39/50\n",
      "132/132 [==============================] - 0s 944us/step - loss: 0.3464 - accuracy: 0.8331\n",
      "Epoch 40/50\n",
      "132/132 [==============================] - 0s 952us/step - loss: 0.3458 - accuracy: 0.8341\n",
      "Epoch 41/50\n",
      "132/132 [==============================] - 0s 930us/step - loss: 0.3452 - accuracy: 0.8324\n",
      "Epoch 42/50\n",
      "132/132 [==============================] - 0s 996us/step - loss: 0.3460 - accuracy: 0.8321\n",
      "Epoch 43/50\n",
      "132/132 [==============================] - 0s 889us/step - loss: 0.3458 - accuracy: 0.8331\n",
      "Epoch 44/50\n",
      "132/132 [==============================] - 0s 896us/step - loss: 0.3458 - accuracy: 0.8318\n",
      "Epoch 45/50\n",
      "132/132 [==============================] - 0s 876us/step - loss: 0.3457 - accuracy: 0.8347\n",
      "Epoch 46/50\n",
      "132/132 [==============================] - 0s 914us/step - loss: 0.3453 - accuracy: 0.8321\n",
      "Epoch 47/50\n",
      "132/132 [==============================] - 0s 938us/step - loss: 0.3453 - accuracy: 0.8341\n",
      "Epoch 48/50\n",
      "132/132 [==============================] - 0s 914us/step - loss: 0.3452 - accuracy: 0.8347\n",
      "Epoch 49/50\n",
      "132/132 [==============================] - 0s 950us/step - loss: 0.3452 - accuracy: 0.8356\n",
      "Epoch 50/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3451 - accuracy: 0.8350\n",
      "Epoch 1/50\n",
      "132/132 [==============================] - 0s 931us/step - loss: 0.3537 - accuracy: 0.8251\n",
      "Epoch 2/50\n",
      "132/132 [==============================] - 0s 936us/step - loss: 0.3503 - accuracy: 0.8292\n",
      "Epoch 3/50\n",
      "132/132 [==============================] - 0s 957us/step - loss: 0.3491 - accuracy: 0.8323\n",
      "Epoch 4/50\n",
      "132/132 [==============================] - 0s 904us/step - loss: 0.3484 - accuracy: 0.8314\n",
      "Epoch 5/50\n",
      "132/132 [==============================] - 0s 930us/step - loss: 0.3470 - accuracy: 0.8297\n",
      "Epoch 6/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3456 - accuracy: 0.8338\n",
      "Epoch 7/50\n",
      "132/132 [==============================] - 0s 904us/step - loss: 0.3451 - accuracy: 0.8359\n",
      "Epoch 8/50\n",
      "132/132 [==============================] - 0s 991us/step - loss: 0.3464 - accuracy: 0.8333\n",
      "Epoch 9/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3444 - accuracy: 0.8323\n",
      "Epoch 10/50\n",
      "132/132 [==============================] - 0s 927us/step - loss: 0.3442 - accuracy: 0.8353\n",
      "Epoch 11/50\n",
      "132/132 [==============================] - 0s 875us/step - loss: 0.3447 - accuracy: 0.8320\n",
      "Epoch 12/50\n",
      "132/132 [==============================] - 0s 869us/step - loss: 0.3431 - accuracy: 0.8352\n",
      "Epoch 13/50\n",
      "132/132 [==============================] - 0s 957us/step - loss: 0.3434 - accuracy: 0.8347\n",
      "Epoch 14/50\n",
      "132/132 [==============================] - 0s 903us/step - loss: 0.3434 - accuracy: 0.8356\n",
      "Epoch 15/50\n",
      "132/132 [==============================] - 0s 935us/step - loss: 0.3429 - accuracy: 0.8349\n",
      "Epoch 16/50\n",
      "132/132 [==============================] - 0s 899us/step - loss: 0.3424 - accuracy: 0.8356\n",
      "Epoch 17/50\n",
      "132/132 [==============================] - 0s 949us/step - loss: 0.3422 - accuracy: 0.8371\n",
      "Epoch 18/50\n",
      "132/132 [==============================] - 0s 896us/step - loss: 0.3412 - accuracy: 0.8379\n",
      "Epoch 19/50\n",
      "132/132 [==============================] - 0s 896us/step - loss: 0.3408 - accuracy: 0.8391\n",
      "Epoch 20/50\n",
      "132/132 [==============================] - 0s 874us/step - loss: 0.3409 - accuracy: 0.8393\n",
      "Epoch 21/50\n",
      "132/132 [==============================] - 0s 899us/step - loss: 0.3407 - accuracy: 0.8374\n",
      "Epoch 22/50\n",
      "132/132 [==============================] - 0s 925us/step - loss: 0.3407 - accuracy: 0.8399\n",
      "Epoch 23/50\n",
      "132/132 [==============================] - 0s 889us/step - loss: 0.3406 - accuracy: 0.8402\n",
      "Epoch 24/50\n",
      "132/132 [==============================] - 0s 955us/step - loss: 0.3410 - accuracy: 0.8359\n",
      "Epoch 25/50\n",
      "132/132 [==============================] - 0s 896us/step - loss: 0.3400 - accuracy: 0.8403\n",
      "Epoch 26/50\n",
      "132/132 [==============================] - 0s 960us/step - loss: 0.3395 - accuracy: 0.8413\n",
      "Epoch 27/50\n",
      "132/132 [==============================] - 0s 921us/step - loss: 0.3396 - accuracy: 0.8403\n",
      "Epoch 28/50\n",
      "132/132 [==============================] - 0s 929us/step - loss: 0.3402 - accuracy: 0.8406\n",
      "Epoch 29/50\n",
      "132/132 [==============================] - 0s 906us/step - loss: 0.3394 - accuracy: 0.8379\n",
      "Epoch 30/50\n",
      "132/132 [==============================] - 0s 971us/step - loss: 0.3399 - accuracy: 0.8382\n",
      "Epoch 31/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3393 - accuracy: 0.8419\n",
      "Epoch 32/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3391 - accuracy: 0.8387\n",
      "Epoch 33/50\n",
      "132/132 [==============================] - 0s 957us/step - loss: 0.3388 - accuracy: 0.8405\n",
      "Epoch 34/50\n",
      "132/132 [==============================] - 0s 940us/step - loss: 0.3387 - accuracy: 0.8368\n",
      "Epoch 35/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 0s 968us/step - loss: 0.3383 - accuracy: 0.8400\n",
      "Epoch 36/50\n",
      "132/132 [==============================] - 0s 980us/step - loss: 0.3379 - accuracy: 0.8387\n",
      "Epoch 37/50\n",
      "132/132 [==============================] - 0s 941us/step - loss: 0.3380 - accuracy: 0.8379\n",
      "Epoch 38/50\n",
      "132/132 [==============================] - 0s 958us/step - loss: 0.3375 - accuracy: 0.8408\n",
      "Epoch 39/50\n",
      "132/132 [==============================] - 0s 924us/step - loss: 0.3386 - accuracy: 0.8408\n",
      "Epoch 40/50\n",
      "132/132 [==============================] - 0s 926us/step - loss: 0.3377 - accuracy: 0.8361\n",
      "Epoch 41/50\n",
      "132/132 [==============================] - 0s 937us/step - loss: 0.3370 - accuracy: 0.8397\n",
      "Epoch 42/50\n",
      "132/132 [==============================] - 0s 921us/step - loss: 0.3371 - accuracy: 0.8368\n",
      "Epoch 43/50\n",
      "132/132 [==============================] - 0s 914us/step - loss: 0.3370 - accuracy: 0.8370\n",
      "Epoch 44/50\n",
      "132/132 [==============================] - 0s 921us/step - loss: 0.3368 - accuracy: 0.8381\n",
      "Epoch 45/50\n",
      "132/132 [==============================] - 0s 937us/step - loss: 0.3372 - accuracy: 0.8390\n",
      "Epoch 46/50\n",
      "132/132 [==============================] - 0s 993us/step - loss: 0.3365 - accuracy: 0.8396\n",
      "Epoch 47/50\n",
      "132/132 [==============================] - 0s 897us/step - loss: 0.3369 - accuracy: 0.8396\n",
      "Epoch 48/50\n",
      "132/132 [==============================] - 0s 880us/step - loss: 0.3372 - accuracy: 0.8371\n",
      "Epoch 49/50\n",
      "132/132 [==============================] - 0s 931us/step - loss: 0.3371 - accuracy: 0.8356\n",
      "Epoch 50/50\n",
      "132/132 [==============================] - 0s 933us/step - loss: 0.3367 - accuracy: 0.8384\n",
      "Average accuracy for model 1:  83.32681017612524\n",
      "Epoch 1/50\n",
      "328/328 [==============================] - 1s 872us/step - loss: 0.7546 - accuracy: 0.5076\n",
      "Epoch 2/50\n",
      "328/328 [==============================] - 0s 903us/step - loss: 0.5392 - accuracy: 0.7410\n",
      "Epoch 3/50\n",
      "328/328 [==============================] - 0s 918us/step - loss: 0.4776 - accuracy: 0.77240s - loss: 0.4802 - accuracy: 0.77\n",
      "Epoch 4/50\n",
      "328/328 [==============================] - 0s 918us/step - loss: 0.4570 - accuracy: 0.7822\n",
      "Epoch 5/50\n",
      "328/328 [==============================] - 0s 897us/step - loss: 0.4487 - accuracy: 0.7906\n",
      "Epoch 6/50\n",
      "328/328 [==============================] - 0s 916us/step - loss: 0.4445 - accuracy: 0.7914\n",
      "Epoch 7/50\n",
      "328/328 [==============================] - 0s 916us/step - loss: 0.4411 - accuracy: 0.79110s - loss: 0.4447 - accuracy: \n",
      "Epoch 8/50\n",
      "328/328 [==============================] - 0s 975us/step - loss: 0.4383 - accuracy: 0.7915\n",
      "Epoch 9/50\n",
      "328/328 [==============================] - 0s 895us/step - loss: 0.4353 - accuracy: 0.7933\n",
      "Epoch 10/50\n",
      "328/328 [==============================] - 0s 895us/step - loss: 0.4326 - accuracy: 0.7943\n",
      "Epoch 11/50\n",
      "328/328 [==============================] - 0s 941us/step - loss: 0.4300 - accuracy: 0.7941\n",
      "Epoch 12/50\n",
      "328/328 [==============================] - 0s 902us/step - loss: 0.4276 - accuracy: 0.7970\n",
      "Epoch 13/50\n",
      "328/328 [==============================] - 0s 911us/step - loss: 0.4251 - accuracy: 0.7982\n",
      "Epoch 14/50\n",
      "328/328 [==============================] - 0s 984us/step - loss: 0.4232 - accuracy: 0.7985\n",
      "Epoch 15/50\n",
      "328/328 [==============================] - 0s 961us/step - loss: 0.4216 - accuracy: 0.7995\n",
      "Epoch 16/50\n",
      "328/328 [==============================] - 0s 873us/step - loss: 0.4205 - accuracy: 0.7988\n",
      "Epoch 17/50\n",
      "328/328 [==============================] - 0s 869us/step - loss: 0.4195 - accuracy: 0.7985\n",
      "Epoch 18/50\n",
      "328/328 [==============================] - 0s 888us/step - loss: 0.4183 - accuracy: 0.7993\n",
      "Epoch 19/50\n",
      "328/328 [==============================] - 0s 990us/step - loss: 0.4172 - accuracy: 0.79840s - loss: 0.4213 - accuracy: 0.\n",
      "Epoch 20/50\n",
      "328/328 [==============================] - 0s 984us/step - loss: 0.4168 - accuracy: 0.8002\n",
      "Epoch 21/50\n",
      "328/328 [==============================] - 0s 967us/step - loss: 0.4159 - accuracy: 0.8010\n",
      "Epoch 22/50\n",
      "328/328 [==============================] - 0s 960us/step - loss: 0.4152 - accuracy: 0.7996\n",
      "Epoch 23/50\n",
      "328/328 [==============================] - 0s 964us/step - loss: 0.4145 - accuracy: 0.7978\n",
      "Epoch 24/50\n",
      "328/328 [==============================] - 0s 912us/step - loss: 0.4140 - accuracy: 0.7998\n",
      "Epoch 25/50\n",
      "328/328 [==============================] - 0s 889us/step - loss: 0.4143 - accuracy: 0.7993\n",
      "Epoch 26/50\n",
      "328/328 [==============================] - 0s 932us/step - loss: 0.4132 - accuracy: 0.8017\n",
      "Epoch 27/50\n",
      "328/328 [==============================] - 0s 982us/step - loss: 0.4130 - accuracy: 0.7991\n",
      "Epoch 28/50\n",
      "328/328 [==============================] - 0s 913us/step - loss: 0.4121 - accuracy: 0.7982\n",
      "Epoch 29/50\n",
      "328/328 [==============================] - 0s 914us/step - loss: 0.4118 - accuracy: 0.8011\n",
      "Epoch 30/50\n",
      "328/328 [==============================] - 0s 929us/step - loss: 0.4115 - accuracy: 0.7993\n",
      "Epoch 31/50\n",
      "328/328 [==============================] - 0s 900us/step - loss: 0.4107 - accuracy: 0.8020\n",
      "Epoch 32/50\n",
      "328/328 [==============================] - 0s 907us/step - loss: 0.4103 - accuracy: 0.8027\n",
      "Epoch 33/50\n",
      "328/328 [==============================] - 0s 907us/step - loss: 0.4100 - accuracy: 0.8039\n",
      "Epoch 34/50\n",
      "328/328 [==============================] - 0s 953us/step - loss: 0.4095 - accuracy: 0.8022\n",
      "Epoch 35/50\n",
      "328/328 [==============================] - 0s 895us/step - loss: 0.4092 - accuracy: 0.8040\n",
      "Epoch 36/50\n",
      "328/328 [==============================] - 0s 918us/step - loss: 0.4084 - accuracy: 0.8017\n",
      "Epoch 37/50\n",
      "328/328 [==============================] - 0s 890us/step - loss: 0.4077 - accuracy: 0.8030\n",
      "Epoch 38/50\n",
      "328/328 [==============================] - 0s 901us/step - loss: 0.4074 - accuracy: 0.8030\n",
      "Epoch 39/50\n",
      "328/328 [==============================] - 0s 885us/step - loss: 0.4067 - accuracy: 0.8054\n",
      "Epoch 40/50\n",
      "328/328 [==============================] - 0s 876us/step - loss: 0.4063 - accuracy: 0.8043\n",
      "Epoch 41/50\n",
      "328/328 [==============================] - 0s 880us/step - loss: 0.4060 - accuracy: 0.8039\n",
      "Epoch 42/50\n",
      "328/328 [==============================] - 0s 888us/step - loss: 0.4054 - accuracy: 0.8042\n",
      "Epoch 43/50\n",
      "328/328 [==============================] - 0s 899us/step - loss: 0.4050 - accuracy: 0.8075\n",
      "Epoch 44/50\n",
      "328/328 [==============================] - 0s 902us/step - loss: 0.4048 - accuracy: 0.8045\n",
      "Epoch 45/50\n",
      "328/328 [==============================] - 0s 917us/step - loss: 0.4042 - accuracy: 0.80750s - loss: 0.4056 - accuracy: 0.\n",
      "Epoch 46/50\n",
      "328/328 [==============================] - 0s 916us/step - loss: 0.4040 - accuracy: 0.8075\n",
      "Epoch 47/50\n",
      "328/328 [==============================] - 0s 1ms/step - loss: 0.4029 - accuracy: 0.8071\n",
      "Epoch 48/50\n",
      "328/328 [==============================] - 0s 911us/step - loss: 0.4034 - accuracy: 0.8100\n",
      "Epoch 49/50\n",
      "328/328 [==============================] - 0s 894us/step - loss: 0.4032 - accuracy: 0.8095\n",
      "Epoch 50/50\n",
      "328/328 [==============================] - 0s 908us/step - loss: 0.4027 - accuracy: 0.8082\n",
      "Epoch 1/50\n",
      "329/329 [==============================] - 0s 897us/step - loss: 0.4049 - accuracy: 0.8027\n",
      "Epoch 2/50\n",
      "329/329 [==============================] - 0s 888us/step - loss: 0.4024 - accuracy: 0.8050\n",
      "Epoch 3/50\n",
      "329/329 [==============================] - 0s 904us/step - loss: 0.4013 - accuracy: 0.8073\n",
      "Epoch 4/50\n",
      "329/329 [==============================] - 0s 892us/step - loss: 0.4000 - accuracy: 0.8084\n",
      "Epoch 5/50\n",
      "329/329 [==============================] - 0s 899us/step - loss: 0.3991 - accuracy: 0.8093\n",
      "Epoch 6/50\n",
      "329/329 [==============================] - 0s 916us/step - loss: 0.3984 - accuracy: 0.8079\n",
      "Epoch 7/50\n",
      "329/329 [==============================] - 0s 986us/step - loss: 0.3981 - accuracy: 0.8096\n",
      "Epoch 8/50\n",
      "329/329 [==============================] - 0s 921us/step - loss: 0.3975 - accuracy: 0.8104\n",
      "Epoch 9/50\n",
      "329/329 [==============================] - 0s 950us/step - loss: 0.3965 - accuracy: 0.8119\n",
      "Epoch 10/50\n",
      "329/329 [==============================] - 0s 957us/step - loss: 0.3961 - accuracy: 0.8108\n",
      "Epoch 11/50\n",
      "329/329 [==============================] - 0s 894us/step - loss: 0.3953 - accuracy: 0.8135\n",
      "Epoch 12/50\n",
      "329/329 [==============================] - 0s 899us/step - loss: 0.3949 - accuracy: 0.8125\n",
      "Epoch 13/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "329/329 [==============================] - 0s 925us/step - loss: 0.3946 - accuracy: 0.8113\n",
      "Epoch 14/50\n",
      "329/329 [==============================] - 0s 893us/step - loss: 0.3940 - accuracy: 0.8123\n",
      "Epoch 15/50\n",
      "329/329 [==============================] - 0s 898us/step - loss: 0.3935 - accuracy: 0.8110\n",
      "Epoch 16/50\n",
      "329/329 [==============================] - 0s 887us/step - loss: 0.3930 - accuracy: 0.8139\n",
      "Epoch 17/50\n",
      "329/329 [==============================] - 0s 926us/step - loss: 0.3923 - accuracy: 0.8163\n",
      "Epoch 18/50\n",
      "329/329 [==============================] - 0s 1ms/step - loss: 0.3920 - accuracy: 0.8140\n",
      "Epoch 19/50\n",
      "329/329 [==============================] - 0s 1ms/step - loss: 0.3915 - accuracy: 0.8143: 0s - loss: 0.3957 - accuracy: 0.\n",
      "Epoch 20/50\n",
      "329/329 [==============================] - 0s 1ms/step - loss: 0.3906 - accuracy: 0.8152\n",
      "Epoch 21/50\n",
      "329/329 [==============================] - 0s 937us/step - loss: 0.3903 - accuracy: 0.8164\n",
      "Epoch 22/50\n",
      "329/329 [==============================] - 0s 919us/step - loss: 0.3897 - accuracy: 0.8151\n",
      "Epoch 23/50\n",
      "329/329 [==============================] - 0s 1ms/step - loss: 0.3891 - accuracy: 0.8140\n",
      "Epoch 24/50\n",
      "329/329 [==============================] - 0s 983us/step - loss: 0.3882 - accuracy: 0.8169\n",
      "Epoch 25/50\n",
      "329/329 [==============================] - 0s 1ms/step - loss: 0.3874 - accuracy: 0.8169\n",
      "Epoch 26/50\n",
      "329/329 [==============================] - 0s 895us/step - loss: 0.3864 - accuracy: 0.8145\n",
      "Epoch 27/50\n",
      "329/329 [==============================] - 0s 990us/step - loss: 0.3864 - accuracy: 0.8166\n",
      "Epoch 28/50\n",
      "329/329 [==============================] - 0s 971us/step - loss: 0.3851 - accuracy: 0.8163\n",
      "Epoch 29/50\n",
      "329/329 [==============================] - 0s 902us/step - loss: 0.3847 - accuracy: 0.8158\n",
      "Epoch 30/50\n",
      "329/329 [==============================] - 0s 997us/step - loss: 0.3844 - accuracy: 0.8190\n",
      "Epoch 31/50\n",
      "329/329 [==============================] - 0s 952us/step - loss: 0.3834 - accuracy: 0.8193\n",
      "Epoch 32/50\n",
      "329/329 [==============================] - 0s 1ms/step - loss: 0.3825 - accuracy: 0.8180\n",
      "Epoch 33/50\n",
      "329/329 [==============================] - 0s 985us/step - loss: 0.3821 - accuracy: 0.8196\n",
      "Epoch 34/50\n",
      "329/329 [==============================] - 0s 914us/step - loss: 0.3811 - accuracy: 0.8192\n",
      "Epoch 35/50\n",
      "329/329 [==============================] - 0s 917us/step - loss: 0.3804 - accuracy: 0.8187\n",
      "Epoch 36/50\n",
      "329/329 [==============================] - 0s 940us/step - loss: 0.3799 - accuracy: 0.8190\n",
      "Epoch 37/50\n",
      "329/329 [==============================] - 0s 946us/step - loss: 0.3790 - accuracy: 0.8228\n",
      "Epoch 38/50\n",
      "329/329 [==============================] - 0s 906us/step - loss: 0.3786 - accuracy: 0.8213\n",
      "Epoch 39/50\n",
      "329/329 [==============================] - 0s 893us/step - loss: 0.3780 - accuracy: 0.8210\n",
      "Epoch 40/50\n",
      "329/329 [==============================] - 0s 1ms/step - loss: 0.3778 - accuracy: 0.8213\n",
      "Epoch 41/50\n",
      "329/329 [==============================] - 0s 956us/step - loss: 0.3770 - accuracy: 0.8212\n",
      "Epoch 42/50\n",
      "329/329 [==============================] - 0s 881us/step - loss: 0.3769 - accuracy: 0.8244\n",
      "Epoch 43/50\n",
      "329/329 [==============================] - 0s 924us/step - loss: 0.3755 - accuracy: 0.8237\n",
      "Epoch 44/50\n",
      "329/329 [==============================] - 0s 880us/step - loss: 0.3754 - accuracy: 0.8215\n",
      "Epoch 45/50\n",
      "329/329 [==============================] - 0s 945us/step - loss: 0.3754 - accuracy: 0.8216\n",
      "Epoch 46/50\n",
      "329/329 [==============================] - 0s 877us/step - loss: 0.3748 - accuracy: 0.8248\n",
      "Epoch 47/50\n",
      "329/329 [==============================] - 0s 956us/step - loss: 0.3748 - accuracy: 0.8212\n",
      "Epoch 48/50\n",
      "329/329 [==============================] - 0s 913us/step - loss: 0.3736 - accuracy: 0.8237\n",
      "Epoch 49/50\n",
      "329/329 [==============================] - 0s 914us/step - loss: 0.3733 - accuracy: 0.8254\n",
      "Epoch 50/50\n",
      "329/329 [==============================] - 0s 957us/step - loss: 0.3725 - accuracy: 0.8233\n",
      "Epoch 1/50\n",
      "329/329 [==============================] - 0s 953us/step - loss: 0.3874 - accuracy: 0.8133\n",
      "Epoch 2/50\n",
      "329/329 [==============================] - 0s 992us/step - loss: 0.3836 - accuracy: 0.8117\n",
      "Epoch 3/50\n",
      "329/329 [==============================] - 0s 922us/step - loss: 0.3821 - accuracy: 0.8153\n",
      "Epoch 4/50\n",
      "329/329 [==============================] - 0s 963us/step - loss: 0.3809 - accuracy: 0.8152\n",
      "Epoch 5/50\n",
      "329/329 [==============================] - 0s 961us/step - loss: 0.3800 - accuracy: 0.8174\n",
      "Epoch 6/50\n",
      "329/329 [==============================] - 0s 947us/step - loss: 0.3793 - accuracy: 0.8167\n",
      "Epoch 7/50\n",
      "329/329 [==============================] - 0s 917us/step - loss: 0.3785 - accuracy: 0.8176\n",
      "Epoch 8/50\n",
      "329/329 [==============================] - 0s 1ms/step - loss: 0.3783 - accuracy: 0.8144\n",
      "Epoch 9/50\n",
      "329/329 [==============================] - 0s 918us/step - loss: 0.3777 - accuracy: 0.8174\n",
      "Epoch 10/50\n",
      "329/329 [==============================] - 0s 1ms/step - loss: 0.3771 - accuracy: 0.8167\n",
      "Epoch 11/50\n",
      "329/329 [==============================] - 0s 951us/step - loss: 0.3766 - accuracy: 0.8183\n",
      "Epoch 12/50\n",
      "329/329 [==============================] - 0s 941us/step - loss: 0.3762 - accuracy: 0.8155\n",
      "Epoch 13/50\n",
      "329/329 [==============================] - 0s 909us/step - loss: 0.3760 - accuracy: 0.8165\n",
      "Epoch 14/50\n",
      "329/329 [==============================] - 0s 886us/step - loss: 0.3756 - accuracy: 0.8197\n",
      "Epoch 15/50\n",
      "329/329 [==============================] - 0s 896us/step - loss: 0.3751 - accuracy: 0.8188\n",
      "Epoch 16/50\n",
      "329/329 [==============================] - 0s 1ms/step - loss: 0.3745 - accuracy: 0.8187\n",
      "Epoch 17/50\n",
      "329/329 [==============================] - 0s 895us/step - loss: 0.3741 - accuracy: 0.8182\n",
      "Epoch 18/50\n",
      "329/329 [==============================] - 0s 890us/step - loss: 0.3742 - accuracy: 0.8212\n",
      "Epoch 19/50\n",
      "329/329 [==============================] - 0s 928us/step - loss: 0.3741 - accuracy: 0.8187\n",
      "Epoch 20/50\n",
      "329/329 [==============================] - 0s 911us/step - loss: 0.3735 - accuracy: 0.8197\n",
      "Epoch 21/50\n",
      "329/329 [==============================] - 0s 909us/step - loss: 0.3731 - accuracy: 0.8193\n",
      "Epoch 22/50\n",
      "329/329 [==============================] - 0s 947us/step - loss: 0.3723 - accuracy: 0.8205\n",
      "Epoch 23/50\n",
      "329/329 [==============================] - 0s 892us/step - loss: 0.3718 - accuracy: 0.8217\n",
      "Epoch 24/50\n",
      "329/329 [==============================] - 0s 973us/step - loss: 0.3715 - accuracy: 0.8211\n",
      "Epoch 25/50\n",
      "329/329 [==============================] - 0s 905us/step - loss: 0.3712 - accuracy: 0.8205\n",
      "Epoch 26/50\n",
      "329/329 [==============================] - 0s 907us/step - loss: 0.3709 - accuracy: 0.8218\n",
      "Epoch 27/50\n",
      "329/329 [==============================] - 0s 1ms/step - loss: 0.3710 - accuracy: 0.8225\n",
      "Epoch 28/50\n",
      "329/329 [==============================] - 0s 897us/step - loss: 0.3700 - accuracy: 0.8208\n",
      "Epoch 29/50\n",
      "329/329 [==============================] - 0s 884us/step - loss: 0.3697 - accuracy: 0.8222\n",
      "Epoch 30/50\n",
      "329/329 [==============================] - 0s 868us/step - loss: 0.3697 - accuracy: 0.8229\n",
      "Epoch 31/50\n",
      "329/329 [==============================] - 0s 877us/step - loss: 0.3699 - accuracy: 0.8225\n",
      "Epoch 32/50\n",
      "329/329 [==============================] - 0s 918us/step - loss: 0.3693 - accuracy: 0.8228\n",
      "Epoch 33/50\n",
      "329/329 [==============================] - 0s 902us/step - loss: 0.3690 - accuracy: 0.8235\n",
      "Epoch 34/50\n",
      "329/329 [==============================] - 0s 909us/step - loss: 0.3690 - accuracy: 0.8218\n",
      "Epoch 35/50\n",
      "329/329 [==============================] - 0s 904us/step - loss: 0.3682 - accuracy: 0.8228\n",
      "Epoch 36/50\n",
      "329/329 [==============================] - 0s 1ms/step - loss: 0.3687 - accuracy: 0.8237\n",
      "Epoch 37/50\n",
      "329/329 [==============================] - 0s 942us/step - loss: 0.3681 - accuracy: 0.8222\n",
      "Epoch 38/50\n",
      "329/329 [==============================] - 0s 955us/step - loss: 0.3680 - accuracy: 0.8252\n",
      "Epoch 39/50\n",
      "329/329 [==============================] - 0s 890us/step - loss: 0.3675 - accuracy: 0.8214\n",
      "Epoch 40/50\n",
      "329/329 [==============================] - 0s 892us/step - loss: 0.3677 - accuracy: 0.8235\n",
      "Epoch 41/50\n",
      "329/329 [==============================] - 0s 895us/step - loss: 0.3670 - accuracy: 0.8235\n",
      "Epoch 42/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "329/329 [==============================] - 0s 933us/step - loss: 0.3673 - accuracy: 0.8246\n",
      "Epoch 43/50\n",
      "329/329 [==============================] - 0s 892us/step - loss: 0.3665 - accuracy: 0.8252\n",
      "Epoch 44/50\n",
      "329/329 [==============================] - 0s 875us/step - loss: 0.3665 - accuracy: 0.8255\n",
      "Epoch 45/50\n",
      "329/329 [==============================] - 0s 889us/step - loss: 0.3661 - accuracy: 0.8237\n",
      "Epoch 46/50\n",
      "329/329 [==============================] - 0s 895us/step - loss: 0.3655 - accuracy: 0.8263\n",
      "Epoch 47/50\n",
      "329/329 [==============================] - 0s 935us/step - loss: 0.3658 - accuracy: 0.8250\n",
      "Epoch 48/50\n",
      "329/329 [==============================] - 0s 969us/step - loss: 0.3659 - accuracy: 0.8261\n",
      "Epoch 49/50\n",
      "329/329 [==============================] - 0s 884us/step - loss: 0.3653 - accuracy: 0.8253\n",
      "Epoch 50/50\n",
      "329/329 [==============================] - 0s 901us/step - loss: 0.3653 - accuracy: 0.8250\n",
      "Epoch 1/50\n",
      "328/328 [==============================] - 0s 898us/step - loss: 0.3938 - accuracy: 0.8085\n",
      "Epoch 2/50\n",
      "328/328 [==============================] - 0s 907us/step - loss: 0.3899 - accuracy: 0.8130\n",
      "Epoch 3/50\n",
      "328/328 [==============================] - 0s 911us/step - loss: 0.3877 - accuracy: 0.8136\n",
      "Epoch 4/50\n",
      "328/328 [==============================] - 0s 1ms/step - loss: 0.3870 - accuracy: 0.8125\n",
      "Epoch 5/50\n",
      "328/328 [==============================] - 0s 903us/step - loss: 0.3860 - accuracy: 0.8154\n",
      "Epoch 6/50\n",
      "328/328 [==============================] - 0s 908us/step - loss: 0.3851 - accuracy: 0.8175\n",
      "Epoch 7/50\n",
      "328/328 [==============================] - 0s 951us/step - loss: 0.3849 - accuracy: 0.8148\n",
      "Epoch 8/50\n",
      "328/328 [==============================] - 0s 1ms/step - loss: 0.3843 - accuracy: 0.8185\n",
      "Epoch 9/50\n",
      "328/328 [==============================] - 0s 1ms/step - loss: 0.3837 - accuracy: 0.8168\n",
      "Epoch 10/50\n",
      "328/328 [==============================] - 0s 904us/step - loss: 0.3836 - accuracy: 0.8192\n",
      "Epoch 11/50\n",
      "328/328 [==============================] - 0s 903us/step - loss: 0.3829 - accuracy: 0.8172\n",
      "Epoch 12/50\n",
      "328/328 [==============================] - 0s 916us/step - loss: 0.3827 - accuracy: 0.8211\n",
      "Epoch 13/50\n",
      "328/328 [==============================] - 0s 949us/step - loss: 0.3825 - accuracy: 0.8143\n",
      "Epoch 14/50\n",
      "328/328 [==============================] - 0s 910us/step - loss: 0.3815 - accuracy: 0.8178\n",
      "Epoch 15/50\n",
      "328/328 [==============================] - 0s 922us/step - loss: 0.3814 - accuracy: 0.8212\n",
      "Epoch 16/50\n",
      "328/328 [==============================] - 0s 924us/step - loss: 0.3810 - accuracy: 0.8200\n",
      "Epoch 17/50\n",
      "328/328 [==============================] - 0s 1ms/step - loss: 0.3808 - accuracy: 0.8221\n",
      "Epoch 18/50\n",
      "328/328 [==============================] - 0s 922us/step - loss: 0.3802 - accuracy: 0.8206\n",
      "Epoch 19/50\n",
      "328/328 [==============================] - 0s 922us/step - loss: 0.3799 - accuracy: 0.8211\n",
      "Epoch 20/50\n",
      "328/328 [==============================] - 0s 927us/step - loss: 0.3796 - accuracy: 0.8220\n",
      "Epoch 21/50\n",
      "328/328 [==============================] - 0s 1ms/step - loss: 0.3793 - accuracy: 0.8230\n",
      "Epoch 22/50\n",
      "328/328 [==============================] - 0s 967us/step - loss: 0.3791 - accuracy: 0.8200\n",
      "Epoch 23/50\n",
      "328/328 [==============================] - 0s 997us/step - loss: 0.3783 - accuracy: 0.8230\n",
      "Epoch 24/50\n",
      "328/328 [==============================] - 0s 1ms/step - loss: 0.3787 - accuracy: 0.8241\n",
      "Epoch 25/50\n",
      "328/328 [==============================] - 0s 957us/step - loss: 0.3783 - accuracy: 0.8243\n",
      "Epoch 26/50\n",
      "328/328 [==============================] - 0s 1ms/step - loss: 0.3778 - accuracy: 0.8249\n",
      "Epoch 27/50\n",
      "328/328 [==============================] - 0s 954us/step - loss: 0.3777 - accuracy: 0.8259\n",
      "Epoch 28/50\n",
      "328/328 [==============================] - 0s 929us/step - loss: 0.3769 - accuracy: 0.8259\n",
      "Epoch 29/50\n",
      "328/328 [==============================] - 0s 911us/step - loss: 0.3769 - accuracy: 0.8223\n",
      "Epoch 30/50\n",
      "328/328 [==============================] - 0s 918us/step - loss: 0.3766 - accuracy: 0.8284\n",
      "Epoch 31/50\n",
      "328/328 [==============================] - 0s 933us/step - loss: 0.3768 - accuracy: 0.8246\n",
      "Epoch 32/50\n",
      "328/328 [==============================] - 0s 887us/step - loss: 0.3759 - accuracy: 0.8243\n",
      "Epoch 33/50\n",
      "328/328 [==============================] - 0s 1ms/step - loss: 0.3760 - accuracy: 0.8247\n",
      "Epoch 34/50\n",
      "328/328 [==============================] - 0s 1ms/step - loss: 0.3753 - accuracy: 0.8258\n",
      "Epoch 35/50\n",
      "328/328 [==============================] - 0s 1ms/step - loss: 0.3747 - accuracy: 0.8279\n",
      "Epoch 36/50\n",
      "328/328 [==============================] - 0s 951us/step - loss: 0.3753 - accuracy: 0.8261\n",
      "Epoch 37/50\n",
      "328/328 [==============================] - 0s 977us/step - loss: 0.3751 - accuracy: 0.8273\n",
      "Epoch 38/50\n",
      "328/328 [==============================] - 0s 948us/step - loss: 0.3746 - accuracy: 0.8243\n",
      "Epoch 39/50\n",
      "328/328 [==============================] - 0s 951us/step - loss: 0.3744 - accuracy: 0.8253\n",
      "Epoch 40/50\n",
      "328/328 [==============================] - 0s 948us/step - loss: 0.3741 - accuracy: 0.8258\n",
      "Epoch 41/50\n",
      "328/328 [==============================] - 0s 959us/step - loss: 0.3733 - accuracy: 0.8273\n",
      "Epoch 42/50\n",
      "328/328 [==============================] - 0s 1ms/step - loss: 0.3734 - accuracy: 0.8247\n",
      "Epoch 43/50\n",
      "328/328 [==============================] - 0s 1ms/step - loss: 0.3737 - accuracy: 0.8259\n",
      "Epoch 44/50\n",
      "328/328 [==============================] - 0s 932us/step - loss: 0.3726 - accuracy: 0.8253\n",
      "Epoch 45/50\n",
      "328/328 [==============================] - 0s 909us/step - loss: 0.3736 - accuracy: 0.8230\n",
      "Epoch 46/50\n",
      "328/328 [==============================] - 0s 900us/step - loss: 0.3725 - accuracy: 0.8255\n",
      "Epoch 47/50\n",
      "328/328 [==============================] - 0s 921us/step - loss: 0.3724 - accuracy: 0.8267\n",
      "Epoch 48/50\n",
      "328/328 [==============================] - 0s 954us/step - loss: 0.3718 - accuracy: 0.8278\n",
      "Epoch 49/50\n",
      "328/328 [==============================] - 0s 966us/step - loss: 0.3722 - accuracy: 0.8278\n",
      "Epoch 50/50\n",
      "328/328 [==============================] - 0s 949us/step - loss: 0.3721 - accuracy: 0.8270\n",
      "Epoch 1/50\n",
      "329/329 [==============================] - 0s 947us/step - loss: 0.3745 - accuracy: 0.8235\n",
      "Epoch 2/50\n",
      "329/329 [==============================] - 0s 1ms/step - loss: 0.3715 - accuracy: 0.8235\n",
      "Epoch 3/50\n",
      "329/329 [==============================] - 0s 974us/step - loss: 0.3708 - accuracy: 0.8211\n",
      "Epoch 4/50\n",
      "329/329 [==============================] - 0s 972us/step - loss: 0.3700 - accuracy: 0.8249\n",
      "Epoch 5/50\n",
      "329/329 [==============================] - 0s 1ms/step - loss: 0.3691 - accuracy: 0.8223\n",
      "Epoch 6/50\n",
      "329/329 [==============================] - 0s 1ms/step - loss: 0.3681 - accuracy: 0.8244\n",
      "Epoch 7/50\n",
      "329/329 [==============================] - 0s 955us/step - loss: 0.3680 - accuracy: 0.8219\n",
      "Epoch 8/50\n",
      "329/329 [==============================] - 0s 1ms/step - loss: 0.3671 - accuracy: 0.8202\n",
      "Epoch 9/50\n",
      "329/329 [==============================] - 0s 887us/step - loss: 0.3665 - accuracy: 0.8209\n",
      "Epoch 10/50\n",
      "329/329 [==============================] - 0s 980us/step - loss: 0.3663 - accuracy: 0.8211\n",
      "Epoch 11/50\n",
      "329/329 [==============================] - 0s 1ms/step - loss: 0.3657 - accuracy: 0.8235\n",
      "Epoch 12/50\n",
      "329/329 [==============================] - 0s 909us/step - loss: 0.3662 - accuracy: 0.8206\n",
      "Epoch 13/50\n",
      "329/329 [==============================] - 0s 918us/step - loss: 0.3656 - accuracy: 0.8205\n",
      "Epoch 14/50\n",
      "329/329 [==============================] - 0s 939us/step - loss: 0.3655 - accuracy: 0.82090s - loss: 0.3635 - accuracy: \n",
      "Epoch 15/50\n",
      "329/329 [==============================] - 0s 903us/step - loss: 0.3648 - accuracy: 0.8219\n",
      "Epoch 16/50\n",
      "329/329 [==============================] - 0s 1ms/step - loss: 0.3648 - accuracy: 0.8240\n",
      "Epoch 17/50\n",
      "329/329 [==============================] - 0s 942us/step - loss: 0.3644 - accuracy: 0.8237\n",
      "Epoch 18/50\n",
      "329/329 [==============================] - 0s 931us/step - loss: 0.3644 - accuracy: 0.8202\n",
      "Epoch 19/50\n",
      "329/329 [==============================] - 0s 896us/step - loss: 0.3641 - accuracy: 0.8241\n",
      "Epoch 20/50\n",
      "329/329 [==============================] - 0s 974us/step - loss: 0.3638 - accuracy: 0.8223\n",
      "Epoch 21/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "329/329 [==============================] - 0s 951us/step - loss: 0.3634 - accuracy: 0.8223\n",
      "Epoch 22/50\n",
      "329/329 [==============================] - 0s 954us/step - loss: 0.3633 - accuracy: 0.8220\n",
      "Epoch 23/50\n",
      "329/329 [==============================] - 0s 948us/step - loss: 0.3631 - accuracy: 0.8254\n",
      "Epoch 24/50\n",
      "329/329 [==============================] - 0s 978us/step - loss: 0.3627 - accuracy: 0.8206\n",
      "Epoch 25/50\n",
      "329/329 [==============================] - 0s 1ms/step - loss: 0.3627 - accuracy: 0.8235\n",
      "Epoch 26/50\n",
      "329/329 [==============================] - 0s 1ms/step - loss: 0.3622 - accuracy: 0.8235\n",
      "Epoch 27/50\n",
      "329/329 [==============================] - 0s 969us/step - loss: 0.3621 - accuracy: 0.8249\n",
      "Epoch 28/50\n",
      "329/329 [==============================] - 0s 917us/step - loss: 0.3617 - accuracy: 0.8241\n",
      "Epoch 29/50\n",
      "329/329 [==============================] - 0s 980us/step - loss: 0.3613 - accuracy: 0.8255\n",
      "Epoch 30/50\n",
      "329/329 [==============================] - 0s 936us/step - loss: 0.3611 - accuracy: 0.8269\n",
      "Epoch 31/50\n",
      "329/329 [==============================] - 0s 952us/step - loss: 0.3607 - accuracy: 0.8240\n",
      "Epoch 32/50\n",
      "329/329 [==============================] - 0s 916us/step - loss: 0.3608 - accuracy: 0.8238\n",
      "Epoch 33/50\n",
      "329/329 [==============================] - 0s 947us/step - loss: 0.3604 - accuracy: 0.8272\n",
      "Epoch 34/50\n",
      "329/329 [==============================] - 0s 989us/step - loss: 0.3600 - accuracy: 0.8254\n",
      "Epoch 35/50\n",
      "329/329 [==============================] - 0s 1ms/step - loss: 0.3599 - accuracy: 0.8296\n",
      "Epoch 36/50\n",
      "329/329 [==============================] - 0s 1ms/step - loss: 0.3599 - accuracy: 0.8264\n",
      "Epoch 37/50\n",
      "329/329 [==============================] - 0s 1ms/step - loss: 0.3596 - accuracy: 0.8258\n",
      "Epoch 38/50\n",
      "329/329 [==============================] - 0s 948us/step - loss: 0.3595 - accuracy: 0.8275\n",
      "Epoch 39/50\n",
      "329/329 [==============================] - 0s 977us/step - loss: 0.3595 - accuracy: 0.8238\n",
      "Epoch 40/50\n",
      "329/329 [==============================] - 0s 1ms/step - loss: 0.3589 - accuracy: 0.8272\n",
      "Epoch 41/50\n",
      "329/329 [==============================] - 0s 1ms/step - loss: 0.3588 - accuracy: 0.8281\n",
      "Epoch 42/50\n",
      "329/329 [==============================] - 0s 943us/step - loss: 0.3584 - accuracy: 0.8273\n",
      "Epoch 43/50\n",
      "329/329 [==============================] - 0s 925us/step - loss: 0.3591 - accuracy: 0.8292\n",
      "Epoch 44/50\n",
      "329/329 [==============================] - 0s 1ms/step - loss: 0.3579 - accuracy: 0.8290\n",
      "Epoch 45/50\n",
      "329/329 [==============================] - 0s 1ms/step - loss: 0.3580 - accuracy: 0.8264\n",
      "Epoch 46/50\n",
      "329/329 [==============================] - 0s 927us/step - loss: 0.3578 - accuracy: 0.8260\n",
      "Epoch 47/50\n",
      "329/329 [==============================] - 0s 963us/step - loss: 0.3575 - accuracy: 0.8278\n",
      "Epoch 48/50\n",
      "329/329 [==============================] - 0s 892us/step - loss: 0.3574 - accuracy: 0.8308\n",
      "Epoch 49/50\n",
      "329/329 [==============================] - 0s 1ms/step - loss: 0.3573 - accuracy: 0.8296\n",
      "Epoch 50/50\n",
      "329/329 [==============================] - 0s 957us/step - loss: 0.3567 - accuracy: 0.8275\n",
      "Epoch 1/50\n",
      "328/328 [==============================] - 0s 890us/step - loss: 0.3655 - accuracy: 0.8309\n",
      "Epoch 2/50\n",
      "328/328 [==============================] - 0s 1ms/step - loss: 0.3623 - accuracy: 0.8295\n",
      "Epoch 3/50\n",
      "328/328 [==============================] - 0s 951us/step - loss: 0.3610 - accuracy: 0.8294\n",
      "Epoch 4/50\n",
      "328/328 [==============================] - 0s 906us/step - loss: 0.3608 - accuracy: 0.8297\n",
      "Epoch 5/50\n",
      "328/328 [==============================] - 0s 1ms/step - loss: 0.3606 - accuracy: 0.8309\n",
      "Epoch 6/50\n",
      "328/328 [==============================] - 0s 909us/step - loss: 0.3595 - accuracy: 0.8294\n",
      "Epoch 7/50\n",
      "328/328 [==============================] - 0s 925us/step - loss: 0.3591 - accuracy: 0.8282\n",
      "Epoch 8/50\n",
      "328/328 [==============================] - 0s 930us/step - loss: 0.3585 - accuracy: 0.8300\n",
      "Epoch 9/50\n",
      "328/328 [==============================] - 0s 950us/step - loss: 0.3583 - accuracy: 0.8283\n",
      "Epoch 10/50\n",
      "328/328 [==============================] - 0s 958us/step - loss: 0.3581 - accuracy: 0.8302\n",
      "Epoch 11/50\n",
      "328/328 [==============================] - 0s 953us/step - loss: 0.3577 - accuracy: 0.8291\n",
      "Epoch 12/50\n",
      "328/328 [==============================] - 0s 945us/step - loss: 0.3574 - accuracy: 0.8302\n",
      "Epoch 13/50\n",
      "328/328 [==============================] - 0s 956us/step - loss: 0.3569 - accuracy: 0.8320\n",
      "Epoch 14/50\n",
      "328/328 [==============================] - 0s 936us/step - loss: 0.3566 - accuracy: 0.8321\n",
      "Epoch 15/50\n",
      "328/328 [==============================] - 0s 925us/step - loss: 0.3569 - accuracy: 0.8285\n",
      "Epoch 16/50\n",
      "328/328 [==============================] - 0s 1ms/step - loss: 0.3562 - accuracy: 0.8317\n",
      "Epoch 17/50\n",
      "328/328 [==============================] - 0s 962us/step - loss: 0.3563 - accuracy: 0.8308\n",
      "Epoch 18/50\n",
      "328/328 [==============================] - 0s 948us/step - loss: 0.3557 - accuracy: 0.8297\n",
      "Epoch 19/50\n",
      "328/328 [==============================] - 0s 940us/step - loss: 0.3557 - accuracy: 0.8331\n",
      "Epoch 20/50\n",
      "328/328 [==============================] - 0s 1ms/step - loss: 0.3553 - accuracy: 0.8315\n",
      "Epoch 21/50\n",
      "328/328 [==============================] - 0s 998us/step - loss: 0.3551 - accuracy: 0.8311\n",
      "Epoch 22/50\n",
      "328/328 [==============================] - 0s 982us/step - loss: 0.3555 - accuracy: 0.8302\n",
      "Epoch 23/50\n",
      "328/328 [==============================] - 0s 950us/step - loss: 0.3552 - accuracy: 0.8297\n",
      "Epoch 24/50\n",
      "328/328 [==============================] - 0s 899us/step - loss: 0.3548 - accuracy: 0.8324\n",
      "Epoch 25/50\n",
      "328/328 [==============================] - 0s 896us/step - loss: 0.3545 - accuracy: 0.8331\n",
      "Epoch 26/50\n",
      "328/328 [==============================] - 0s 982us/step - loss: 0.3545 - accuracy: 0.8329\n",
      "Epoch 27/50\n",
      "328/328 [==============================] - 0s 905us/step - loss: 0.3548 - accuracy: 0.8303\n",
      "Epoch 28/50\n",
      "328/328 [==============================] - 0s 894us/step - loss: 0.3541 - accuracy: 0.8283\n",
      "Epoch 29/50\n",
      "328/328 [==============================] - 0s 885us/step - loss: 0.3539 - accuracy: 0.8324\n",
      "Epoch 30/50\n",
      "328/328 [==============================] - 0s 983us/step - loss: 0.3540 - accuracy: 0.8312\n",
      "Epoch 31/50\n",
      "328/328 [==============================] - 0s 915us/step - loss: 0.3540 - accuracy: 0.8332\n",
      "Epoch 32/50\n",
      "328/328 [==============================] - 0s 913us/step - loss: 0.3538 - accuracy: 0.8320\n",
      "Epoch 33/50\n",
      "328/328 [==============================] - 0s 902us/step - loss: 0.3538 - accuracy: 0.8308\n",
      "Epoch 34/50\n",
      "328/328 [==============================] - 0s 958us/step - loss: 0.3533 - accuracy: 0.8326\n",
      "Epoch 35/50\n",
      "328/328 [==============================] - 0s 884us/step - loss: 0.3529 - accuracy: 0.8331\n",
      "Epoch 36/50\n",
      "328/328 [==============================] - 0s 882us/step - loss: 0.3531 - accuracy: 0.8305\n",
      "Epoch 37/50\n",
      "328/328 [==============================] - 0s 947us/step - loss: 0.3528 - accuracy: 0.8332\n",
      "Epoch 38/50\n",
      "328/328 [==============================] - 0s 879us/step - loss: 0.3530 - accuracy: 0.8327\n",
      "Epoch 39/50\n",
      "328/328 [==============================] - 0s 902us/step - loss: 0.3529 - accuracy: 0.8318\n",
      "Epoch 40/50\n",
      "328/328 [==============================] - 0s 955us/step - loss: 0.3525 - accuracy: 0.8346\n",
      "Epoch 41/50\n",
      "328/328 [==============================] - 0s 882us/step - loss: 0.3528 - accuracy: 0.8334\n",
      "Epoch 42/50\n",
      "328/328 [==============================] - 0s 972us/step - loss: 0.3529 - accuracy: 0.8324\n",
      "Epoch 43/50\n",
      "328/328 [==============================] - 0s 897us/step - loss: 0.3519 - accuracy: 0.8329\n",
      "Epoch 44/50\n",
      "328/328 [==============================] - 0s 891us/step - loss: 0.3522 - accuracy: 0.8324\n",
      "Epoch 45/50\n",
      "328/328 [==============================] - 0s 907us/step - loss: 0.3520 - accuracy: 0.8344\n",
      "Epoch 46/50\n",
      "328/328 [==============================] - 0s 890us/step - loss: 0.3522 - accuracy: 0.8352\n",
      "Epoch 47/50\n",
      "328/328 [==============================] - 0s 908us/step - loss: 0.3518 - accuracy: 0.8349\n",
      "Epoch 48/50\n",
      "328/328 [==============================] - 0s 962us/step - loss: 0.3519 - accuracy: 0.8353\n",
      "Epoch 49/50\n",
      "328/328 [==============================] - 0s 963us/step - loss: 0.3518 - accuracy: 0.8350\n",
      "Epoch 50/50\n",
      "328/328 [==============================] - 0s 1ms/step - loss: 0.3519 - accuracy: 0.8318\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "329/329 [==============================] - 0s 899us/step - loss: 0.3603 - accuracy: 0.8244\n",
      "Epoch 2/50\n",
      "329/329 [==============================] - 0s 907us/step - loss: 0.3572 - accuracy: 0.8267\n",
      "Epoch 3/50\n",
      "329/329 [==============================] - 0s 911us/step - loss: 0.3556 - accuracy: 0.8292\n",
      "Epoch 4/50\n",
      "329/329 [==============================] - 0s 912us/step - loss: 0.3545 - accuracy: 0.8305\n",
      "Epoch 5/50\n",
      "329/329 [==============================] - 0s 905us/step - loss: 0.3543 - accuracy: 0.8301\n",
      "Epoch 6/50\n",
      "329/329 [==============================] - 0s 937us/step - loss: 0.3533 - accuracy: 0.8295\n",
      "Epoch 7/50\n",
      "329/329 [==============================] - 0s 898us/step - loss: 0.3530 - accuracy: 0.8308\n",
      "Epoch 8/50\n",
      "329/329 [==============================] - 0s 993us/step - loss: 0.3527 - accuracy: 0.8281\n",
      "Epoch 9/50\n",
      "329/329 [==============================] - 0s 1ms/step - loss: 0.3524 - accuracy: 0.8293\n",
      "Epoch 10/50\n",
      "329/329 [==============================] - 0s 1ms/step - loss: 0.3519 - accuracy: 0.8318\n",
      "Epoch 11/50\n",
      "329/329 [==============================] - 0s 944us/step - loss: 0.3520 - accuracy: 0.8299\n",
      "Epoch 12/50\n",
      "329/329 [==============================] - 0s 1ms/step - loss: 0.3517 - accuracy: 0.8298\n",
      "Epoch 13/50\n",
      "329/329 [==============================] - 0s 1ms/step - loss: 0.3514 - accuracy: 0.8311\n",
      "Epoch 14/50\n",
      "329/329 [==============================] - 0s 938us/step - loss: 0.3509 - accuracy: 0.8305\n",
      "Epoch 15/50\n",
      "329/329 [==============================] - 0s 1ms/step - loss: 0.3513 - accuracy: 0.8299\n",
      "Epoch 16/50\n",
      "329/329 [==============================] - 0s 1ms/step - loss: 0.3514 - accuracy: 0.8298\n",
      "Epoch 17/50\n",
      "329/329 [==============================] - 0s 1ms/step - loss: 0.3510 - accuracy: 0.8322\n",
      "Epoch 18/50\n",
      "329/329 [==============================] - 0s 950us/step - loss: 0.3506 - accuracy: 0.8308\n",
      "Epoch 19/50\n",
      "329/329 [==============================] - 0s 871us/step - loss: 0.3502 - accuracy: 0.8307\n",
      "Epoch 20/50\n",
      "329/329 [==============================] - 0s 890us/step - loss: 0.3503 - accuracy: 0.8318\n",
      "Epoch 21/50\n",
      "329/329 [==============================] - 0s 983us/step - loss: 0.3504 - accuracy: 0.8307\n",
      "Epoch 22/50\n",
      "329/329 [==============================] - 0s 926us/step - loss: 0.3499 - accuracy: 0.8305\n",
      "Epoch 23/50\n",
      "329/329 [==============================] - 0s 907us/step - loss: 0.3500 - accuracy: 0.8295\n",
      "Epoch 24/50\n",
      "329/329 [==============================] - 0s 945us/step - loss: 0.3500 - accuracy: 0.8296\n",
      "Epoch 25/50\n",
      "329/329 [==============================] - 0s 923us/step - loss: 0.3495 - accuracy: 0.8304\n",
      "Epoch 26/50\n",
      "329/329 [==============================] - 0s 1ms/step - loss: 0.3491 - accuracy: 0.8307\n",
      "Epoch 27/50\n",
      "329/329 [==============================] - 0s 938us/step - loss: 0.3493 - accuracy: 0.8308\n",
      "Epoch 28/50\n",
      "329/329 [==============================] - 0s 897us/step - loss: 0.3494 - accuracy: 0.8315\n",
      "Epoch 29/50\n",
      "329/329 [==============================] - 0s 899us/step - loss: 0.3490 - accuracy: 0.8311\n",
      "Epoch 30/50\n",
      "329/329 [==============================] - 0s 941us/step - loss: 0.3490 - accuracy: 0.8319\n",
      "Epoch 31/50\n",
      "329/329 [==============================] - 0s 914us/step - loss: 0.3488 - accuracy: 0.8318\n",
      "Epoch 32/50\n",
      "329/329 [==============================] - 0s 1ms/step - loss: 0.3492 - accuracy: 0.8311\n",
      "Epoch 33/50\n",
      "329/329 [==============================] - 0s 1ms/step - loss: 0.3491 - accuracy: 0.8304\n",
      "Epoch 34/50\n",
      "329/329 [==============================] - 0s 927us/step - loss: 0.3486 - accuracy: 0.8307\n",
      "Epoch 35/50\n",
      "329/329 [==============================] - 0s 906us/step - loss: 0.3486 - accuracy: 0.8319\n",
      "Epoch 36/50\n",
      "329/329 [==============================] - 0s 907us/step - loss: 0.3483 - accuracy: 0.8310\n",
      "Epoch 37/50\n",
      "329/329 [==============================] - 0s 1ms/step - loss: 0.3485 - accuracy: 0.8296\n",
      "Epoch 38/50\n",
      "329/329 [==============================] - 0s 937us/step - loss: 0.3484 - accuracy: 0.8340\n",
      "Epoch 39/50\n",
      "329/329 [==============================] - 0s 975us/step - loss: 0.3487 - accuracy: 0.8318\n",
      "Epoch 40/50\n",
      "329/329 [==============================] - 0s 952us/step - loss: 0.3482 - accuracy: 0.83100s - loss: 0.3486 - accuracy: \n",
      "Epoch 41/50\n",
      "329/329 [==============================] - 0s 929us/step - loss: 0.3479 - accuracy: 0.8331\n",
      "Epoch 42/50\n",
      "329/329 [==============================] - 0s 980us/step - loss: 0.3478 - accuracy: 0.8313\n",
      "Epoch 43/50\n",
      "329/329 [==============================] - 0s 1ms/step - loss: 0.3477 - accuracy: 0.8316\n",
      "Epoch 44/50\n",
      "329/329 [==============================] - 0s 964us/step - loss: 0.3480 - accuracy: 0.8327\n",
      "Epoch 45/50\n",
      "329/329 [==============================] - 0s 957us/step - loss: 0.3474 - accuracy: 0.8308\n",
      "Epoch 46/50\n",
      "329/329 [==============================] - 0s 1ms/step - loss: 0.3475 - accuracy: 0.8343\n",
      "Epoch 47/50\n",
      "329/329 [==============================] - 0s 910us/step - loss: 0.3473 - accuracy: 0.8331\n",
      "Epoch 48/50\n",
      "329/329 [==============================] - 0s 937us/step - loss: 0.3470 - accuracy: 0.8336\n",
      "Epoch 49/50\n",
      "329/329 [==============================] - 0s 948us/step - loss: 0.3473 - accuracy: 0.8321\n",
      "Epoch 50/50\n",
      "329/329 [==============================] - 0s 950us/step - loss: 0.3472 - accuracy: 0.8347\n",
      "Epoch 1/50\n",
      "328/328 [==============================] - 0s 1ms/step - loss: 0.3731 - accuracy: 0.8170\n",
      "Epoch 2/50\n",
      "328/328 [==============================] - 0s 990us/step - loss: 0.3688 - accuracy: 0.8208\n",
      "Epoch 3/50\n",
      "328/328 [==============================] - 0s 909us/step - loss: 0.3674 - accuracy: 0.8198\n",
      "Epoch 4/50\n",
      "328/328 [==============================] - 0s 939us/step - loss: 0.3661 - accuracy: 0.8220\n",
      "Epoch 5/50\n",
      "328/328 [==============================] - 0s 1ms/step - loss: 0.3656 - accuracy: 0.8182\n",
      "Epoch 6/50\n",
      "328/328 [==============================] - 0s 994us/step - loss: 0.3653 - accuracy: 0.8225\n",
      "Epoch 7/50\n",
      "328/328 [==============================] - 0s 1ms/step - loss: 0.3645 - accuracy: 0.8173\n",
      "Epoch 8/50\n",
      "328/328 [==============================] - 0s 909us/step - loss: 0.3644 - accuracy: 0.8184\n",
      "Epoch 9/50\n",
      "328/328 [==============================] - 0s 928us/step - loss: 0.3637 - accuracy: 0.8199\n",
      "Epoch 10/50\n",
      "328/328 [==============================] - 0s 952us/step - loss: 0.3633 - accuracy: 0.8217\n",
      "Epoch 11/50\n",
      "328/328 [==============================] - 0s 978us/step - loss: 0.3634 - accuracy: 0.8190\n",
      "Epoch 12/50\n",
      "328/328 [==============================] - 0s 1ms/step - loss: 0.3632 - accuracy: 0.8217\n",
      "Epoch 13/50\n",
      "328/328 [==============================] - 0s 982us/step - loss: 0.3627 - accuracy: 0.8217\n",
      "Epoch 14/50\n",
      "328/328 [==============================] - 0s 1ms/step - loss: 0.3619 - accuracy: 0.8192\n",
      "Epoch 15/50\n",
      "328/328 [==============================] - 0s 1ms/step - loss: 0.3625 - accuracy: 0.8196\n",
      "Epoch 16/50\n",
      "328/328 [==============================] - 0s 920us/step - loss: 0.3620 - accuracy: 0.8184\n",
      "Epoch 17/50\n",
      "328/328 [==============================] - 0s 919us/step - loss: 0.3618 - accuracy: 0.8207\n",
      "Epoch 18/50\n",
      "328/328 [==============================] - 0s 915us/step - loss: 0.3617 - accuracy: 0.8219\n",
      "Epoch 19/50\n",
      "328/328 [==============================] - 0s 1ms/step - loss: 0.3614 - accuracy: 0.8193\n",
      "Epoch 20/50\n",
      "328/328 [==============================] - 0s 907us/step - loss: 0.3613 - accuracy: 0.8207\n",
      "Epoch 21/50\n",
      "328/328 [==============================] - 0s 913us/step - loss: 0.3612 - accuracy: 0.8213\n",
      "Epoch 22/50\n",
      "328/328 [==============================] - 0s 887us/step - loss: 0.3611 - accuracy: 0.8204\n",
      "Epoch 23/50\n",
      "328/328 [==============================] - 0s 893us/step - loss: 0.3606 - accuracy: 0.8196\n",
      "Epoch 24/50\n",
      "328/328 [==============================] - 0s 914us/step - loss: 0.3604 - accuracy: 0.8198\n",
      "Epoch 25/50\n",
      "328/328 [==============================] - 0s 892us/step - loss: 0.3605 - accuracy: 0.8225\n",
      "Epoch 26/50\n",
      "328/328 [==============================] - 0s 1ms/step - loss: 0.3599 - accuracy: 0.8213\n",
      "Epoch 27/50\n",
      "328/328 [==============================] - 0s 1ms/step - loss: 0.3604 - accuracy: 0.8188\n",
      "Epoch 28/50\n",
      "328/328 [==============================] - 0s 1ms/step - loss: 0.3600 - accuracy: 0.8237\n",
      "Epoch 29/50\n",
      "328/328 [==============================] - 0s 897us/step - loss: 0.3596 - accuracy: 0.8230\n",
      "Epoch 30/50\n",
      "328/328 [==============================] - 0s 894us/step - loss: 0.3596 - accuracy: 0.8184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50\n",
      "328/328 [==============================] - 0s 919us/step - loss: 0.3601 - accuracy: 0.8207\n",
      "Epoch 32/50\n",
      "328/328 [==============================] - 0s 969us/step - loss: 0.3595 - accuracy: 0.8188\n",
      "Epoch 33/50\n",
      "328/328 [==============================] - 0s 877us/step - loss: 0.3598 - accuracy: 0.8199\n",
      "Epoch 34/50\n",
      "328/328 [==============================] - 0s 877us/step - loss: 0.3589 - accuracy: 0.8214\n",
      "Epoch 35/50\n",
      "328/328 [==============================] - 0s 974us/step - loss: 0.3590 - accuracy: 0.8210\n",
      "Epoch 36/50\n",
      "328/328 [==============================] - 0s 914us/step - loss: 0.3588 - accuracy: 0.8211\n",
      "Epoch 37/50\n",
      "328/328 [==============================] - 0s 967us/step - loss: 0.3590 - accuracy: 0.8195\n",
      "Epoch 38/50\n",
      "328/328 [==============================] - 0s 917us/step - loss: 0.3589 - accuracy: 0.8211\n",
      "Epoch 39/50\n",
      "328/328 [==============================] - 0s 901us/step - loss: 0.3589 - accuracy: 0.8202\n",
      "Epoch 40/50\n",
      "328/328 [==============================] - 0s 907us/step - loss: 0.3585 - accuracy: 0.8217\n",
      "Epoch 41/50\n",
      "328/328 [==============================] - 0s 908us/step - loss: 0.3583 - accuracy: 0.8202\n",
      "Epoch 42/50\n",
      "328/328 [==============================] - 0s 894us/step - loss: 0.3577 - accuracy: 0.8205\n",
      "Epoch 43/50\n",
      "328/328 [==============================] - 0s 881us/step - loss: 0.3576 - accuracy: 0.8231\n",
      "Epoch 44/50\n",
      "328/328 [==============================] - 0s 884us/step - loss: 0.3579 - accuracy: 0.8216\n",
      "Epoch 45/50\n",
      "328/328 [==============================] - 0s 908us/step - loss: 0.3576 - accuracy: 0.8231\n",
      "Epoch 46/50\n",
      "328/328 [==============================] - 0s 909us/step - loss: 0.3579 - accuracy: 0.8242\n",
      "Epoch 47/50\n",
      "328/328 [==============================] - 0s 875us/step - loss: 0.3576 - accuracy: 0.8248\n",
      "Epoch 48/50\n",
      "328/328 [==============================] - 0s 1ms/step - loss: 0.3573 - accuracy: 0.8219\n",
      "Epoch 49/50\n",
      "328/328 [==============================] - 0s 886us/step - loss: 0.3574 - accuracy: 0.8233\n",
      "Epoch 50/50\n",
      "328/328 [==============================] - 0s 898us/step - loss: 0.3569 - accuracy: 0.8217\n",
      "Epoch 1/50\n",
      "329/329 [==============================] - 0s 877us/step - loss: 0.3767 - accuracy: 0.8159\n",
      "Epoch 2/50\n",
      "329/329 [==============================] - 0s 890us/step - loss: 0.3724 - accuracy: 0.8162\n",
      "Epoch 3/50\n",
      "329/329 [==============================] - 0s 889us/step - loss: 0.3698 - accuracy: 0.8206\n",
      "Epoch 4/50\n",
      "329/329 [==============================] - 0s 902us/step - loss: 0.3673 - accuracy: 0.8197\n",
      "Epoch 5/50\n",
      "329/329 [==============================] - 0s 884us/step - loss: 0.3662 - accuracy: 0.8183\n",
      "Epoch 6/50\n",
      "329/329 [==============================] - 0s 903us/step - loss: 0.3652 - accuracy: 0.8177\n",
      "Epoch 7/50\n",
      "329/329 [==============================] - 0s 960us/step - loss: 0.3644 - accuracy: 0.8188\n",
      "Epoch 8/50\n",
      "329/329 [==============================] - 0s 1ms/step - loss: 0.3632 - accuracy: 0.8177\n",
      "Epoch 9/50\n",
      "329/329 [==============================] - 0s 960us/step - loss: 0.3628 - accuracy: 0.8194\n",
      "Epoch 10/50\n",
      "329/329 [==============================] - 0s 919us/step - loss: 0.3626 - accuracy: 0.8197\n",
      "Epoch 11/50\n",
      "329/329 [==============================] - 0s 979us/step - loss: 0.3622 - accuracy: 0.8218\n",
      "Epoch 12/50\n",
      "329/329 [==============================] - 0s 1ms/step - loss: 0.3618 - accuracy: 0.8214\n",
      "Epoch 13/50\n",
      "329/329 [==============================] - 0s 986us/step - loss: 0.3617 - accuracy: 0.8221\n",
      "Epoch 14/50\n",
      "329/329 [==============================] - 0s 991us/step - loss: 0.3611 - accuracy: 0.8218\n",
      "Epoch 15/50\n",
      "329/329 [==============================] - 0s 920us/step - loss: 0.3605 - accuracy: 0.8215\n",
      "Epoch 16/50\n",
      "329/329 [==============================] - 0s 929us/step - loss: 0.3608 - accuracy: 0.8203\n",
      "Epoch 17/50\n",
      "329/329 [==============================] - 0s 982us/step - loss: 0.3607 - accuracy: 0.8202\n",
      "Epoch 18/50\n",
      "329/329 [==============================] - 0s 937us/step - loss: 0.3606 - accuracy: 0.8223\n",
      "Epoch 19/50\n",
      "329/329 [==============================] - 0s 916us/step - loss: 0.3601 - accuracy: 0.8212\n",
      "Epoch 20/50\n",
      "329/329 [==============================] - 0s 909us/step - loss: 0.3603 - accuracy: 0.8220\n",
      "Epoch 21/50\n",
      "329/329 [==============================] - ETA: 0s - loss: 0.3603 - accuracy: 0.81 - 0s 924us/step - loss: 0.3593 - accuracy: 0.8191\n",
      "Epoch 22/50\n",
      "329/329 [==============================] - 0s 864us/step - loss: 0.3597 - accuracy: 0.8206\n",
      "Epoch 23/50\n",
      "329/329 [==============================] - 0s 887us/step - loss: 0.3594 - accuracy: 0.8218\n",
      "Epoch 24/50\n",
      "329/329 [==============================] - 0s 953us/step - loss: 0.3591 - accuracy: 0.8220\n",
      "Epoch 25/50\n",
      "329/329 [==============================] - 0s 947us/step - loss: 0.3588 - accuracy: 0.8221\n",
      "Epoch 26/50\n",
      "329/329 [==============================] - 0s 1ms/step - loss: 0.3590 - accuracy: 0.8215\n",
      "Epoch 27/50\n",
      "329/329 [==============================] - 0s 912us/step - loss: 0.3589 - accuracy: 0.8217\n",
      "Epoch 28/50\n",
      "329/329 [==============================] - 0s 939us/step - loss: 0.3589 - accuracy: 0.8199\n",
      "Epoch 29/50\n",
      "329/329 [==============================] - 0s 897us/step - loss: 0.3585 - accuracy: 0.8226\n",
      "Epoch 30/50\n",
      "329/329 [==============================] - 0s 910us/step - loss: 0.3591 - accuracy: 0.8186\n",
      "Epoch 31/50\n",
      "329/329 [==============================] - 0s 913us/step - loss: 0.3583 - accuracy: 0.8214\n",
      "Epoch 32/50\n",
      "329/329 [==============================] - 0s 901us/step - loss: 0.3586 - accuracy: 0.8209\n",
      "Epoch 33/50\n",
      "329/329 [==============================] - 0s 902us/step - loss: 0.3580 - accuracy: 0.8196\n",
      "Epoch 34/50\n",
      "329/329 [==============================] - 0s 916us/step - loss: 0.3585 - accuracy: 0.8223\n",
      "Epoch 35/50\n",
      "329/329 [==============================] - 0s 981us/step - loss: 0.3580 - accuracy: 0.8199\n",
      "Epoch 36/50\n",
      "329/329 [==============================] - 0s 980us/step - loss: 0.3570 - accuracy: 0.8215\n",
      "Epoch 37/50\n",
      "329/329 [==============================] - 0s 935us/step - loss: 0.3575 - accuracy: 0.8214\n",
      "Epoch 38/50\n",
      "329/329 [==============================] - 0s 1ms/step - loss: 0.3579 - accuracy: 0.8221\n",
      "Epoch 39/50\n",
      "329/329 [==============================] - 0s 900us/step - loss: 0.3577 - accuracy: 0.8203\n",
      "Epoch 40/50\n",
      "329/329 [==============================] - 0s 959us/step - loss: 0.3577 - accuracy: 0.8234\n",
      "Epoch 41/50\n",
      "329/329 [==============================] - 0s 936us/step - loss: 0.3576 - accuracy: 0.8200\n",
      "Epoch 42/50\n",
      "329/329 [==============================] - 0s 936us/step - loss: 0.3571 - accuracy: 0.8218\n",
      "Epoch 43/50\n",
      "329/329 [==============================] - 0s 973us/step - loss: 0.3570 - accuracy: 0.8252\n",
      "Epoch 44/50\n",
      "329/329 [==============================] - 0s 1ms/step - loss: 0.3569 - accuracy: 0.8206\n",
      "Epoch 45/50\n",
      "329/329 [==============================] - 0s 899us/step - loss: 0.3570 - accuracy: 0.8243\n",
      "Epoch 46/50\n",
      "329/329 [==============================] - 0s 925us/step - loss: 0.3569 - accuracy: 0.8235\n",
      "Epoch 47/50\n",
      "329/329 [==============================] - 0s 911us/step - loss: 0.3567 - accuracy: 0.8217\n",
      "Epoch 48/50\n",
      "329/329 [==============================] - 0s 917us/step - loss: 0.3567 - accuracy: 0.8231\n",
      "Epoch 49/50\n",
      "329/329 [==============================] - 0s 967us/step - loss: 0.3568 - accuracy: 0.8200\n",
      "Epoch 50/50\n",
      "329/329 [==============================] - 0s 982us/step - loss: 0.3566 - accuracy: 0.8218\n",
      "Epoch 1/50\n",
      "329/329 [==============================] - 0s 1ms/step - loss: 0.3602 - accuracy: 0.8263\n",
      "Epoch 2/50\n",
      "329/329 [==============================] - 0s 921us/step - loss: 0.3573 - accuracy: 0.8275\n",
      "Epoch 3/50\n",
      "329/329 [==============================] - 0s 912us/step - loss: 0.3567 - accuracy: 0.8282\n",
      "Epoch 4/50\n",
      "329/329 [==============================] - 0s 942us/step - loss: 0.3553 - accuracy: 0.8315\n",
      "Epoch 5/50\n",
      "329/329 [==============================] - 0s 936us/step - loss: 0.3546 - accuracy: 0.8309\n",
      "Epoch 6/50\n",
      "329/329 [==============================] - 0s 1ms/step - loss: 0.3547 - accuracy: 0.8301\n",
      "Epoch 7/50\n",
      "329/329 [==============================] - 0s 952us/step - loss: 0.3537 - accuracy: 0.8312\n",
      "Epoch 8/50\n",
      "329/329 [==============================] - 0s 989us/step - loss: 0.3537 - accuracy: 0.8295\n",
      "Epoch 9/50\n",
      "329/329 [==============================] - 0s 1ms/step - loss: 0.3531 - accuracy: 0.8314\n",
      "Epoch 10/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "329/329 [==============================] - 0s 903us/step - loss: 0.3529 - accuracy: 0.8300\n",
      "Epoch 11/50\n",
      "329/329 [==============================] - 0s 939us/step - loss: 0.3527 - accuracy: 0.8307\n",
      "Epoch 12/50\n",
      "329/329 [==============================] - 0s 972us/step - loss: 0.3527 - accuracy: 0.8307\n",
      "Epoch 13/50\n",
      "329/329 [==============================] - 0s 893us/step - loss: 0.3523 - accuracy: 0.8320\n",
      "Epoch 14/50\n",
      "329/329 [==============================] - 0s 884us/step - loss: 0.3524 - accuracy: 0.8329\n",
      "Epoch 15/50\n",
      "329/329 [==============================] - 0s 901us/step - loss: 0.3518 - accuracy: 0.8338\n",
      "Epoch 16/50\n",
      "329/329 [==============================] - 0s 906us/step - loss: 0.3518 - accuracy: 0.8318\n",
      "Epoch 17/50\n",
      "329/329 [==============================] - 0s 884us/step - loss: 0.3513 - accuracy: 0.8344\n",
      "Epoch 18/50\n",
      "329/329 [==============================] - 0s 1ms/step - loss: 0.3516 - accuracy: 0.8341\n",
      "Epoch 19/50\n",
      "329/329 [==============================] - 0s 998us/step - loss: 0.3509 - accuracy: 0.8347\n",
      "Epoch 20/50\n",
      "329/329 [==============================] - 0s 904us/step - loss: 0.3506 - accuracy: 0.8317\n",
      "Epoch 21/50\n",
      "329/329 [==============================] - 0s 958us/step - loss: 0.3503 - accuracy: 0.8342\n",
      "Epoch 22/50\n",
      "329/329 [==============================] - 0s 935us/step - loss: 0.3503 - accuracy: 0.8346\n",
      "Epoch 23/50\n",
      "329/329 [==============================] - 0s 1ms/step - loss: 0.3501 - accuracy: 0.8342\n",
      "Epoch 24/50\n",
      "329/329 [==============================] - 0s 944us/step - loss: 0.3497 - accuracy: 0.8356\n",
      "Epoch 25/50\n",
      "329/329 [==============================] - 0s 953us/step - loss: 0.3495 - accuracy: 0.8346\n",
      "Epoch 26/50\n",
      "329/329 [==============================] - 0s 1ms/step - loss: 0.3498 - accuracy: 0.8349\n",
      "Epoch 27/50\n",
      "329/329 [==============================] - 0s 1ms/step - loss: 0.3489 - accuracy: 0.8370\n",
      "Epoch 28/50\n",
      "329/329 [==============================] - 0s 905us/step - loss: 0.3484 - accuracy: 0.8347\n",
      "Epoch 29/50\n",
      "329/329 [==============================] - 0s 911us/step - loss: 0.3488 - accuracy: 0.8358\n",
      "Epoch 30/50\n",
      "329/329 [==============================] - 0s 970us/step - loss: 0.3483 - accuracy: 0.8367\n",
      "Epoch 31/50\n",
      "329/329 [==============================] - 0s 913us/step - loss: 0.3489 - accuracy: 0.8368\n",
      "Epoch 32/50\n",
      "329/329 [==============================] - 0s 965us/step - loss: 0.3478 - accuracy: 0.8359\n",
      "Epoch 33/50\n",
      "329/329 [==============================] - 0s 972us/step - loss: 0.3484 - accuracy: 0.8374\n",
      "Epoch 34/50\n",
      "329/329 [==============================] - 0s 898us/step - loss: 0.3473 - accuracy: 0.8374\n",
      "Epoch 35/50\n",
      "329/329 [==============================] - 0s 910us/step - loss: 0.3480 - accuracy: 0.8365\n",
      "Epoch 36/50\n",
      "329/329 [==============================] - 0s 929us/step - loss: 0.3480 - accuracy: 0.8373\n",
      "Epoch 37/50\n",
      "329/329 [==============================] - 0s 956us/step - loss: 0.3477 - accuracy: 0.8385\n",
      "Epoch 38/50\n",
      "329/329 [==============================] - 0s 905us/step - loss: 0.3472 - accuracy: 0.8376\n",
      "Epoch 39/50\n",
      "329/329 [==============================] - 0s 942us/step - loss: 0.3471 - accuracy: 0.8358\n",
      "Epoch 40/50\n",
      "329/329 [==============================] - 0s 1ms/step - loss: 0.3476 - accuracy: 0.8391\n",
      "Epoch 41/50\n",
      "329/329 [==============================] - 0s 895us/step - loss: 0.3470 - accuracy: 0.8387\n",
      "Epoch 42/50\n",
      "329/329 [==============================] - 0s 897us/step - loss: 0.3473 - accuracy: 0.8367\n",
      "Epoch 43/50\n",
      "329/329 [==============================] - 0s 891us/step - loss: 0.3475 - accuracy: 0.8352\n",
      "Epoch 44/50\n",
      "329/329 [==============================] - 0s 900us/step - loss: 0.3470 - accuracy: 0.8371\n",
      "Epoch 45/50\n",
      "329/329 [==============================] - 0s 891us/step - loss: 0.3468 - accuracy: 0.8371\n",
      "Epoch 46/50\n",
      "329/329 [==============================] - 0s 917us/step - loss: 0.3472 - accuracy: 0.8367\n",
      "Epoch 47/50\n",
      "329/329 [==============================] - 0s 966us/step - loss: 0.3467 - accuracy: 0.8364\n",
      "Epoch 48/50\n",
      "329/329 [==============================] - 0s 1ms/step - loss: 0.3470 - accuracy: 0.8362\n",
      "Epoch 49/50\n",
      "329/329 [==============================] - 0s 909us/step - loss: 0.3459 - accuracy: 0.8390\n",
      "Epoch 50/50\n",
      "329/329 [==============================] - 0s 901us/step - loss: 0.3467 - accuracy: 0.8371\n",
      "Average accuracy for model 2:  83.11154598825833\n",
      "Epoch 1/75\n",
      "657/657 [==============================] - 1s 888us/step - loss: 0.4882 - accuracy: 0.7415\n",
      "Epoch 2/75\n",
      "657/657 [==============================] - 1s 895us/step - loss: 0.4289 - accuracy: 0.7835\n",
      "Epoch 3/75\n",
      "657/657 [==============================] - 1s 932us/step - loss: 0.4202 - accuracy: 0.7917\n",
      "Epoch 4/75\n",
      "657/657 [==============================] - 1s 910us/step - loss: 0.4135 - accuracy: 0.7982\n",
      "Epoch 5/75\n",
      "657/657 [==============================] - 1s 916us/step - loss: 0.4081 - accuracy: 0.7995\n",
      "Epoch 6/75\n",
      "657/657 [==============================] - 1s 932us/step - loss: 0.4043 - accuracy: 0.8028\n",
      "Epoch 7/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.4004 - accuracy: 0.8089\n",
      "Epoch 8/75\n",
      "657/657 [==============================] - 1s 954us/step - loss: 0.3963 - accuracy: 0.8089\n",
      "Epoch 9/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.3938 - accuracy: 0.8127\n",
      "Epoch 10/75\n",
      "657/657 [==============================] - 1s 963us/step - loss: 0.3909 - accuracy: 0.8127\n",
      "Epoch 11/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.3882 - accuracy: 0.8161\n",
      "Epoch 12/75\n",
      "657/657 [==============================] - 1s 940us/step - loss: 0.3862 - accuracy: 0.8145\n",
      "Epoch 13/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.3832 - accuracy: 0.8147\n",
      "Epoch 14/75\n",
      "657/657 [==============================] - 1s 900us/step - loss: 0.3808 - accuracy: 0.8185\n",
      "Epoch 15/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.3787 - accuracy: 0.8202\n",
      "Epoch 16/75\n",
      "657/657 [==============================] - 1s 950us/step - loss: 0.3764 - accuracy: 0.8191\n",
      "Epoch 17/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.3744 - accuracy: 0.8200\n",
      "Epoch 18/75\n",
      "657/657 [==============================] - 1s 947us/step - loss: 0.3717 - accuracy: 0.8209\n",
      "Epoch 19/75\n",
      "657/657 [==============================] - 1s 943us/step - loss: 0.3716 - accuracy: 0.8222\n",
      "Epoch 20/75\n",
      "657/657 [==============================] - 1s 979us/step - loss: 0.3698 - accuracy: 0.8222\n",
      "Epoch 21/75\n",
      "657/657 [==============================] - 1s 987us/step - loss: 0.3683 - accuracy: 0.8254\n",
      "Epoch 22/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.3666 - accuracy: 0.8249\n",
      "Epoch 23/75\n",
      "657/657 [==============================] - 1s 998us/step - loss: 0.3641 - accuracy: 0.8279\n",
      "Epoch 24/75\n",
      "657/657 [==============================] - 1s 997us/step - loss: 0.3625 - accuracy: 0.8261\n",
      "Epoch 25/75\n",
      "657/657 [==============================] - 1s 979us/step - loss: 0.3618 - accuracy: 0.8275\n",
      "Epoch 26/75\n",
      "657/657 [==============================] - 1s 924us/step - loss: 0.3596 - accuracy: 0.8276\n",
      "Epoch 27/75\n",
      "657/657 [==============================] - 1s 947us/step - loss: 0.3584 - accuracy: 0.8266\n",
      "Epoch 28/75\n",
      "657/657 [==============================] - 1s 937us/step - loss: 0.3573 - accuracy: 0.82890s - loss: 0.3524 - accuracy\n",
      "Epoch 29/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.3558 - accuracy: 0.8334\n",
      "Epoch 30/75\n",
      "657/657 [==============================] - 1s 920us/step - loss: 0.3563 - accuracy: 0.8296\n",
      "Epoch 31/75\n",
      "657/657 [==============================] - 1s 894us/step - loss: 0.3536 - accuracy: 0.8307\n",
      "Epoch 32/75\n",
      "657/657 [==============================] - 1s 932us/step - loss: 0.3523 - accuracy: 0.8307\n",
      "Epoch 33/75\n",
      "657/657 [==============================] - 1s 916us/step - loss: 0.3511 - accuracy: 0.8339\n",
      "Epoch 34/75\n",
      "657/657 [==============================] - 1s 924us/step - loss: 0.3507 - accuracy: 0.8325\n",
      "Epoch 35/75\n",
      "657/657 [==============================] - 1s 957us/step - loss: 0.3491 - accuracy: 0.83370s - loss: 0.3511 - accuracy: 0.\n",
      "Epoch 36/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.3486 - accuracy: 0.8322\n",
      "Epoch 37/75\n",
      "657/657 [==============================] - 1s 995us/step - loss: 0.3464 - accuracy: 0.8360\n",
      "Epoch 38/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.3455 - accuracy: 0.8340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/75\n",
      "657/657 [==============================] - 1s 969us/step - loss: 0.3452 - accuracy: 0.8327\n",
      "Epoch 40/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.3439 - accuracy: 0.8357\n",
      "Epoch 41/75\n",
      "657/657 [==============================] - 1s 973us/step - loss: 0.3431 - accuracy: 0.8350\n",
      "Epoch 42/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.3413 - accuracy: 0.8343\n",
      "Epoch 43/75\n",
      "657/657 [==============================] - 1s 931us/step - loss: 0.3408 - accuracy: 0.8343\n",
      "Epoch 44/75\n",
      "657/657 [==============================] - 1s 976us/step - loss: 0.3398 - accuracy: 0.8369\n",
      "Epoch 45/75\n",
      "657/657 [==============================] - 1s 910us/step - loss: 0.3390 - accuracy: 0.8363\n",
      "Epoch 46/75\n",
      "657/657 [==============================] - 1s 992us/step - loss: 0.3387 - accuracy: 0.8340\n",
      "Epoch 47/75\n",
      "657/657 [==============================] - 1s 944us/step - loss: 0.3371 - accuracy: 0.8333\n",
      "Epoch 48/75\n",
      "657/657 [==============================] - 1s 915us/step - loss: 0.3378 - accuracy: 0.8368\n",
      "Epoch 49/75\n",
      "657/657 [==============================] - 1s 965us/step - loss: 0.3350 - accuracy: 0.8380\n",
      "Epoch 50/75\n",
      "657/657 [==============================] - 1s 954us/step - loss: 0.3343 - accuracy: 0.8375\n",
      "Epoch 51/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.3336 - accuracy: 0.8391\n",
      "Epoch 52/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.3329 - accuracy: 0.8388\n",
      "Epoch 53/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.8380\n",
      "Epoch 54/75\n",
      "657/657 [==============================] - 1s 956us/step - loss: 0.3315 - accuracy: 0.8407\n",
      "Epoch 55/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.3307 - accuracy: 0.8397: 0s - loss: 0.3350 - ac\n",
      "Epoch 56/75\n",
      "657/657 [==============================] - 1s 979us/step - loss: 0.3306 - accuracy: 0.8418\n",
      "Epoch 57/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.3297 - accuracy: 0.8423\n",
      "Epoch 58/75\n",
      "657/657 [==============================] - 1s 963us/step - loss: 0.3297 - accuracy: 0.8389\n",
      "Epoch 59/75\n",
      "657/657 [==============================] - 1s 960us/step - loss: 0.3278 - accuracy: 0.8421\n",
      "Epoch 60/75\n",
      "657/657 [==============================] - 1s 928us/step - loss: 0.3274 - accuracy: 0.8395\n",
      "Epoch 61/75\n",
      "657/657 [==============================] - 1s 947us/step - loss: 0.3271 - accuracy: 0.8404\n",
      "Epoch 62/75\n",
      "657/657 [==============================] - 1s 902us/step - loss: 0.3266 - accuracy: 0.8404\n",
      "Epoch 63/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.3253 - accuracy: 0.8438\n",
      "Epoch 64/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.3254 - accuracy: 0.8411\n",
      "Epoch 65/75\n",
      "657/657 [==============================] - 1s 942us/step - loss: 0.3248 - accuracy: 0.8418\n",
      "Epoch 66/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.3225 - accuracy: 0.8453\n",
      "Epoch 67/75\n",
      "657/657 [==============================] - 1s 930us/step - loss: 0.3214 - accuracy: 0.8444\n",
      "Epoch 68/75\n",
      "657/657 [==============================] - 1s 941us/step - loss: 0.3220 - accuracy: 0.8432\n",
      "Epoch 69/75\n",
      "657/657 [==============================] - 1s 945us/step - loss: 0.3214 - accuracy: 0.8421\n",
      "Epoch 70/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.3209 - accuracy: 0.8452\n",
      "Epoch 71/75\n",
      "657/657 [==============================] - 1s 957us/step - loss: 0.3205 - accuracy: 0.8438\n",
      "Epoch 72/75\n",
      "657/657 [==============================] - 1s 963us/step - loss: 0.3195 - accuracy: 0.8459\n",
      "Epoch 73/75\n",
      "657/657 [==============================] - 1s 946us/step - loss: 0.3189 - accuracy: 0.8461\n",
      "Epoch 74/75\n",
      "657/657 [==============================] - 1s 910us/step - loss: 0.3191 - accuracy: 0.8487\n",
      "Epoch 75/75\n",
      "657/657 [==============================] - 1s 976us/step - loss: 0.3183 - accuracy: 0.8459\n",
      "Epoch 1/75\n",
      "657/657 [==============================] - 1s 983us/step - loss: 0.3604 - accuracy: 0.8295\n",
      "Epoch 2/75\n",
      "657/657 [==============================] - 1s 881us/step - loss: 0.3515 - accuracy: 0.8301\n",
      "Epoch 3/75\n",
      "657/657 [==============================] - 1s 915us/step - loss: 0.3455 - accuracy: 0.8330\n",
      "Epoch 4/75\n",
      "657/657 [==============================] - 1s 896us/step - loss: 0.3437 - accuracy: 0.8330\n",
      "Epoch 5/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.3411 - accuracy: 0.8336\n",
      "Epoch 6/75\n",
      "657/657 [==============================] - 1s 904us/step - loss: 0.3381 - accuracy: 0.8391\n",
      "Epoch 7/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.3381 - accuracy: 0.8375\n",
      "Epoch 8/75\n",
      "657/657 [==============================] - 1s 898us/step - loss: 0.3359 - accuracy: 0.8377\n",
      "Epoch 9/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.3338 - accuracy: 0.8403\n",
      "Epoch 10/75\n",
      "657/657 [==============================] - 1s 953us/step - loss: 0.3315 - accuracy: 0.84300s - loss: 0.3302 - accu\n",
      "Epoch 11/75\n",
      "657/657 [==============================] - 1s 992us/step - loss: 0.3307 - accuracy: 0.84010s - loss: 0.3281 - ac\n",
      "Epoch 12/75\n",
      "657/657 [==============================] - 1s 940us/step - loss: 0.3293 - accuracy: 0.8421\n",
      "Epoch 13/75\n",
      "657/657 [==============================] - 1s 881us/step - loss: 0.3287 - accuracy: 0.84440s - loss: 0.3276 - accuracy: 0.\n",
      "Epoch 14/75\n",
      "657/657 [==============================] - 1s 900us/step - loss: 0.3275 - accuracy: 0.8459\n",
      "Epoch 15/75\n",
      "657/657 [==============================] - 1s 890us/step - loss: 0.3265 - accuracy: 0.8474\n",
      "Epoch 16/75\n",
      "657/657 [==============================] - 1s 937us/step - loss: 0.3262 - accuracy: 0.8479\n",
      "Epoch 17/75\n",
      "657/657 [==============================] - 1s 922us/step - loss: 0.3249 - accuracy: 0.8490\n",
      "Epoch 18/75\n",
      "657/657 [==============================] - 1s 935us/step - loss: 0.3229 - accuracy: 0.8485\n",
      "Epoch 19/75\n",
      "657/657 [==============================] - 1s 943us/step - loss: 0.3223 - accuracy: 0.8500\n",
      "Epoch 20/75\n",
      "657/657 [==============================] - 1s 940us/step - loss: 0.3232 - accuracy: 0.8476\n",
      "Epoch 21/75\n",
      "657/657 [==============================] - 1s 927us/step - loss: 0.3217 - accuracy: 0.8544\n",
      "Epoch 22/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.3203 - accuracy: 0.8535\n",
      "Epoch 23/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.3199 - accuracy: 0.8522: 0s - loss: 0.3244 - accu\n",
      "Epoch 24/75\n",
      "657/657 [==============================] - 1s 918us/step - loss: 0.3208 - accuracy: 0.8508\n",
      "Epoch 25/75\n",
      "657/657 [==============================] - 1s 909us/step - loss: 0.3190 - accuracy: 0.8538\n",
      "Epoch 26/75\n",
      "657/657 [==============================] - 1s 949us/step - loss: 0.3176 - accuracy: 0.85490s - loss: 0.3197 - accuracy: 0.\n",
      "Epoch 27/75\n",
      "657/657 [==============================] - 1s 999us/step - loss: 0.3175 - accuracy: 0.8560\n",
      "Epoch 28/75\n",
      "657/657 [==============================] - 1s 951us/step - loss: 0.3156 - accuracy: 0.85840s - loss: 0.3152 - accuracy: 0.85\n",
      "Epoch 29/75\n",
      "657/657 [==============================] - 1s 960us/step - loss: 0.3157 - accuracy: 0.8558\n",
      "Epoch 30/75\n",
      "657/657 [==============================] - 1s 890us/step - loss: 0.3172 - accuracy: 0.8551\n",
      "Epoch 31/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.3140 - accuracy: 0.8526\n",
      "Epoch 32/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.3130 - accuracy: 0.8598\n",
      "Epoch 33/75\n",
      "657/657 [==============================] - 1s 969us/step - loss: 0.3137 - accuracy: 0.8575\n",
      "Epoch 34/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.3115 - accuracy: 0.8586\n",
      "Epoch 35/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.3114 - accuracy: 0.8633\n",
      "Epoch 36/75\n",
      "657/657 [==============================] - 1s 989us/step - loss: 0.3113 - accuracy: 0.8583\n",
      "Epoch 37/75\n",
      "657/657 [==============================] - 1s 910us/step - loss: 0.3106 - accuracy: 0.8618\n",
      "Epoch 38/75\n",
      "657/657 [==============================] - 1s 940us/step - loss: 0.3105 - accuracy: 0.8608\n",
      "Epoch 39/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.3101 - accuracy: 0.8592\n",
      "Epoch 40/75\n",
      "657/657 [==============================] - 1s 929us/step - loss: 0.3094 - accuracy: 0.8605\n",
      "Epoch 41/75\n",
      "657/657 [==============================] - 1s 925us/step - loss: 0.3078 - accuracy: 0.8614\n",
      "Epoch 42/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "657/657 [==============================] - 1s 936us/step - loss: 0.3081 - accuracy: 0.8621\n",
      "Epoch 43/75\n",
      "657/657 [==============================] - 1s 939us/step - loss: 0.3084 - accuracy: 0.8650\n",
      "Epoch 44/75\n",
      "657/657 [==============================] - 1s 911us/step - loss: 0.3071 - accuracy: 0.8645\n",
      "Epoch 45/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.3056 - accuracy: 0.8598\n",
      "Epoch 46/75\n",
      "657/657 [==============================] - 1s 899us/step - loss: 0.3064 - accuracy: 0.8634\n",
      "Epoch 47/75\n",
      "657/657 [==============================] - 1s 902us/step - loss: 0.3052 - accuracy: 0.8633\n",
      "Epoch 48/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.3051 - accuracy: 0.8625\n",
      "Epoch 49/75\n",
      "657/657 [==============================] - 1s 935us/step - loss: 0.3046 - accuracy: 0.86690s - loss: 0.3062 - accuracy: 0.86\n",
      "Epoch 50/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.3035 - accuracy: 0.8631\n",
      "Epoch 51/75\n",
      "657/657 [==============================] - 1s 893us/step - loss: 0.3030 - accuracy: 0.8639\n",
      "Epoch 52/75\n",
      "657/657 [==============================] - 1s 909us/step - loss: 0.3030 - accuracy: 0.8672\n",
      "Epoch 53/75\n",
      "657/657 [==============================] - 1s 888us/step - loss: 0.3029 - accuracy: 0.8607\n",
      "Epoch 54/75\n",
      "657/657 [==============================] - 1s 909us/step - loss: 0.3036 - accuracy: 0.8630\n",
      "Epoch 55/75\n",
      "657/657 [==============================] - 1s 887us/step - loss: 0.3010 - accuracy: 0.8665\n",
      "Epoch 56/75\n",
      "657/657 [==============================] - 1s 966us/step - loss: 0.3003 - accuracy: 0.8672\n",
      "Epoch 57/75\n",
      "657/657 [==============================] - 1s 999us/step - loss: 0.3006 - accuracy: 0.8662\n",
      "Epoch 58/75\n",
      "657/657 [==============================] - 1s 985us/step - loss: 0.3009 - accuracy: 0.8653\n",
      "Epoch 59/75\n",
      "657/657 [==============================] - 1s 901us/step - loss: 0.3006 - accuracy: 0.8674\n",
      "Epoch 60/75\n",
      "657/657 [==============================] - 1s 897us/step - loss: 0.3003 - accuracy: 0.8633\n",
      "Epoch 61/75\n",
      "657/657 [==============================] - 1s 901us/step - loss: 0.2992 - accuracy: 0.8695\n",
      "Epoch 62/75\n",
      "657/657 [==============================] - 1s 886us/step - loss: 0.2993 - accuracy: 0.86570s - loss: 0.3020 - accuracy: \n",
      "Epoch 63/75\n",
      "657/657 [==============================] - 1s 909us/step - loss: 0.2994 - accuracy: 0.8650\n",
      "Epoch 64/75\n",
      "657/657 [==============================] - 1s 918us/step - loss: 0.2978 - accuracy: 0.8663\n",
      "Epoch 65/75\n",
      "657/657 [==============================] - 1s 905us/step - loss: 0.2983 - accuracy: 0.8668\n",
      "Epoch 66/75\n",
      "657/657 [==============================] - 1s 912us/step - loss: 0.2977 - accuracy: 0.8694\n",
      "Epoch 67/75\n",
      "657/657 [==============================] - 1s 902us/step - loss: 0.2970 - accuracy: 0.8663\n",
      "Epoch 68/75\n",
      "657/657 [==============================] - 1s 903us/step - loss: 0.2958 - accuracy: 0.8686\n",
      "Epoch 69/75\n",
      "657/657 [==============================] - 1s 906us/step - loss: 0.2966 - accuracy: 0.8686\n",
      "Epoch 70/75\n",
      "657/657 [==============================] - 1s 889us/step - loss: 0.2961 - accuracy: 0.8659\n",
      "Epoch 71/75\n",
      "657/657 [==============================] - 1s 903us/step - loss: 0.2956 - accuracy: 0.8672\n",
      "Epoch 72/75\n",
      "657/657 [==============================] - 1s 889us/step - loss: 0.2942 - accuracy: 0.8686\n",
      "Epoch 73/75\n",
      "657/657 [==============================] - 1s 942us/step - loss: 0.2942 - accuracy: 0.8700\n",
      "Epoch 74/75\n",
      "657/657 [==============================] - 1s 908us/step - loss: 0.2938 - accuracy: 0.8683\n",
      "Epoch 75/75\n",
      "657/657 [==============================] - 1s 909us/step - loss: 0.2922 - accuracy: 0.8730\n",
      "Epoch 1/75\n",
      "657/657 [==============================] - 1s 931us/step - loss: 0.3249 - accuracy: 0.8522\n",
      "Epoch 2/75\n",
      "657/657 [==============================] - 1s 975us/step - loss: 0.3165 - accuracy: 0.8550\n",
      "Epoch 3/75\n",
      "657/657 [==============================] - 1s 908us/step - loss: 0.3150 - accuracy: 0.8553\n",
      "Epoch 4/75\n",
      "657/657 [==============================] - 1s 904us/step - loss: 0.3104 - accuracy: 0.8594\n",
      "Epoch 5/75\n",
      "657/657 [==============================] - 1s 913us/step - loss: 0.3105 - accuracy: 0.8614\n",
      "Epoch 6/75\n",
      "657/657 [==============================] - 1s 912us/step - loss: 0.3086 - accuracy: 0.8576\n",
      "Epoch 7/75\n",
      "657/657 [==============================] - 1s 929us/step - loss: 0.3093 - accuracy: 0.8600\n",
      "Epoch 8/75\n",
      "657/657 [==============================] - 1s 869us/step - loss: 0.3060 - accuracy: 0.8608\n",
      "Epoch 9/75\n",
      "657/657 [==============================] - 1s 922us/step - loss: 0.3065 - accuracy: 0.8620\n",
      "Epoch 10/75\n",
      "657/657 [==============================] - 1s 911us/step - loss: 0.3056 - accuracy: 0.8661\n",
      "Epoch 11/75\n",
      "657/657 [==============================] - 1s 915us/step - loss: 0.3037 - accuracy: 0.8638\n",
      "Epoch 12/75\n",
      "657/657 [==============================] - 1s 918us/step - loss: 0.3024 - accuracy: 0.8655\n",
      "Epoch 13/75\n",
      "657/657 [==============================] - 1s 894us/step - loss: 0.3018 - accuracy: 0.86310s - loss: 0.3034 \n",
      "Epoch 14/75\n",
      "657/657 [==============================] - 1s 918us/step - loss: 0.3025 - accuracy: 0.8649\n",
      "Epoch 15/75\n",
      "657/657 [==============================] - 1s 913us/step - loss: 0.3005 - accuracy: 0.8672\n",
      "Epoch 16/75\n",
      "657/657 [==============================] - 1s 940us/step - loss: 0.3007 - accuracy: 0.8620\n",
      "Epoch 17/75\n",
      "657/657 [==============================] - 1s 959us/step - loss: 0.3005 - accuracy: 0.8623\n",
      "Epoch 18/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2990 - accuracy: 0.8650\n",
      "Epoch 19/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2990 - accuracy: 0.8650\n",
      "Epoch 20/75\n",
      "657/657 [==============================] - 1s 943us/step - loss: 0.2972 - accuracy: 0.86720s - loss: 0.3031 \n",
      "Epoch 21/75\n",
      "657/657 [==============================] - 1s 995us/step - loss: 0.2989 - accuracy: 0.8667\n",
      "Epoch 22/75\n",
      "657/657 [==============================] - 1s 918us/step - loss: 0.2961 - accuracy: 0.8676\n",
      "Epoch 23/75\n",
      "657/657 [==============================] - 1s 992us/step - loss: 0.2944 - accuracy: 0.8692\n",
      "Epoch 24/75\n",
      "657/657 [==============================] - 1s 993us/step - loss: 0.2966 - accuracy: 0.86470s - loss: 0\n",
      "Epoch 25/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2953 - accuracy: 0.8685\n",
      "Epoch 26/75\n",
      "657/657 [==============================] - 1s 999us/step - loss: 0.2941 - accuracy: 0.86660s - loss: 0.2933 - accuracy: 0.86\n",
      "Epoch 27/75\n",
      "657/657 [==============================] - 1s 940us/step - loss: 0.2955 - accuracy: 0.8676\n",
      "Epoch 28/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2941 - accuracy: 0.8653\n",
      "Epoch 29/75\n",
      "657/657 [==============================] - 1s 897us/step - loss: 0.2954 - accuracy: 0.8685\n",
      "Epoch 30/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2944 - accuracy: 0.8661\n",
      "Epoch 31/75\n",
      "657/657 [==============================] - 1s 961us/step - loss: 0.2948 - accuracy: 0.86920s - loss: 0.2990 - ac\n",
      "Epoch 32/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2935 - accuracy: 0.8679\n",
      "Epoch 33/75\n",
      "657/657 [==============================] - 1s 934us/step - loss: 0.2933 - accuracy: 0.8702\n",
      "Epoch 34/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2934 - accuracy: 0.8681\n",
      "Epoch 35/75\n",
      "657/657 [==============================] - 1s 937us/step - loss: 0.2923 - accuracy: 0.87100s - loss: 0.3031 - \n",
      "Epoch 36/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2928 - accuracy: 0.8702\n",
      "Epoch 37/75\n",
      "657/657 [==============================] - 1s 936us/step - loss: 0.2916 - accuracy: 0.8695\n",
      "Epoch 38/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2922 - accuracy: 0.8701\n",
      "Epoch 39/75\n",
      "657/657 [==============================] - 1s 939us/step - loss: 0.2914 - accuracy: 0.8702\n",
      "Epoch 40/75\n",
      "657/657 [==============================] - 1s 947us/step - loss: 0.2911 - accuracy: 0.8676\n",
      "Epoch 41/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2929 - accuracy: 0.8687\n",
      "Epoch 42/75\n",
      "657/657 [==============================] - 1s 938us/step - loss: 0.2922 - accuracy: 0.8664\n",
      "Epoch 43/75\n",
      "657/657 [==============================] - 1s 939us/step - loss: 0.2920 - accuracy: 0.8676\n",
      "Epoch 44/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2902 - accuracy: 0.8701: 0s - loss: 0.2902 - accuracy: 0.\n",
      "Epoch 45/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2922 - accuracy: 0.8707\n",
      "Epoch 46/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2898 - accuracy: 0.8696\n",
      "Epoch 47/75\n",
      "657/657 [==============================] - 1s 951us/step - loss: 0.2910 - accuracy: 0.8698\n",
      "Epoch 48/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2907 - accuracy: 0.8725\n",
      "Epoch 49/75\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.2911 - accuracy: 0.8663\n",
      "Epoch 50/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2889 - accuracy: 0.8710: 0s - loss: 0.2798 - \n",
      "Epoch 51/75\n",
      "657/657 [==============================] - 1s 969us/step - loss: 0.2905 - accuracy: 0.8705\n",
      "Epoch 52/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2891 - accuracy: 0.8698\n",
      "Epoch 53/75\n",
      "657/657 [==============================] - 1s 925us/step - loss: 0.2904 - accuracy: 0.8728\n",
      "Epoch 54/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2867 - accuracy: 0.8710: 0s - loss:\n",
      "Epoch 55/75\n",
      "657/657 [==============================] - 1s 942us/step - loss: 0.2896 - accuracy: 0.86660s - loss: 0.2903 - accuracy: 0.86\n",
      "Epoch 56/75\n",
      "657/657 [==============================] - 1s 946us/step - loss: 0.2871 - accuracy: 0.8704\n",
      "Epoch 57/75\n",
      "657/657 [==============================] - 1s 919us/step - loss: 0.2909 - accuracy: 0.8676\n",
      "Epoch 58/75\n",
      "657/657 [==============================] - 1s 964us/step - loss: 0.2888 - accuracy: 0.8684\n",
      "Epoch 59/75\n",
      "657/657 [==============================] - 1s 935us/step - loss: 0.2864 - accuracy: 0.8719\n",
      "Epoch 60/75\n",
      "657/657 [==============================] - 1s 920us/step - loss: 0.2891 - accuracy: 0.8696\n",
      "Epoch 61/75\n",
      "657/657 [==============================] - 1s 972us/step - loss: 0.2873 - accuracy: 0.8688\n",
      "Epoch 62/75\n",
      "657/657 [==============================] - 1s 940us/step - loss: 0.2894 - accuracy: 0.87020s - loss: 0.2897 - accuracy: 0.87\n",
      "Epoch 63/75\n",
      "657/657 [==============================] - 1s 978us/step - loss: 0.2868 - accuracy: 0.8673\n",
      "Epoch 64/75\n",
      "657/657 [==============================] - 1s 922us/step - loss: 0.2856 - accuracy: 0.8690\n",
      "Epoch 65/75\n",
      "657/657 [==============================] - 1s 941us/step - loss: 0.2857 - accuracy: 0.8687\n",
      "Epoch 66/75\n",
      "657/657 [==============================] - 1s 946us/step - loss: 0.2836 - accuracy: 0.8722\n",
      "Epoch 67/75\n",
      "657/657 [==============================] - 1s 922us/step - loss: 0.2858 - accuracy: 0.8719\n",
      "Epoch 68/75\n",
      "657/657 [==============================] - 1s 952us/step - loss: 0.2861 - accuracy: 0.8695\n",
      "Epoch 69/75\n",
      "657/657 [==============================] - 1s 951us/step - loss: 0.2847 - accuracy: 0.8743\n",
      "Epoch 70/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2847 - accuracy: 0.8725\n",
      "Epoch 71/75\n",
      "657/657 [==============================] - 1s 981us/step - loss: 0.2856 - accuracy: 0.8752\n",
      "Epoch 72/75\n",
      "657/657 [==============================] - 1s 960us/step - loss: 0.2848 - accuracy: 0.8727\n",
      "Epoch 73/75\n",
      "657/657 [==============================] - 1s 949us/step - loss: 0.2836 - accuracy: 0.8705\n",
      "Epoch 74/75\n",
      "657/657 [==============================] - 1s 919us/step - loss: 0.2831 - accuracy: 0.8745\n",
      "Epoch 75/75\n",
      "657/657 [==============================] - 1s 942us/step - loss: 0.2847 - accuracy: 0.8731\n",
      "Epoch 1/75\n",
      "657/657 [==============================] - 1s 906us/step - loss: 0.3207 - accuracy: 0.8472\n",
      "Epoch 2/75\n",
      "657/657 [==============================] - 1s 933us/step - loss: 0.3092 - accuracy: 0.8561\n",
      "Epoch 3/75\n",
      "657/657 [==============================] - 1s 947us/step - loss: 0.3049 - accuracy: 0.8561\n",
      "Epoch 4/75\n",
      "657/657 [==============================] - 1s 922us/step - loss: 0.3026 - accuracy: 0.8595\n",
      "Epoch 5/75\n",
      "657/657 [==============================] - 1s 891us/step - loss: 0.3016 - accuracy: 0.8628\n",
      "Epoch 6/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2993 - accuracy: 0.8593\n",
      "Epoch 7/75\n",
      "657/657 [==============================] - 1s 880us/step - loss: 0.2998 - accuracy: 0.8595\n",
      "Epoch 8/75\n",
      "657/657 [==============================] - 1s 946us/step - loss: 0.3006 - accuracy: 0.8612\n",
      "Epoch 9/75\n",
      "657/657 [==============================] - 1s 970us/step - loss: 0.2963 - accuracy: 0.8689\n",
      "Epoch 10/75\n",
      "657/657 [==============================] - 1s 980us/step - loss: 0.2955 - accuracy: 0.8619\n",
      "Epoch 11/75\n",
      "657/657 [==============================] - 1s 966us/step - loss: 0.2975 - accuracy: 0.8625\n",
      "Epoch 12/75\n",
      "657/657 [==============================] - 1s 980us/step - loss: 0.2951 - accuracy: 0.8648\n",
      "Epoch 13/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2951 - accuracy: 0.8657\n",
      "Epoch 14/75\n",
      "657/657 [==============================] - 1s 912us/step - loss: 0.2937 - accuracy: 0.8654\n",
      "Epoch 15/75\n",
      "657/657 [==============================] - 1s 977us/step - loss: 0.2933 - accuracy: 0.8648\n",
      "Epoch 16/75\n",
      "657/657 [==============================] - 1s 927us/step - loss: 0.2941 - accuracy: 0.8645\n",
      "Epoch 17/75\n",
      "657/657 [==============================] - 1s 940us/step - loss: 0.2925 - accuracy: 0.8650\n",
      "Epoch 18/75\n",
      "657/657 [==============================] - 1s 983us/step - loss: 0.2917 - accuracy: 0.8699\n",
      "Epoch 19/75\n",
      "657/657 [==============================] - 1s 933us/step - loss: 0.2918 - accuracy: 0.8676\n",
      "Epoch 20/75\n",
      "657/657 [==============================] - 1s 974us/step - loss: 0.2926 - accuracy: 0.86620s - loss: 0.2921 - accuracy: 0.86\n",
      "Epoch 21/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2899 - accuracy: 0.8676\n",
      "Epoch 22/75\n",
      "657/657 [==============================] - 1s 948us/step - loss: 0.2902 - accuracy: 0.8679\n",
      "Epoch 23/75\n",
      "657/657 [==============================] - 1s 917us/step - loss: 0.2909 - accuracy: 0.8691\n",
      "Epoch 24/75\n",
      "657/657 [==============================] - 1s 909us/step - loss: 0.2910 - accuracy: 0.8686\n",
      "Epoch 25/75\n",
      "657/657 [==============================] - 1s 947us/step - loss: 0.2897 - accuracy: 0.8651\n",
      "Epoch 26/75\n",
      "657/657 [==============================] - 1s 947us/step - loss: 0.2903 - accuracy: 0.8676\n",
      "Epoch 27/75\n",
      "657/657 [==============================] - 1s 942us/step - loss: 0.2913 - accuracy: 0.8657\n",
      "Epoch 28/75\n",
      "657/657 [==============================] - 1s 958us/step - loss: 0.2872 - accuracy: 0.8671\n",
      "Epoch 29/75\n",
      "657/657 [==============================] - 1s 918us/step - loss: 0.2879 - accuracy: 0.8660\n",
      "Epoch 30/75\n",
      "657/657 [==============================] - 1s 932us/step - loss: 0.2888 - accuracy: 0.8679\n",
      "Epoch 31/75\n",
      "657/657 [==============================] - 1s 977us/step - loss: 0.2900 - accuracy: 0.8662\n",
      "Epoch 32/75\n",
      "657/657 [==============================] - 1s 904us/step - loss: 0.2877 - accuracy: 0.8685\n",
      "Epoch 33/75\n",
      "657/657 [==============================] - 1s 893us/step - loss: 0.2884 - accuracy: 0.8674\n",
      "Epoch 34/75\n",
      "657/657 [==============================] - 1s 936us/step - loss: 0.2862 - accuracy: 0.8706\n",
      "Epoch 35/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2890 - accuracy: 0.8662\n",
      "Epoch 36/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2879 - accuracy: 0.8668\n",
      "Epoch 37/75\n",
      "657/657 [==============================] - 1s 935us/step - loss: 0.2873 - accuracy: 0.8677\n",
      "Epoch 38/75\n",
      "657/657 [==============================] - 1s 985us/step - loss: 0.2865 - accuracy: 0.8680\n",
      "Epoch 39/75\n",
      "657/657 [==============================] - 1s 941us/step - loss: 0.2878 - accuracy: 0.8671\n",
      "Epoch 40/75\n",
      "657/657 [==============================] - 1s 919us/step - loss: 0.2875 - accuracy: 0.8677\n",
      "Epoch 41/75\n",
      "657/657 [==============================] - 1s 931us/step - loss: 0.2867 - accuracy: 0.8702\n",
      "Epoch 42/75\n",
      "657/657 [==============================] - 1s 955us/step - loss: 0.2865 - accuracy: 0.8688\n",
      "Epoch 43/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2842 - accuracy: 0.8685\n",
      "Epoch 44/75\n",
      "657/657 [==============================] - 1s 951us/step - loss: 0.2856 - accuracy: 0.8711\n",
      "Epoch 45/75\n",
      "657/657 [==============================] - 1s 954us/step - loss: 0.2856 - accuracy: 0.8674\n",
      "Epoch 46/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2859 - accuracy: 0.8697\n",
      "Epoch 47/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "657/657 [==============================] - 1s 977us/step - loss: 0.2837 - accuracy: 0.8697\n",
      "Epoch 48/75\n",
      "657/657 [==============================] - 1s 932us/step - loss: 0.2870 - accuracy: 0.8686\n",
      "Epoch 49/75\n",
      "657/657 [==============================] - 1s 914us/step - loss: 0.2852 - accuracy: 0.8696\n",
      "Epoch 50/75\n",
      "657/657 [==============================] - 1s 947us/step - loss: 0.2829 - accuracy: 0.8706\n",
      "Epoch 51/75\n",
      "657/657 [==============================] - 1s 968us/step - loss: 0.2849 - accuracy: 0.8685\n",
      "Epoch 52/75\n",
      "657/657 [==============================] - 1s 980us/step - loss: 0.2821 - accuracy: 0.8734\n",
      "Epoch 53/75\n",
      "657/657 [==============================] - 1s 934us/step - loss: 0.2824 - accuracy: 0.8699\n",
      "Epoch 54/75\n",
      "657/657 [==============================] - 1s 914us/step - loss: 0.2814 - accuracy: 0.8731\n",
      "Epoch 55/75\n",
      "657/657 [==============================] - 1s 904us/step - loss: 0.2834 - accuracy: 0.8732\n",
      "Epoch 56/75\n",
      "657/657 [==============================] - 1s 906us/step - loss: 0.2832 - accuracy: 0.8709\n",
      "Epoch 57/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2838 - accuracy: 0.8702\n",
      "Epoch 58/75\n",
      "657/657 [==============================] - 1s 917us/step - loss: 0.2834 - accuracy: 0.8705\n",
      "Epoch 59/75\n",
      "657/657 [==============================] - 1s 974us/step - loss: 0.2804 - accuracy: 0.87520s - loss: 0\n",
      "Epoch 60/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2816 - accuracy: 0.8697\n",
      "Epoch 61/75\n",
      "657/657 [==============================] - 1s 941us/step - loss: 0.2792 - accuracy: 0.8743\n",
      "Epoch 62/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2808 - accuracy: 0.8747\n",
      "Epoch 63/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2825 - accuracy: 0.8715\n",
      "Epoch 64/75\n",
      "657/657 [==============================] - 1s 972us/step - loss: 0.2803 - accuracy: 0.87210s - loss: 0.2765 \n",
      "Epoch 65/75\n",
      "657/657 [==============================] - 1s 942us/step - loss: 0.2795 - accuracy: 0.8735\n",
      "Epoch 66/75\n",
      "657/657 [==============================] - 1s 904us/step - loss: 0.2811 - accuracy: 0.8735\n",
      "Epoch 67/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2803 - accuracy: 0.8734\n",
      "Epoch 68/75\n",
      "657/657 [==============================] - 1s 929us/step - loss: 0.2816 - accuracy: 0.8734\n",
      "Epoch 69/75\n",
      "657/657 [==============================] - 1s 881us/step - loss: 0.2782 - accuracy: 0.8743\n",
      "Epoch 70/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2795 - accuracy: 0.8775\n",
      "Epoch 71/75\n",
      "657/657 [==============================] - 1s 972us/step - loss: 0.2801 - accuracy: 0.8747\n",
      "Epoch 72/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2814 - accuracy: 0.8712\n",
      "Epoch 73/75\n",
      "657/657 [==============================] - 1s 940us/step - loss: 0.2778 - accuracy: 0.8718\n",
      "Epoch 74/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2790 - accuracy: 0.8764\n",
      "Epoch 75/75\n",
      "657/657 [==============================] - 1s 913us/step - loss: 0.2790 - accuracy: 0.8746\n",
      "Epoch 1/75\n",
      "656/656 [==============================] - 1s 967us/step - loss: 0.3147 - accuracy: 0.8516\n",
      "Epoch 2/75\n",
      "656/656 [==============================] - 1s 945us/step - loss: 0.3047 - accuracy: 0.85930s - loss: 0.2949 - accuracy\n",
      "Epoch 3/75\n",
      "656/656 [==============================] - 1s 911us/step - loss: 0.3026 - accuracy: 0.8573\n",
      "Epoch 4/75\n",
      "656/656 [==============================] - 1s 908us/step - loss: 0.2999 - accuracy: 0.8588\n",
      "Epoch 5/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2968 - accuracy: 0.8613\n",
      "Epoch 6/75\n",
      "656/656 [==============================] - 1s 985us/step - loss: 0.2963 - accuracy: 0.8637\n",
      "Epoch 7/75\n",
      "656/656 [==============================] - 1s 900us/step - loss: 0.2936 - accuracy: 0.8677\n",
      "Epoch 8/75\n",
      "656/656 [==============================] - 1s 924us/step - loss: 0.2948 - accuracy: 0.8642\n",
      "Epoch 9/75\n",
      "656/656 [==============================] - 1s 960us/step - loss: 0.2951 - accuracy: 0.8636\n",
      "Epoch 10/75\n",
      "656/656 [==============================] - 1s 881us/step - loss: 0.2930 - accuracy: 0.8636\n",
      "Epoch 11/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2936 - accuracy: 0.8634\n",
      "Epoch 12/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2921 - accuracy: 0.8661\n",
      "Epoch 13/75\n",
      "656/656 [==============================] - 1s 911us/step - loss: 0.2903 - accuracy: 0.8672\n",
      "Epoch 14/75\n",
      "656/656 [==============================] - 1s 910us/step - loss: 0.2910 - accuracy: 0.86720s - loss: 0.2900 - accuracy: \n",
      "Epoch 15/75\n",
      "656/656 [==============================] - 1s 934us/step - loss: 0.2885 - accuracy: 0.8674\n",
      "Epoch 16/75\n",
      "656/656 [==============================] - 1s 931us/step - loss: 0.2908 - accuracy: 0.8666\n",
      "Epoch 17/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2887 - accuracy: 0.8692: 0s - loss: 0.2879 - accuracy\n",
      "Epoch 18/75\n",
      "656/656 [==============================] - 1s 950us/step - loss: 0.2883 - accuracy: 0.8658\n",
      "Epoch 19/75\n",
      "656/656 [==============================] - 1s 909us/step - loss: 0.2886 - accuracy: 0.8694\n",
      "Epoch 20/75\n",
      "656/656 [==============================] - 1s 971us/step - loss: 0.2864 - accuracy: 0.8671\n",
      "Epoch 21/75\n",
      "656/656 [==============================] - 1s 927us/step - loss: 0.2862 - accuracy: 0.8718\n",
      "Epoch 22/75\n",
      "656/656 [==============================] - 1s 984us/step - loss: 0.2880 - accuracy: 0.8661\n",
      "Epoch 23/75\n",
      "656/656 [==============================] - 1s 935us/step - loss: 0.2848 - accuracy: 0.8729\n",
      "Epoch 24/75\n",
      "656/656 [==============================] - 1s 994us/step - loss: 0.2843 - accuracy: 0.8695\n",
      "Epoch 25/75\n",
      "656/656 [==============================] - 1s 951us/step - loss: 0.2872 - accuracy: 0.8689\n",
      "Epoch 26/75\n",
      "656/656 [==============================] - 1s 967us/step - loss: 0.2867 - accuracy: 0.8666\n",
      "Epoch 27/75\n",
      "656/656 [==============================] - 1s 952us/step - loss: 0.2837 - accuracy: 0.8706\n",
      "Epoch 28/75\n",
      "656/656 [==============================] - 1s 943us/step - loss: 0.2855 - accuracy: 0.8690\n",
      "Epoch 29/75\n",
      "656/656 [==============================] - 1s 914us/step - loss: 0.2849 - accuracy: 0.8681\n",
      "Epoch 30/75\n",
      "656/656 [==============================] - 1s 965us/step - loss: 0.2841 - accuracy: 0.8718\n",
      "Epoch 31/75\n",
      "656/656 [==============================] - 1s 979us/step - loss: 0.2844 - accuracy: 0.8712\n",
      "Epoch 32/75\n",
      "656/656 [==============================] - 1s 935us/step - loss: 0.2837 - accuracy: 0.8706\n",
      "Epoch 33/75\n",
      "656/656 [==============================] - 1s 987us/step - loss: 0.2864 - accuracy: 0.8738\n",
      "Epoch 34/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2841 - accuracy: 0.8723\n",
      "Epoch 35/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2840 - accuracy: 0.8718\n",
      "Epoch 36/75\n",
      "656/656 [==============================] - 1s 926us/step - loss: 0.2820 - accuracy: 0.8701\n",
      "Epoch 37/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2833 - accuracy: 0.8726\n",
      "Epoch 38/75\n",
      "656/656 [==============================] - 1s 928us/step - loss: 0.2827 - accuracy: 0.8710\n",
      "Epoch 39/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2833 - accuracy: 0.8738: 0s - loss: 0.2834 - accuracy: 0.87\n",
      "Epoch 40/75\n",
      "656/656 [==============================] - 1s 929us/step - loss: 0.2817 - accuracy: 0.8753\n",
      "Epoch 41/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2813 - accuracy: 0.8727\n",
      "Epoch 42/75\n",
      "656/656 [==============================] - 1s 961us/step - loss: 0.2809 - accuracy: 0.8756\n",
      "Epoch 43/75\n",
      "656/656 [==============================] - 1s 977us/step - loss: 0.2833 - accuracy: 0.8724\n",
      "Epoch 44/75\n",
      "656/656 [==============================] - 1s 918us/step - loss: 0.2823 - accuracy: 0.8721\n",
      "Epoch 45/75\n",
      "656/656 [==============================] - 1s 944us/step - loss: 0.2818 - accuracy: 0.8729\n",
      "Epoch 46/75\n",
      "656/656 [==============================] - 1s 953us/step - loss: 0.2820 - accuracy: 0.8726\n",
      "Epoch 47/75\n",
      "656/656 [==============================] - 1s 949us/step - loss: 0.2837 - accuracy: 0.8732\n",
      "Epoch 48/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2831 - accuracy: 0.8762\n",
      "Epoch 49/75\n",
      "656/656 [==============================] - 1s 972us/step - loss: 0.2809 - accuracy: 0.8704\n",
      "Epoch 50/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2813 - accuracy: 0.8730\n",
      "Epoch 51/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2808 - accuracy: 0.8736\n",
      "Epoch 52/75\n",
      "656/656 [==============================] - 1s 957us/step - loss: 0.2804 - accuracy: 0.8729\n",
      "Epoch 53/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2815 - accuracy: 0.8707\n",
      "Epoch 54/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2833 - accuracy: 0.8666\n",
      "Epoch 55/75\n",
      "656/656 [==============================] - 1s 968us/step - loss: 0.2815 - accuracy: 0.8709\n",
      "Epoch 56/75\n",
      "656/656 [==============================] - 1s 909us/step - loss: 0.2821 - accuracy: 0.8745\n",
      "Epoch 57/75\n",
      "656/656 [==============================] - 1s 981us/step - loss: 0.2809 - accuracy: 0.8730\n",
      "Epoch 58/75\n",
      "656/656 [==============================] - 1s 952us/step - loss: 0.2806 - accuracy: 0.87060s - loss: 0.2772 - accuracy\n",
      "Epoch 59/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2800 - accuracy: 0.8771\n",
      "Epoch 60/75\n",
      "656/656 [==============================] - 1s 943us/step - loss: 0.2805 - accuracy: 0.8735\n",
      "Epoch 61/75\n",
      "656/656 [==============================] - 1s 950us/step - loss: 0.2785 - accuracy: 0.8761\n",
      "Epoch 62/75\n",
      "656/656 [==============================] - 1s 916us/step - loss: 0.2800 - accuracy: 0.8767\n",
      "Epoch 63/75\n",
      "656/656 [==============================] - 1s 950us/step - loss: 0.2796 - accuracy: 0.8730\n",
      "Epoch 64/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2802 - accuracy: 0.8759\n",
      "Epoch 65/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2819 - accuracy: 0.8742\n",
      "Epoch 66/75\n",
      "656/656 [==============================] - 1s 979us/step - loss: 0.2779 - accuracy: 0.87680s - loss: 0.2810 - accu\n",
      "Epoch 67/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2801 - accuracy: 0.8744\n",
      "Epoch 68/75\n",
      "656/656 [==============================] - 1s 935us/step - loss: 0.2783 - accuracy: 0.8759\n",
      "Epoch 69/75\n",
      "656/656 [==============================] - 1s 937us/step - loss: 0.2794 - accuracy: 0.8761\n",
      "Epoch 70/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2793 - accuracy: 0.8762\n",
      "Epoch 71/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2787 - accuracy: 0.8730: 0s - loss: 0.2650 - ac\n",
      "Epoch 72/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2777 - accuracy: 0.8767\n",
      "Epoch 73/75\n",
      "656/656 [==============================] - 1s 921us/step - loss: 0.2780 - accuracy: 0.8715\n",
      "Epoch 74/75\n",
      "656/656 [==============================] - 1s 953us/step - loss: 0.2794 - accuracy: 0.8761\n",
      "Epoch 75/75\n",
      "656/656 [==============================] - 1s 903us/step - loss: 0.2795 - accuracy: 0.8730\n",
      "Epoch 1/75\n",
      "656/656 [==============================] - 1s 914us/step - loss: 0.2992 - accuracy: 0.8603\n",
      "Epoch 2/75\n",
      "656/656 [==============================] - 1s 970us/step - loss: 0.2880 - accuracy: 0.8721\n",
      "Epoch 3/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2857 - accuracy: 0.8758\n",
      "Epoch 4/75\n",
      "656/656 [==============================] - 1s 992us/step - loss: 0.2836 - accuracy: 0.8762\n",
      "Epoch 5/75\n",
      "656/656 [==============================] - 1s 951us/step - loss: 0.2825 - accuracy: 0.8762\n",
      "Epoch 6/75\n",
      "656/656 [==============================] - 1s 941us/step - loss: 0.2817 - accuracy: 0.8745\n",
      "Epoch 7/75\n",
      "656/656 [==============================] - 1s 947us/step - loss: 0.2819 - accuracy: 0.8758\n",
      "Epoch 8/75\n",
      "656/656 [==============================] - 1s 951us/step - loss: 0.2792 - accuracy: 0.8802\n",
      "Epoch 9/75\n",
      "656/656 [==============================] - 1s 952us/step - loss: 0.2798 - accuracy: 0.87740s - loss: 0.2696 - \n",
      "Epoch 10/75\n",
      "656/656 [==============================] - 1s 932us/step - loss: 0.2760 - accuracy: 0.8782\n",
      "Epoch 11/75\n",
      "656/656 [==============================] - 1s 956us/step - loss: 0.2782 - accuracy: 0.87670s - loss: 0.2828 - \n",
      "Epoch 12/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2788 - accuracy: 0.8736\n",
      "Epoch 13/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2785 - accuracy: 0.8777\n",
      "Epoch 14/75\n",
      "656/656 [==============================] - 1s 949us/step - loss: 0.2764 - accuracy: 0.8794\n",
      "Epoch 15/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2791 - accuracy: 0.8753\n",
      "Epoch 16/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2761 - accuracy: 0.8805\n",
      "Epoch 17/75\n",
      "656/656 [==============================] - 1s 967us/step - loss: 0.2766 - accuracy: 0.8806\n",
      "Epoch 18/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2752 - accuracy: 0.8752\n",
      "Epoch 19/75\n",
      "656/656 [==============================] - 1s 986us/step - loss: 0.2759 - accuracy: 0.87960s - loss: 0.2758 - accuracy: 0.\n",
      "Epoch 20/75\n",
      "656/656 [==============================] - 1s 1000us/step - loss: 0.2750 - accuracy: 0.8765\n",
      "Epoch 21/75\n",
      "656/656 [==============================] - 1s 996us/step - loss: 0.2751 - accuracy: 0.8768\n",
      "Epoch 22/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2755 - accuracy: 0.8768\n",
      "Epoch 23/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2755 - accuracy: 0.8777\n",
      "Epoch 24/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2737 - accuracy: 0.8828\n",
      "Epoch 25/75\n",
      "656/656 [==============================] - 1s 931us/step - loss: 0.2736 - accuracy: 0.8796\n",
      "Epoch 26/75\n",
      "656/656 [==============================] - 1s 985us/step - loss: 0.2746 - accuracy: 0.8770\n",
      "Epoch 27/75\n",
      "656/656 [==============================] - 1s 983us/step - loss: 0.2728 - accuracy: 0.8774\n",
      "Epoch 28/75\n",
      "656/656 [==============================] - 1s 952us/step - loss: 0.2732 - accuracy: 0.8773\n",
      "Epoch 29/75\n",
      "656/656 [==============================] - 1s 954us/step - loss: 0.2740 - accuracy: 0.8805\n",
      "Epoch 30/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2739 - accuracy: 0.8800\n",
      "Epoch 31/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2750 - accuracy: 0.8776\n",
      "Epoch 32/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2716 - accuracy: 0.8808\n",
      "Epoch 33/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2726 - accuracy: 0.8753: 0s - loss: 0.2724 - accuracy: 0.\n",
      "Epoch 34/75\n",
      "656/656 [==============================] - 1s 961us/step - loss: 0.2715 - accuracy: 0.8806\n",
      "Epoch 35/75\n",
      "656/656 [==============================] - 1s 956us/step - loss: 0.2730 - accuracy: 0.8761\n",
      "Epoch 36/75\n",
      "656/656 [==============================] - 1s 990us/step - loss: 0.2714 - accuracy: 0.88320s - loss: 0.2700 - accuracy: \n",
      "Epoch 37/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2722 - accuracy: 0.8828: 0s - loss: 0.2706 - ac\n",
      "Epoch 38/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2713 - accuracy: 0.8828\n",
      "Epoch 39/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2726 - accuracy: 0.8773\n",
      "Epoch 40/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2706 - accuracy: 0.8813\n",
      "Epoch 41/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2713 - accuracy: 0.8831\n",
      "Epoch 42/75\n",
      "656/656 [==============================] - 1s 972us/step - loss: 0.2708 - accuracy: 0.8814\n",
      "Epoch 43/75\n",
      "656/656 [==============================] - 1s 973us/step - loss: 0.2693 - accuracy: 0.8831\n",
      "Epoch 44/75\n",
      "656/656 [==============================] - 1s 974us/step - loss: 0.2708 - accuracy: 0.8805\n",
      "Epoch 45/75\n",
      "656/656 [==============================] - 1s 966us/step - loss: 0.2703 - accuracy: 0.8810\n",
      "Epoch 46/75\n",
      "656/656 [==============================] - 1s 936us/step - loss: 0.2695 - accuracy: 0.8811\n",
      "Epoch 47/75\n",
      "656/656 [==============================] - 1s 957us/step - loss: 0.2708 - accuracy: 0.8782\n",
      "Epoch 48/75\n",
      "656/656 [==============================] - 1s 911us/step - loss: 0.2685 - accuracy: 0.8787\n",
      "Epoch 49/75\n",
      "656/656 [==============================] - 1s 903us/step - loss: 0.2705 - accuracy: 0.8819\n",
      "Epoch 50/75\n",
      "656/656 [==============================] - 1s 920us/step - loss: 0.2704 - accuracy: 0.8813\n",
      "Epoch 51/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2721 - accuracy: 0.8776\n",
      "Epoch 52/75\n",
      "656/656 [==============================] - 1s 958us/step - loss: 0.2701 - accuracy: 0.8803\n",
      "Epoch 53/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2678 - accuracy: 0.8835: 0s - loss: 0.2664 - accuracy\n",
      "Epoch 54/75\n",
      "656/656 [==============================] - 1s 954us/step - loss: 0.2685 - accuracy: 0.8808\n",
      "Epoch 55/75\n",
      "656/656 [==============================] - 1s 950us/step - loss: 0.2686 - accuracy: 0.8811\n",
      "Epoch 56/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2690 - accuracy: 0.8813\n",
      "Epoch 57/75\n",
      "656/656 [==============================] - 1s 985us/step - loss: 0.2697 - accuracy: 0.8779\n",
      "Epoch 58/75\n",
      "656/656 [==============================] - 1s 946us/step - loss: 0.2689 - accuracy: 0.8808\n",
      "Epoch 59/75\n",
      "656/656 [==============================] - 1s 932us/step - loss: 0.2684 - accuracy: 0.8828\n",
      "Epoch 60/75\n",
      "656/656 [==============================] - 1s 991us/step - loss: 0.2699 - accuracy: 0.8765\n",
      "Epoch 61/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2688 - accuracy: 0.8835\n",
      "Epoch 62/75\n",
      "656/656 [==============================] - 1s 952us/step - loss: 0.2674 - accuracy: 0.8826\n",
      "Epoch 63/75\n",
      "656/656 [==============================] - 1s 934us/step - loss: 0.2685 - accuracy: 0.8820\n",
      "Epoch 64/75\n",
      "656/656 [==============================] - 1s 993us/step - loss: 0.2681 - accuracy: 0.8822\n",
      "Epoch 65/75\n",
      "656/656 [==============================] - 1s 962us/step - loss: 0.2681 - accuracy: 0.8816\n",
      "Epoch 66/75\n",
      "656/656 [==============================] - 1s 963us/step - loss: 0.2677 - accuracy: 0.8811\n",
      "Epoch 67/75\n",
      "656/656 [==============================] - 1s 916us/step - loss: 0.2675 - accuracy: 0.8823\n",
      "Epoch 68/75\n",
      "656/656 [==============================] - 1s 900us/step - loss: 0.2656 - accuracy: 0.8840\n",
      "Epoch 69/75\n",
      "656/656 [==============================] - 1s 944us/step - loss: 0.2674 - accuracy: 0.8800\n",
      "Epoch 70/75\n",
      "656/656 [==============================] - 1s 964us/step - loss: 0.2683 - accuracy: 0.8839\n",
      "Epoch 71/75\n",
      "656/656 [==============================] - 1s 954us/step - loss: 0.2668 - accuracy: 0.8834\n",
      "Epoch 72/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2686 - accuracy: 0.8826\n",
      "Epoch 73/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2665 - accuracy: 0.8782\n",
      "Epoch 74/75\n",
      "656/656 [==============================] - 1s 974us/step - loss: 0.2662 - accuracy: 0.8822\n",
      "Epoch 75/75\n",
      "656/656 [==============================] - 1s 980us/step - loss: 0.2646 - accuracy: 0.8874\n",
      "Epoch 1/75\n",
      "658/658 [==============================] - 1s 1ms/step - loss: 0.3013 - accuracy: 0.8624\n",
      "Epoch 2/75\n",
      "658/658 [==============================] - 1s 1ms/step - loss: 0.2937 - accuracy: 0.8676\n",
      "Epoch 3/75\n",
      "658/658 [==============================] - 1s 1ms/step - loss: 0.2894 - accuracy: 0.8687\n",
      "Epoch 4/75\n",
      "658/658 [==============================] - 1s 1ms/step - loss: 0.2860 - accuracy: 0.8709\n",
      "Epoch 5/75\n",
      "658/658 [==============================] - 1s 976us/step - loss: 0.2863 - accuracy: 0.8693\n",
      "Epoch 6/75\n",
      "658/658 [==============================] - 1s 1ms/step - loss: 0.2851 - accuracy: 0.8697\n",
      "Epoch 7/75\n",
      "658/658 [==============================] - 1s 966us/step - loss: 0.2842 - accuracy: 0.8748\n",
      "Epoch 8/75\n",
      "658/658 [==============================] - 1s 976us/step - loss: 0.2828 - accuracy: 0.8726\n",
      "Epoch 9/75\n",
      "658/658 [==============================] - 1s 1ms/step - loss: 0.2810 - accuracy: 0.8744\n",
      "Epoch 10/75\n",
      "658/658 [==============================] - 1s 1ms/step - loss: 0.2817 - accuracy: 0.8748\n",
      "Epoch 11/75\n",
      "658/658 [==============================] - 1s 988us/step - loss: 0.2817 - accuracy: 0.8743\n",
      "Epoch 12/75\n",
      "658/658 [==============================] - 1s 996us/step - loss: 0.2815 - accuracy: 0.8726\n",
      "Epoch 13/75\n",
      "658/658 [==============================] - 1s 1ms/step - loss: 0.2809 - accuracy: 0.8746\n",
      "Epoch 14/75\n",
      "658/658 [==============================] - 1s 1ms/step - loss: 0.2817 - accuracy: 0.8716\n",
      "Epoch 15/75\n",
      "658/658 [==============================] - 1s 1ms/step - loss: 0.2791 - accuracy: 0.8731: 0s - loss: 0.2704 \n",
      "Epoch 16/75\n",
      "658/658 [==============================] - 1s 1ms/step - loss: 0.2771 - accuracy: 0.8735\n",
      "Epoch 17/75\n",
      "658/658 [==============================] - 1s 1ms/step - loss: 0.2772 - accuracy: 0.8722\n",
      "Epoch 18/75\n",
      "658/658 [==============================] - 1s 1ms/step - loss: 0.2797 - accuracy: 0.8713\n",
      "Epoch 19/75\n",
      "658/658 [==============================] - 1s 1ms/step - loss: 0.2766 - accuracy: 0.8757\n",
      "Epoch 20/75\n",
      "658/658 [==============================] - 1s 992us/step - loss: 0.2760 - accuracy: 0.8769\n",
      "Epoch 21/75\n",
      "658/658 [==============================] - 1s 982us/step - loss: 0.2774 - accuracy: 0.8735\n",
      "Epoch 22/75\n",
      "658/658 [==============================] - 1s 1ms/step - loss: 0.2746 - accuracy: 0.8786\n",
      "Epoch 23/75\n",
      "658/658 [==============================] - 1s 1ms/step - loss: 0.2760 - accuracy: 0.8775\n",
      "Epoch 24/75\n",
      "658/658 [==============================] - 1s 971us/step - loss: 0.2761 - accuracy: 0.8784\n",
      "Epoch 25/75\n",
      "658/658 [==============================] - 1s 971us/step - loss: 0.2747 - accuracy: 0.87570s - loss: 0.2778 - accuracy: 0.\n",
      "Epoch 26/75\n",
      "658/658 [==============================] - 1s 1ms/step - loss: 0.2750 - accuracy: 0.8778\n",
      "Epoch 27/75\n",
      "658/658 [==============================] - 1s 1ms/step - loss: 0.2744 - accuracy: 0.8738\n",
      "Epoch 28/75\n",
      "658/658 [==============================] - 1s 954us/step - loss: 0.2759 - accuracy: 0.8746\n",
      "Epoch 29/75\n",
      "658/658 [==============================] - 1s 1ms/step - loss: 0.2755 - accuracy: 0.8760\n",
      "Epoch 30/75\n",
      "658/658 [==============================] - 1s 1ms/step - loss: 0.2732 - accuracy: 0.8805\n",
      "Epoch 31/75\n",
      "658/658 [==============================] - 1s 1ms/step - loss: 0.2725 - accuracy: 0.8751\n",
      "Epoch 32/75\n",
      "658/658 [==============================] - 1s 1ms/step - loss: 0.2723 - accuracy: 0.8731: 0s - loss: 0.2757 - ac\n",
      "Epoch 33/75\n",
      "658/658 [==============================] - 1s 980us/step - loss: 0.2734 - accuracy: 0.8754\n",
      "Epoch 34/75\n",
      "658/658 [==============================] - 1s 987us/step - loss: 0.2723 - accuracy: 0.8761\n",
      "Epoch 35/75\n",
      "658/658 [==============================] - 1s 1ms/step - loss: 0.2747 - accuracy: 0.8755\n",
      "Epoch 36/75\n",
      "658/658 [==============================] - 1s 1ms/step - loss: 0.2727 - accuracy: 0.8792\n",
      "Epoch 37/75\n",
      "658/658 [==============================] - 1s 1ms/step - loss: 0.2729 - accuracy: 0.8748\n",
      "Epoch 38/75\n",
      "658/658 [==============================] - 1s 1ms/step - loss: 0.2705 - accuracy: 0.8793\n",
      "Epoch 39/75\n",
      "658/658 [==============================] - 1s 1ms/step - loss: 0.2738 - accuracy: 0.8752\n",
      "Epoch 40/75\n",
      "658/658 [==============================] - 1s 1ms/step - loss: 0.2726 - accuracy: 0.8755: 0s - loss: 0.2742 - accu\n",
      "Epoch 41/75\n",
      "658/658 [==============================] - 1s 962us/step - loss: 0.2702 - accuracy: 0.8810\n",
      "Epoch 42/75\n",
      "658/658 [==============================] - 1s 996us/step - loss: 0.2708 - accuracy: 0.8775\n",
      "Epoch 43/75\n",
      "658/658 [==============================] - 1s 997us/step - loss: 0.2719 - accuracy: 0.8775\n",
      "Epoch 44/75\n",
      "658/658 [==============================] - 1s 1ms/step - loss: 0.2711 - accuracy: 0.8773\n",
      "Epoch 45/75\n",
      "658/658 [==============================] - 1s 992us/step - loss: 0.2698 - accuracy: 0.8795\n",
      "Epoch 46/75\n",
      "658/658 [==============================] - 1s 1ms/step - loss: 0.2692 - accuracy: 0.8779\n",
      "Epoch 47/75\n",
      "658/658 [==============================] - 1s 1ms/step - loss: 0.2699 - accuracy: 0.8757\n",
      "Epoch 48/75\n",
      "658/658 [==============================] - 1s 1ms/step - loss: 0.2712 - accuracy: 0.8769\n",
      "Epoch 49/75\n",
      "658/658 [==============================] - 1s 1ms/step - loss: 0.2692 - accuracy: 0.8807\n",
      "Epoch 50/75\n",
      "658/658 [==============================] - 1s 982us/step - loss: 0.2689 - accuracy: 0.8798\n",
      "Epoch 51/75\n",
      "658/658 [==============================] - 1s 1ms/step - loss: 0.2713 - accuracy: 0.8783\n",
      "Epoch 52/75\n",
      "658/658 [==============================] - 1s 1ms/step - loss: 0.2697 - accuracy: 0.8786\n",
      "Epoch 53/75\n",
      "658/658 [==============================] - 1s 1ms/step - loss: 0.2697 - accuracy: 0.8760\n",
      "Epoch 54/75\n",
      "658/658 [==============================] - 1s 1ms/step - loss: 0.2679 - accuracy: 0.8770\n",
      "Epoch 55/75\n",
      "658/658 [==============================] - 1s 995us/step - loss: 0.2670 - accuracy: 0.8783\n",
      "Epoch 56/75\n",
      "658/658 [==============================] - 1s 1ms/step - loss: 0.2695 - accuracy: 0.8799\n",
      "Epoch 57/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "658/658 [==============================] - 1s 962us/step - loss: 0.2673 - accuracy: 0.8795\n",
      "Epoch 58/75\n",
      "658/658 [==============================] - 1s 1ms/step - loss: 0.2681 - accuracy: 0.8772\n",
      "Epoch 59/75\n",
      "658/658 [==============================] - 1s 1ms/step - loss: 0.2666 - accuracy: 0.8779\n",
      "Epoch 60/75\n",
      "658/658 [==============================] - 1s 1ms/step - loss: 0.2692 - accuracy: 0.8766\n",
      "Epoch 61/75\n",
      "658/658 [==============================] - 1s 944us/step - loss: 0.2659 - accuracy: 0.8805\n",
      "Epoch 62/75\n",
      "658/658 [==============================] - 1s 1ms/step - loss: 0.2682 - accuracy: 0.8760\n",
      "Epoch 63/75\n",
      "658/658 [==============================] - 1s 957us/step - loss: 0.2675 - accuracy: 0.8792\n",
      "Epoch 64/75\n",
      "658/658 [==============================] - 1s 955us/step - loss: 0.2676 - accuracy: 0.8760\n",
      "Epoch 65/75\n",
      "658/658 [==============================] - 1s 1ms/step - loss: 0.2662 - accuracy: 0.8789: 0s - loss: 0.2664 - accuracy: \n",
      "Epoch 66/75\n",
      "658/658 [==============================] - 1s 982us/step - loss: 0.2671 - accuracy: 0.8772\n",
      "Epoch 67/75\n",
      "658/658 [==============================] - 1s 1ms/step - loss: 0.2664 - accuracy: 0.8767: 0s - loss: 0.2717 - accuracy\n",
      "Epoch 68/75\n",
      "658/658 [==============================] - 1s 1ms/step - loss: 0.2661 - accuracy: 0.8824\n",
      "Epoch 69/75\n",
      "658/658 [==============================] - 1s 1ms/step - loss: 0.2654 - accuracy: 0.8814\n",
      "Epoch 70/75\n",
      "658/658 [==============================] - 1s 1ms/step - loss: 0.2677 - accuracy: 0.8772\n",
      "Epoch 71/75\n",
      "658/658 [==============================] - 1s 1ms/step - loss: 0.2678 - accuracy: 0.8776\n",
      "Epoch 72/75\n",
      "658/658 [==============================] - 1s 965us/step - loss: 0.2647 - accuracy: 0.8796\n",
      "Epoch 73/75\n",
      "658/658 [==============================] - 1s 1ms/step - loss: 0.2651 - accuracy: 0.8786\n",
      "Epoch 74/75\n",
      "658/658 [==============================] - 1s 1ms/step - loss: 0.2656 - accuracy: 0.8802\n",
      "Epoch 75/75\n",
      "658/658 [==============================] - 1s 978us/step - loss: 0.2653 - accuracy: 0.8772\n",
      "Epoch 1/75\n",
      "657/657 [==============================] - 1s 978us/step - loss: 0.2846 - accuracy: 0.8733\n",
      "Epoch 2/75\n",
      "657/657 [==============================] - 1s 971us/step - loss: 0.2793 - accuracy: 0.8733\n",
      "Epoch 3/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2735 - accuracy: 0.8805\n",
      "Epoch 4/75\n",
      "657/657 [==============================] - 1s 965us/step - loss: 0.2717 - accuracy: 0.8735\n",
      "Epoch 5/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2680 - accuracy: 0.8808\n",
      "Epoch 6/75\n",
      "657/657 [==============================] - 1s 958us/step - loss: 0.2695 - accuracy: 0.8790\n",
      "Epoch 7/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2679 - accuracy: 0.8778\n",
      "Epoch 8/75\n",
      "657/657 [==============================] - 1s 982us/step - loss: 0.2682 - accuracy: 0.8829\n",
      "Epoch 9/75\n",
      "657/657 [==============================] - 1s 989us/step - loss: 0.2668 - accuracy: 0.8799\n",
      "Epoch 10/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2669 - accuracy: 0.8788\n",
      "Epoch 11/75\n",
      "657/657 [==============================] - 1s 981us/step - loss: 0.2657 - accuracy: 0.8810\n",
      "Epoch 12/75\n",
      "657/657 [==============================] - 1s 971us/step - loss: 0.2652 - accuracy: 0.8761\n",
      "Epoch 13/75\n",
      "657/657 [==============================] - 1s 991us/step - loss: 0.2623 - accuracy: 0.8804\n",
      "Epoch 14/75\n",
      "657/657 [==============================] - 1s 987us/step - loss: 0.2637 - accuracy: 0.8802\n",
      "Epoch 15/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2633 - accuracy: 0.8820: 0s - loss: 0.2641 - \n",
      "Epoch 16/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2628 - accuracy: 0.8775\n",
      "Epoch 17/75\n",
      "657/657 [==============================] - 1s 950us/step - loss: 0.2623 - accuracy: 0.8793\n",
      "Epoch 18/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2624 - accuracy: 0.8794: 0s - loss: 0.2583 - ac\n",
      "Epoch 19/75\n",
      "657/657 [==============================] - 1s 961us/step - loss: 0.2604 - accuracy: 0.8829\n",
      "Epoch 20/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2621 - accuracy: 0.8813\n",
      "Epoch 21/75\n",
      "657/657 [==============================] - 1s 967us/step - loss: 0.2588 - accuracy: 0.88310s - loss: 0.2751 - \n",
      "Epoch 22/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2617 - accuracy: 0.8820\n",
      "Epoch 23/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2593 - accuracy: 0.8788: 0s - loss: 0.2775 \n",
      "Epoch 24/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2587 - accuracy: 0.8825\n",
      "Epoch 25/75\n",
      "657/657 [==============================] - 1s 979us/step - loss: 0.2596 - accuracy: 0.8849\n",
      "Epoch 26/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2583 - accuracy: 0.8810: 0s - loss: 0.2579 - accura\n",
      "Epoch 27/75\n",
      "657/657 [==============================] - 1s 983us/step - loss: 0.2576 - accuracy: 0.8820\n",
      "Epoch 28/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2577 - accuracy: 0.8825\n",
      "Epoch 29/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2571 - accuracy: 0.8846\n",
      "Epoch 30/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2583 - accuracy: 0.8816\n",
      "Epoch 31/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2576 - accuracy: 0.8843: 0s - loss: 0.2600 - accu\n",
      "Epoch 32/75\n",
      "657/657 [==============================] - 1s 983us/step - loss: 0.2591 - accuracy: 0.8810\n",
      "Epoch 33/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2572 - accuracy: 0.8857\n",
      "Epoch 34/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2576 - accuracy: 0.8836\n",
      "Epoch 35/75\n",
      "657/657 [==============================] - 1s 979us/step - loss: 0.2563 - accuracy: 0.8831\n",
      "Epoch 36/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2562 - accuracy: 0.8845\n",
      "Epoch 37/75\n",
      "657/657 [==============================] - 1s 984us/step - loss: 0.2568 - accuracy: 0.8807\n",
      "Epoch 38/75\n",
      "657/657 [==============================] - 1s 957us/step - loss: 0.2570 - accuracy: 0.8828\n",
      "Epoch 39/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2551 - accuracy: 0.8839\n",
      "Epoch 40/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2570 - accuracy: 0.8857\n",
      "Epoch 41/75\n",
      "657/657 [==============================] - 1s 987us/step - loss: 0.2566 - accuracy: 0.8852\n",
      "Epoch 42/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2575 - accuracy: 0.8804\n",
      "Epoch 43/75\n",
      "657/657 [==============================] - 1s 981us/step - loss: 0.2539 - accuracy: 0.8854\n",
      "Epoch 44/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2557 - accuracy: 0.8820\n",
      "Epoch 45/75\n",
      "657/657 [==============================] - 1s 987us/step - loss: 0.2542 - accuracy: 0.8861\n",
      "Epoch 46/75\n",
      "657/657 [==============================] - 1s 986us/step - loss: 0.2534 - accuracy: 0.8837\n",
      "Epoch 47/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2561 - accuracy: 0.8846\n",
      "Epoch 48/75\n",
      "657/657 [==============================] - 1s 980us/step - loss: 0.2550 - accuracy: 0.8807\n",
      "Epoch 49/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2547 - accuracy: 0.8846\n",
      "Epoch 50/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2533 - accuracy: 0.8837\n",
      "Epoch 51/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2550 - accuracy: 0.8831\n",
      "Epoch 52/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2542 - accuracy: 0.8808\n",
      "Epoch 53/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2538 - accuracy: 0.8877\n",
      "Epoch 54/75\n",
      "657/657 [==============================] - 1s 956us/step - loss: 0.2513 - accuracy: 0.8880\n",
      "Epoch 55/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2543 - accuracy: 0.8880\n",
      "Epoch 56/75\n",
      "657/657 [==============================] - 1s 996us/step - loss: 0.2538 - accuracy: 0.8828\n",
      "Epoch 57/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2556 - accuracy: 0.8863\n",
      "Epoch 58/75\n",
      "657/657 [==============================] - 1s 956us/step - loss: 0.2520 - accuracy: 0.8886\n",
      "Epoch 59/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2540 - accuracy: 0.8811\n",
      "Epoch 60/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2518 - accuracy: 0.8860\n",
      "Epoch 61/75\n",
      "657/657 [==============================] - 1s 953us/step - loss: 0.2524 - accuracy: 0.8861\n",
      "Epoch 62/75\n",
      "657/657 [==============================] - 1s 925us/step - loss: 0.2529 - accuracy: 0.8822\n",
      "Epoch 63/75\n",
      "657/657 [==============================] - 1s 970us/step - loss: 0.2536 - accuracy: 0.8834\n",
      "Epoch 64/75\n",
      "657/657 [==============================] - 1s 940us/step - loss: 0.2518 - accuracy: 0.8831\n",
      "Epoch 65/75\n",
      "657/657 [==============================] - 1s 973us/step - loss: 0.2527 - accuracy: 0.8828\n",
      "Epoch 66/75\n",
      "657/657 [==============================] - 1s 979us/step - loss: 0.2505 - accuracy: 0.8868\n",
      "Epoch 67/75\n",
      "657/657 [==============================] - 1s 976us/step - loss: 0.2517 - accuracy: 0.8843\n",
      "Epoch 68/75\n",
      "657/657 [==============================] - 1s 975us/step - loss: 0.2524 - accuracy: 0.8860\n",
      "Epoch 69/75\n",
      "657/657 [==============================] - 1s 967us/step - loss: 0.2506 - accuracy: 0.8875\n",
      "Epoch 70/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2529 - accuracy: 0.8855\n",
      "Epoch 71/75\n",
      "657/657 [==============================] - 1s 934us/step - loss: 0.2515 - accuracy: 0.8848\n",
      "Epoch 72/75\n",
      "657/657 [==============================] - 1s 955us/step - loss: 0.2505 - accuracy: 0.88570s - loss: 0.2519 - accuracy: 0.\n",
      "Epoch 73/75\n",
      "657/657 [==============================] - 1s 953us/step - loss: 0.2527 - accuracy: 0.8842\n",
      "Epoch 74/75\n",
      "657/657 [==============================] - 1s 957us/step - loss: 0.2514 - accuracy: 0.8826\n",
      "Epoch 75/75\n",
      "657/657 [==============================] - 1s 945us/step - loss: 0.2514 - accuracy: 0.8849\n",
      "Epoch 1/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2952 - accuracy: 0.8671\n",
      "Epoch 2/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2822 - accuracy: 0.8694\n",
      "Epoch 3/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2809 - accuracy: 0.8732\n",
      "Epoch 4/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2771 - accuracy: 0.8738\n",
      "Epoch 5/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2777 - accuracy: 0.8725\n",
      "Epoch 6/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2735 - accuracy: 0.8758\n",
      "Epoch 7/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2749 - accuracy: 0.8749\n",
      "Epoch 8/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2743 - accuracy: 0.8729: 0s - loss: 0.2682 - accuracy\n",
      "Epoch 9/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2731 - accuracy: 0.8740\n",
      "Epoch 10/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2706 - accuracy: 0.8750\n",
      "Epoch 11/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2676 - accuracy: 0.8788\n",
      "Epoch 12/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2700 - accuracy: 0.8767\n",
      "Epoch 13/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2690 - accuracy: 0.8753\n",
      "Epoch 14/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2692 - accuracy: 0.8743\n",
      "Epoch 15/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2685 - accuracy: 0.8779\n",
      "Epoch 16/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2693 - accuracy: 0.8808\n",
      "Epoch 17/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2672 - accuracy: 0.8787\n",
      "Epoch 18/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2650 - accuracy: 0.8833\n",
      "Epoch 19/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2679 - accuracy: 0.8801\n",
      "Epoch 20/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2683 - accuracy: 0.8776\n",
      "Epoch 21/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2681 - accuracy: 0.8791\n",
      "Epoch 22/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2663 - accuracy: 0.8793\n",
      "Epoch 23/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2667 - accuracy: 0.8791\n",
      "Epoch 24/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2651 - accuracy: 0.8817\n",
      "Epoch 25/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2642 - accuracy: 0.8781: 0s - loss: 0.2644 - accuracy: 0.87\n",
      "Epoch 26/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2658 - accuracy: 0.8795\n",
      "Epoch 27/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2632 - accuracy: 0.8833\n",
      "Epoch 28/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2649 - accuracy: 0.8784\n",
      "Epoch 29/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2641 - accuracy: 0.8802\n",
      "Epoch 30/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2642 - accuracy: 0.8784\n",
      "Epoch 31/75\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.2633 - accuracy: 0.8814\n",
      "Epoch 32/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2640 - accuracy: 0.8830\n",
      "Epoch 33/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2646 - accuracy: 0.8787\n",
      "Epoch 34/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2631 - accuracy: 0.8814\n",
      "Epoch 35/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2624 - accuracy: 0.8854\n",
      "Epoch 36/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2642 - accuracy: 0.8784\n",
      "Epoch 37/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2646 - accuracy: 0.8836\n",
      "Epoch 38/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2608 - accuracy: 0.8781\n",
      "Epoch 39/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2617 - accuracy: 0.8801\n",
      "Epoch 40/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2614 - accuracy: 0.8787\n",
      "Epoch 41/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2593 - accuracy: 0.8839\n",
      "Epoch 42/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2621 - accuracy: 0.8830\n",
      "Epoch 43/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2596 - accuracy: 0.8822\n",
      "Epoch 44/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2600 - accuracy: 0.8842\n",
      "Epoch 45/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2607 - accuracy: 0.8804\n",
      "Epoch 46/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2607 - accuracy: 0.8813\n",
      "Epoch 47/75\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.2578 - accuracy: 0.8868\n",
      "Epoch 48/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2606 - accuracy: 0.8845\n",
      "Epoch 49/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2613 - accuracy: 0.8831\n",
      "Epoch 50/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2598 - accuracy: 0.8833\n",
      "Epoch 51/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2587 - accuracy: 0.8836\n",
      "Epoch 52/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2604 - accuracy: 0.8816\n",
      "Epoch 53/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2573 - accuracy: 0.8820\n",
      "Epoch 54/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2589 - accuracy: 0.8833\n",
      "Epoch 55/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2588 - accuracy: 0.8816\n",
      "Epoch 56/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2607 - accuracy: 0.8802\n",
      "Epoch 57/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2606 - accuracy: 0.8839\n",
      "Epoch 58/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2580 - accuracy: 0.8826: 0s - loss: 0.2480 - accuracy - ETA: 0s - loss: 0.2562 - accuracy\n",
      "Epoch 59/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2571 - accuracy: 0.8826\n",
      "Epoch 60/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2573 - accuracy: 0.8834\n",
      "Epoch 61/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2581 - accuracy: 0.8836\n",
      "Epoch 62/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2580 - accuracy: 0.8861\n",
      "Epoch 63/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2575 - accuracy: 0.8878\n",
      "Epoch 64/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2576 - accuracy: 0.8863\n",
      "Epoch 65/75\n",
      "657/657 [==============================] - ETA: 0s - loss: 0.2614 - accuracy: 0.88 - 1s 1ms/step - loss: 0.2594 - accuracy: 0.8830\n",
      "Epoch 66/75\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.2575 - accuracy: 0.8816\n",
      "Epoch 67/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2566 - accuracy: 0.8831\n",
      "Epoch 68/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2551 - accuracy: 0.8869: 0s - loss: 0.2425 - ac\n",
      "Epoch 69/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2562 - accuracy: 0.8858\n",
      "Epoch 70/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2555 - accuracy: 0.8849\n",
      "Epoch 71/75\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.2557 - accuracy: 0.8845\n",
      "Epoch 72/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2569 - accuracy: 0.8848\n",
      "Epoch 73/75\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.2556 - accuracy: 0.8863\n",
      "Epoch 74/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2551 - accuracy: 0.8834\n",
      "Epoch 75/75\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2559 - accuracy: 0.8830\n",
      "Epoch 1/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2851 - accuracy: 0.8707\n",
      "Epoch 2/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2709 - accuracy: 0.8772\n",
      "Epoch 3/75\n",
      "656/656 [==============================] - 1s 978us/step - loss: 0.2673 - accuracy: 0.8818\n",
      "Epoch 4/75\n",
      "656/656 [==============================] - 1s 981us/step - loss: 0.2652 - accuracy: 0.8783\n",
      "Epoch 5/75\n",
      "656/656 [==============================] - 1s 959us/step - loss: 0.2620 - accuracy: 0.8840\n",
      "Epoch 6/75\n",
      "656/656 [==============================] - 1s 973us/step - loss: 0.2623 - accuracy: 0.8820\n",
      "Epoch 7/75\n",
      "656/656 [==============================] - 1s 977us/step - loss: 0.2590 - accuracy: 0.8894\n",
      "Epoch 8/75\n",
      "656/656 [==============================] - 1s 979us/step - loss: 0.2588 - accuracy: 0.8840\n",
      "Epoch 9/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2590 - accuracy: 0.8910\n",
      "Epoch 10/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2582 - accuracy: 0.8844\n",
      "Epoch 11/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2577 - accuracy: 0.8881: 0s - loss: 0.2517 - accu\n",
      "Epoch 12/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2563 - accuracy: 0.8850\n",
      "Epoch 13/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2527 - accuracy: 0.8887: 0s - loss: 0.2539 - accuracy: \n",
      "Epoch 14/75\n",
      "656/656 [==============================] - 1s 985us/step - loss: 0.2547 - accuracy: 0.8855\n",
      "Epoch 15/75\n",
      "656/656 [==============================] - 1s 1000us/step - loss: 0.2545 - accuracy: 0.8902\n",
      "Epoch 16/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2542 - accuracy: 0.8902\n",
      "Epoch 17/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2544 - accuracy: 0.8866: 0s - loss: 0.2520 - accuracy: 0.88\n",
      "Epoch 18/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2540 - accuracy: 0.8893\n",
      "Epoch 19/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2525 - accuracy: 0.8904\n",
      "Epoch 20/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2561 - accuracy: 0.8864\n",
      "Epoch 21/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2534 - accuracy: 0.8887\n",
      "Epoch 22/75\n",
      "656/656 [==============================] - 1s 1000us/step - loss: 0.2526 - accuracy: 0.8864\n",
      "Epoch 23/75\n",
      "656/656 [==============================] - 1s 979us/step - loss: 0.2537 - accuracy: 0.8905\n",
      "Epoch 24/75\n",
      "656/656 [==============================] - 1s 981us/step - loss: 0.2522 - accuracy: 0.8911\n",
      "Epoch 25/75\n",
      "656/656 [==============================] - 1s 975us/step - loss: 0.2495 - accuracy: 0.8890\n",
      "Epoch 26/75\n",
      "656/656 [==============================] - 1s 986us/step - loss: 0.2506 - accuracy: 0.8899\n",
      "Epoch 27/75\n",
      "656/656 [==============================] - 1s 978us/step - loss: 0.2516 - accuracy: 0.8902\n",
      "Epoch 28/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2500 - accuracy: 0.8942\n",
      "Epoch 29/75\n",
      "656/656 [==============================] - 1s 978us/step - loss: 0.2515 - accuracy: 0.8911\n",
      "Epoch 30/75\n",
      "656/656 [==============================] - 1s 980us/step - loss: 0.2503 - accuracy: 0.8925\n",
      "Epoch 31/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2494 - accuracy: 0.8919\n",
      "Epoch 32/75\n",
      "656/656 [==============================] - 1s 983us/step - loss: 0.2480 - accuracy: 0.8884\n",
      "Epoch 33/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2473 - accuracy: 0.8911\n",
      "Epoch 34/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2492 - accuracy: 0.8888\n",
      "Epoch 35/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2498 - accuracy: 0.8908\n",
      "Epoch 36/75\n",
      "656/656 [==============================] - 1s 966us/step - loss: 0.2477 - accuracy: 0.8908\n",
      "Epoch 37/75\n",
      "656/656 [==============================] - 1s 991us/step - loss: 0.2450 - accuracy: 0.8930\n",
      "Epoch 38/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2484 - accuracy: 0.8899\n",
      "Epoch 39/75\n",
      "656/656 [==============================] - 1s 960us/step - loss: 0.2481 - accuracy: 0.8905\n",
      "Epoch 40/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2485 - accuracy: 0.8911\n",
      "Epoch 41/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2474 - accuracy: 0.8899: 0s - loss: 0.2447 - accura\n",
      "Epoch 42/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2474 - accuracy: 0.8940\n",
      "Epoch 43/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2496 - accuracy: 0.8879\n",
      "Epoch 44/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2468 - accuracy: 0.8925\n",
      "Epoch 45/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2456 - accuracy: 0.8940\n",
      "Epoch 46/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2460 - accuracy: 0.8957\n",
      "Epoch 47/75\n",
      "656/656 [==============================] - 1s 990us/step - loss: 0.2462 - accuracy: 0.8904\n",
      "Epoch 48/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2469 - accuracy: 0.8893\n",
      "Epoch 49/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2460 - accuracy: 0.8931: 0s - loss: 0.2496 \n",
      "Epoch 50/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2452 - accuracy: 0.8940\n",
      "Epoch 51/75\n",
      "656/656 [==============================] - 1s 984us/step - loss: 0.2468 - accuracy: 0.8930\n",
      "Epoch 52/75\n",
      "656/656 [==============================] - 1s 974us/step - loss: 0.2458 - accuracy: 0.8942\n",
      "Epoch 53/75\n",
      "656/656 [==============================] - 1s 990us/step - loss: 0.2453 - accuracy: 0.8901\n",
      "Epoch 54/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2471 - accuracy: 0.8913\n",
      "Epoch 55/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2454 - accuracy: 0.8957\n",
      "Epoch 56/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2451 - accuracy: 0.8901\n",
      "Epoch 57/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2440 - accuracy: 0.8957\n",
      "Epoch 58/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2454 - accuracy: 0.8913\n",
      "Epoch 59/75\n",
      "656/656 [==============================] - 1s 981us/step - loss: 0.2450 - accuracy: 0.8917\n",
      "Epoch 60/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2440 - accuracy: 0.8919\n",
      "Epoch 61/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2433 - accuracy: 0.8925\n",
      "Epoch 62/75\n",
      "656/656 [==============================] - 1s 988us/step - loss: 0.2438 - accuracy: 0.8933\n",
      "Epoch 63/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2433 - accuracy: 0.8989\n",
      "Epoch 64/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2451 - accuracy: 0.8927\n",
      "Epoch 65/75\n",
      "656/656 [==============================] - 1s 976us/step - loss: 0.2445 - accuracy: 0.8919\n",
      "Epoch 66/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2451 - accuracy: 0.8955\n",
      "Epoch 67/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2442 - accuracy: 0.8896\n",
      "Epoch 68/75\n",
      "656/656 [==============================] - 1s 996us/step - loss: 0.2428 - accuracy: 0.8916\n",
      "Epoch 69/75\n",
      "656/656 [==============================] - 1s 993us/step - loss: 0.2446 - accuracy: 0.8913\n",
      "Epoch 70/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2406 - accuracy: 0.8955\n",
      "Epoch 71/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2444 - accuracy: 0.8917\n",
      "Epoch 72/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2432 - accuracy: 0.8933\n",
      "Epoch 73/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2417 - accuracy: 0.8933\n",
      "Epoch 74/75\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2434 - accuracy: 0.8934: 0s - loss: 0.2260 \n",
      "Epoch 75/75\n",
      "656/656 [==============================] - 1s 984us/step - loss: 0.2410 - accuracy: 0.8946\n",
      "Average accuracy for model 3:  86.08610567514678\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.5\n",
    "sum1 = 0\n",
    "for train_index, test_index in kf.split(health_pca):\n",
    "    X_train, X_test = health_pca[train_index], health_pca[test_index] \n",
    "    y_train, y_test = labels_arr[train_index], labels_arr[test_index]\n",
    "    X_train_new, y_train_new = sm.fit_resample(X_train, y_train.ravel())\n",
    "    model_1.fit(X_train_new, y_train_new, epochs=50, batch_size=50)\n",
    "    preds = model_1.predict(X_test)\n",
    "    preds = np.where(preds > threshold, 1, 0)\n",
    "    sum1 += accuracy_score(y_test, preds) * 100\n",
    "\n",
    "print(\"Average accuracy for model 1: \", (sum1/10))\n",
    "\n",
    "sum2 = 0\n",
    "for train_index, test_index in kf.split(health_pca):\n",
    "    X_train, X_test = health_pca[train_index], health_pca[test_index] \n",
    "    y_train, y_test = labels_arr[train_index], labels_arr[test_index]\n",
    "    X_train_new, y_train_new = sm.fit_resample(X_train, y_train.ravel())\n",
    "    model_2.fit(X_train_new, y_train_new, epochs=50, batch_size=20)\n",
    "    preds = model_2.predict(X_test)\n",
    "    preds = np.where(preds > threshold, 1, 0)\n",
    "    sum2 += accuracy_score(y_test, preds) * 100\n",
    "\n",
    "print(\"Average accuracy for model 2: \", (sum2/10))\n",
    "\n",
    "sum3 = 0\n",
    "for train_index, test_index in kf.split(health_pca):\n",
    "    X_train, X_test = health_pca[train_index], health_pca[test_index] \n",
    "    y_train, y_test = labels_arr[train_index], labels_arr[test_index]\n",
    "    X_train_new, y_train_new = sm.fit_resample(X_train, y_train.ravel())\n",
    "    model_3.fit(X_train_new, y_train_new, epochs=75, batch_size=10)\n",
    "    preds = model_3.predict(X_test)\n",
    "    preds = np.where(preds > threshold, 1, 0)\n",
    "    sum3 += accuracy_score(y_test, preds) * 100\n",
    "\n",
    "print(\"Average accuracy for model 3: \", (sum3/10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is not visible but I wrote it here for clarity:\n",
    "Average accuracy for model 1:  83.9334637964775\n",
    "Average accuracy for model 2:  83.15068493150685\n",
    "Average accuracy for model 3:  86.36007827788649\n",
    "NN model 3 seems to be the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.5251 - accuracy: 0.7135\n",
      "Epoch 2/75\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.4378 - accuracy: 0.7774\n",
      "Epoch 3/75\n",
      "584/584 [==============================] - 1s 992us/step - loss: 0.4259 - accuracy: 0.7914\n",
      "Epoch 4/75\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.4205 - accuracy: 0.7916\n",
      "Epoch 5/75\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.4146 - accuracy: 0.7969\n",
      "Epoch 6/75\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.4115 - accuracy: 0.7943\n",
      "Epoch 7/75\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.4082 - accuracy: 0.7976\n",
      "Epoch 8/75\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.4049 - accuracy: 0.7960\n",
      "Epoch 9/75\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.4010 - accuracy: 0.7991\n",
      "Epoch 10/75\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3985 - accuracy: 0.7995\n",
      "Epoch 11/75\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3954 - accuracy: 0.8027\n",
      "Epoch 12/75\n",
      "584/584 [==============================] - 1s 985us/step - loss: 0.3932 - accuracy: 0.8060\n",
      "Epoch 13/75\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3908 - accuracy: 0.8032\n",
      "Epoch 14/75\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3893 - accuracy: 0.8010\n",
      "Epoch 15/75\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3854 - accuracy: 0.8089\n",
      "Epoch 16/75\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3839 - accuracy: 0.8092\n",
      "Epoch 17/75\n",
      "584/584 [==============================] - 1s 968us/step - loss: 0.3816 - accuracy: 0.8075\n",
      "Epoch 18/75\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3801 - accuracy: 0.8078\n",
      "Epoch 19/75\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3770 - accuracy: 0.8132\n",
      "Epoch 20/75\n",
      "584/584 [==============================] - 1s 983us/step - loss: 0.3756 - accuracy: 0.8101\n",
      "Epoch 21/75\n",
      "584/584 [==============================] - 1s 937us/step - loss: 0.3736 - accuracy: 0.8125\n",
      "Epoch 22/75\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3712 - accuracy: 0.8167\n",
      "Epoch 23/75\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3678 - accuracy: 0.8181\n",
      "Epoch 24/75\n",
      "584/584 [==============================] - 1s 992us/step - loss: 0.3666 - accuracy: 0.8183\n",
      "Epoch 25/75\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3640 - accuracy: 0.8186\n",
      "Epoch 26/75\n",
      "584/584 [==============================] - 1s 967us/step - loss: 0.3631 - accuracy: 0.8209\n",
      "Epoch 27/75\n",
      "584/584 [==============================] - 1s 979us/step - loss: 0.3603 - accuracy: 0.8188\n",
      "Epoch 28/75\n",
      "584/584 [==============================] - 1s 977us/step - loss: 0.3595 - accuracy: 0.8231\n",
      "Epoch 29/75\n",
      "584/584 [==============================] - 1s 951us/step - loss: 0.3578 - accuracy: 0.8246\n",
      "Epoch 30/75\n",
      "584/584 [==============================] - 1s 955us/step - loss: 0.3563 - accuracy: 0.8241\n",
      "Epoch 31/75\n",
      "584/584 [==============================] - 1s 987us/step - loss: 0.3534 - accuracy: 0.8215\n",
      "Epoch 32/75\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3520 - accuracy: 0.8260\n",
      "Epoch 33/75\n",
      "584/584 [==============================] - 1s 928us/step - loss: 0.3508 - accuracy: 0.8282\n",
      "Epoch 34/75\n",
      "584/584 [==============================] - 1s 945us/step - loss: 0.3484 - accuracy: 0.8272\n",
      "Epoch 35/75\n",
      "584/584 [==============================] - 1s 978us/step - loss: 0.3482 - accuracy: 0.8272\n",
      "Epoch 36/75\n",
      "584/584 [==============================] - 1s 979us/step - loss: 0.3455 - accuracy: 0.8286\n",
      "Epoch 37/75\n",
      "584/584 [==============================] - 1s 984us/step - loss: 0.3438 - accuracy: 0.8315\n",
      "Epoch 38/75\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3445 - accuracy: 0.8327\n",
      "Epoch 39/75\n",
      "584/584 [==============================] - 1s 980us/step - loss: 0.3431 - accuracy: 0.8337\n",
      "Epoch 40/75\n",
      "584/584 [==============================] - 1s 994us/step - loss: 0.3420 - accuracy: 0.8332\n",
      "Epoch 41/75\n",
      "584/584 [==============================] - 1s 949us/step - loss: 0.3407 - accuracy: 0.8337\n",
      "Epoch 42/75\n",
      "584/584 [==============================] - 1s 945us/step - loss: 0.3388 - accuracy: 0.8339\n",
      "Epoch 43/75\n",
      "584/584 [==============================] - 1s 944us/step - loss: 0.3385 - accuracy: 0.8323\n",
      "Epoch 44/75\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3368 - accuracy: 0.8371\n",
      "Epoch 45/75\n",
      "584/584 [==============================] - 1s 976us/step - loss: 0.3352 - accuracy: 0.8359\n",
      "Epoch 46/75\n",
      "584/584 [==============================] - 1s 965us/step - loss: 0.3340 - accuracy: 0.8382\n",
      "Epoch 47/75\n",
      "584/584 [==============================] - 1s 936us/step - loss: 0.3321 - accuracy: 0.8414\n",
      "Epoch 48/75\n",
      "584/584 [==============================] - 1s 954us/step - loss: 0.3322 - accuracy: 0.8373\n",
      "Epoch 49/75\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3301 - accuracy: 0.8423\n",
      "Epoch 50/75\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3308 - accuracy: 0.8426\n",
      "Epoch 51/75\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3295 - accuracy: 0.8421: 0s - loss: 0.3245 - accu\n",
      "Epoch 52/75\n",
      "584/584 [==============================] - 1s 996us/step - loss: 0.3298 - accuracy: 0.8407\n",
      "Epoch 53/75\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3276 - accuracy: 0.8424\n",
      "Epoch 54/75\n",
      "584/584 [==============================] - 1s 944us/step - loss: 0.3265 - accuracy: 0.8418\n",
      "Epoch 55/75\n",
      "584/584 [==============================] - 1s 935us/step - loss: 0.3250 - accuracy: 0.8443\n",
      "Epoch 56/75\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3251 - accuracy: 0.8454\n",
      "Epoch 57/75\n",
      "584/584 [==============================] - 1s 958us/step - loss: 0.3244 - accuracy: 0.8447\n",
      "Epoch 58/75\n",
      "584/584 [==============================] - 1s 967us/step - loss: 0.3228 - accuracy: 0.8469\n",
      "Epoch 59/75\n",
      "584/584 [==============================] - 1s 945us/step - loss: 0.3226 - accuracy: 0.8459\n",
      "Epoch 60/75\n",
      "584/584 [==============================] - 1s 980us/step - loss: 0.3217 - accuracy: 0.8479\n",
      "Epoch 61/75\n",
      "584/584 [==============================] - 1s 954us/step - loss: 0.3201 - accuracy: 0.8479\n",
      "Epoch 62/75\n",
      "584/584 [==============================] - ETA: 0s - loss: 0.3167 - accuracy: 0.85 - 1s 950us/step - loss: 0.3191 - accuracy: 0.8507\n",
      "Epoch 63/75\n",
      "584/584 [==============================] - 1s 948us/step - loss: 0.3196 - accuracy: 0.8442\n",
      "Epoch 64/75\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3190 - accuracy: 0.8459\n",
      "Epoch 65/75\n",
      "584/584 [==============================] - 1s 955us/step - loss: 0.3181 - accuracy: 0.8512\n",
      "Epoch 66/75\n",
      "584/584 [==============================] - 1s 987us/step - loss: 0.3171 - accuracy: 0.85170s - loss: 0.3180 - accuracy: 0.\n",
      "Epoch 67/75\n",
      "584/584 [==============================] - 1s 978us/step - loss: 0.3155 - accuracy: 0.8515\n",
      "Epoch 68/75\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3160 - accuracy: 0.8496\n",
      "Epoch 69/75\n",
      "584/584 [==============================] - 1s 989us/step - loss: 0.3137 - accuracy: 0.85460s - loss: 0.3122 - accuracy: \n",
      "Epoch 70/75\n",
      "584/584 [==============================] - 1s 959us/step - loss: 0.3144 - accuracy: 0.8498\n",
      "Epoch 71/75\n",
      "584/584 [==============================] - 1s 979us/step - loss: 0.3132 - accuracy: 0.8548\n",
      "Epoch 72/75\n",
      "584/584 [==============================] - 1s 929us/step - loss: 0.3118 - accuracy: 0.8555\n",
      "Epoch 73/75\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3123 - accuracy: 0.8532\n",
      "Epoch 74/75\n",
      "584/584 [==============================] - 1s 941us/step - loss: 0.3131 - accuracy: 0.8568\n",
      "Epoch 75/75\n",
      "584/584 [==============================] - 1s 951us/step - loss: 0.3126 - accuracy: 0.8570\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd664983a30>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_model = Sequential()\n",
    "nn_model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "nn_model.add(Dense(20, activation='relu'))\n",
    "nn_model.add(Dense(1, activation='sigmoid'))\n",
    "nn_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "X_train_new, y_train_new = sm.fit_resample(p_train, p_target.ravel())\n",
    "nn_model.fit(X_train_new, y_train_new, epochs=75, batch_size=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of neural network model (in %): 84.54011741682974\n",
      "Precision score: 0.13380281690140844\n",
      "Recall score: 0.35185185185185186\n",
      "F1 score: 0.19387755102040816\n",
      "confusion matrix:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = nn_model.predict(p_test)\n",
    "preds = np.where(preds > threshold, 1, 0)\n",
    "\n",
    "acc = (accuracy_score(p_target_test, preds) * 100)\n",
    "print(\"Accuracy of neural network model (in %):\", acc)\n",
    "\n",
    "prec = precision_score(p_target_test, preds)\n",
    "print(\"Precision score:\", prec)\n",
    "\n",
    "recall = recall_score(p_target_test, preds)\n",
    "print(\"Recall score:\", recall)\n",
    "\n",
    "f1 = f1_score(p_target_test, preds)\n",
    "print(\"F1 score:\", f1)\n",
    "\n",
    "cm = confusion_matrix(p_target_test, preds, labels = [0, 1])\n",
    "print(\"confusion matrix:\")\n",
    "\n",
    "plot = sns.heatmap(cm, annot=True) # along the y axis are the true values, along the x axis are the predicted values\n",
    "plot.set(xlabel='Predicted Label', ylabel='Actual label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best model\n",
    "As described in my report, I think that the best model for this problem is the logistic regression model (with l2 regularization, sag solver and 200 max iterations) with the lowered classification threshold (bayes classifier) of 0.4. This is not because the model had the best accuracy (just 80% to the highest accuracy of 90% that belongs to the random classifier) but because it had a good mixture of accuracy and recall. The model has a recall of 0.66 which means that it is able to correctly recognize 66% of all people susceptible to strokes/ who have had strokes. The random forrest classifier on the other hand had a recall of just 0.129.\n",
    "\n",
    "In a real world medical problem such as this, it is more important to correctly classify postive cases (of a disease or risk of disease/stroke like in this case) which is why I would recommend using a model with lower accuracy but higher recall."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
